{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import constants\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import IPython\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy.io import wavfile\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Embedding,Conv3D,Bidirectional\n",
    "from keras.layers import (Convolution1D, Convolution2D,Convolution3D,GlobalAveragePooling1D,GlobalAveragePooling2D, \n",
    "                          BatchNormalization, Flatten,\n",
    "                          GlobalMaxPool1D,LeakyReLU,GlobalMaxPool3D,\n",
    "                          MaxPool1D,MaxPool2D,MaxPool3D, Flatten, concatenate, Activation,ELU)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav_loc = \"../audio_train/\"\n",
    "test_wav_loc = \"../audio_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\",header=0,names=['name','label','verified'])\n",
    "verifiedData = dataset.loc[dataset.verified == 1,[\"name\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>003da8e5.wav</td>\n",
       "      <td>Knock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0048fd00.wav</td>\n",
       "      <td>Gunshot_or_gunfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>006f2f32.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0091fc7f.wav</td>\n",
       "      <td>Cello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0097160c.wav</td>\n",
       "      <td>Laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00c934d7.wav</td>\n",
       "      <td>Laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00cb787c.wav</td>\n",
       "      <td>Flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00d3bba3.wav</td>\n",
       "      <td>Telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00e2b4cd.wav</td>\n",
       "      <td>Bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00f88dc5.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>011a2185.wav</td>\n",
       "      <td>Cello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>01257aad.wav</td>\n",
       "      <td>Scissors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0160d55e.wav</td>\n",
       "      <td>Gong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0172a2a5.wav</td>\n",
       "      <td>Microwave_oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>018b1df6.wav</td>\n",
       "      <td>Shatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>019d2a2c.wav</td>\n",
       "      <td>Bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>01a59c11.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01b9f44a.wav</td>\n",
       "      <td>Telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>01c2f88b.wav</td>\n",
       "      <td>Bass_drum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>01d4dafd.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>01e723f5.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>01ee18fd.wav</td>\n",
       "      <td>Microwave_oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>01f2e70b.wav</td>\n",
       "      <td>Gunshot_or_gunfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>01fc4661.wav</td>\n",
       "      <td>Oboe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>020eb9f6.wav</td>\n",
       "      <td>Bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>022a3507.wav</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>022cc908.wav</td>\n",
       "      <td>Knock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9403</th>\n",
       "      <td>fe626e30.wav</td>\n",
       "      <td>Tambourine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9405</th>\n",
       "      <td>fe76c972.wav</td>\n",
       "      <td>Flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9411</th>\n",
       "      <td>fea8ae24.wav</td>\n",
       "      <td>Double_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>fec00143.wav</td>\n",
       "      <td>Violin_or_fiddle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>fec180d4.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>fef2f4dd.wav</td>\n",
       "      <td>Burping_or_eructation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9424</th>\n",
       "      <td>fef60012.wav</td>\n",
       "      <td>Double_bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9426</th>\n",
       "      <td>fefcacd6.wav</td>\n",
       "      <td>Drawer_open_or_close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9428</th>\n",
       "      <td>ff038671.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9429</th>\n",
       "      <td>ff0b5da2.wav</td>\n",
       "      <td>Gong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9430</th>\n",
       "      <td>ff0c153b.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9431</th>\n",
       "      <td>ff0d3545.wav</td>\n",
       "      <td>Snare_drum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>ff11628d.wav</td>\n",
       "      <td>Bass_drum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>ff12dece.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9438</th>\n",
       "      <td>ff3f21e7.wav</td>\n",
       "      <td>Snare_drum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9439</th>\n",
       "      <td>ff402c67.wav</td>\n",
       "      <td>Fireworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>ff462e1b.wav</td>\n",
       "      <td>Cowbell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9444</th>\n",
       "      <td>ff752a0c.wav</td>\n",
       "      <td>Clarinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>ff758ee0.wav</td>\n",
       "      <td>Gunshot_or_gunfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>ff95ac47.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>ff9eae6f.wav</td>\n",
       "      <td>Gong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9453</th>\n",
       "      <td>ffa4a506.wav</td>\n",
       "      <td>Cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>ffa61f00.wav</td>\n",
       "      <td>Tearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9458</th>\n",
       "      <td>ffc92b01.wav</td>\n",
       "      <td>Cello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9459</th>\n",
       "      <td>ffcb5c56.wav</td>\n",
       "      <td>Computer_keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>ffcefb78.wav</td>\n",
       "      <td>Knock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9461</th>\n",
       "      <td>ffd52400.wav</td>\n",
       "      <td>Microwave_oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>ffd6b26c.wav</td>\n",
       "      <td>Fart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>ffda1d2b.wav</td>\n",
       "      <td>Keys_jangling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>fff81f55.wav</td>\n",
       "      <td>Cough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3710 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                  label\n",
       "1     001ca53d.wav              Saxophone\n",
       "3     0033e230.wav           Glockenspiel\n",
       "4     00353774.wav                  Cello\n",
       "6     003da8e5.wav                  Knock\n",
       "7     0048fd00.wav     Gunshot_or_gunfire\n",
       "10    006f2f32.wav                 Hi-hat\n",
       "14    0091fc7f.wav                  Cello\n",
       "15    0097160c.wav               Laughter\n",
       "19    00c934d7.wav               Laughter\n",
       "21    00cb787c.wav                  Flute\n",
       "24    00d3bba3.wav              Telephone\n",
       "27    00e2b4cd.wav                   Bark\n",
       "28    00f88dc5.wav           Glockenspiel\n",
       "32    011a2185.wav                  Cello\n",
       "35    01257aad.wav               Scissors\n",
       "41    0160d55e.wav                   Gong\n",
       "43    0172a2a5.wav         Microwave_oven\n",
       "49    018b1df6.wav                Shatter\n",
       "54    019d2a2c.wav                   Bark\n",
       "58    01a59c11.wav              Harmonica\n",
       "60    01b9f44a.wav              Telephone\n",
       "61    01c2f88b.wav              Bass_drum\n",
       "63    01d4dafd.wav              Harmonica\n",
       "65    01e723f5.wav              Harmonica\n",
       "67    01ee18fd.wav         Microwave_oven\n",
       "68    01f2e70b.wav     Gunshot_or_gunfire\n",
       "69    01fc4661.wav                   Oboe\n",
       "70    020eb9f6.wav                   Bark\n",
       "75    022a3507.wav                    Bus\n",
       "76    022cc908.wav                  Knock\n",
       "...            ...                    ...\n",
       "9403  fe626e30.wav             Tambourine\n",
       "9405  fe76c972.wav                  Flute\n",
       "9411  fea8ae24.wav            Double_bass\n",
       "9415  fec00143.wav       Violin_or_fiddle\n",
       "9416  fec180d4.wav                Trumpet\n",
       "9423  fef2f4dd.wav  Burping_or_eructation\n",
       "9424  fef60012.wav            Double_bass\n",
       "9426  fefcacd6.wav   Drawer_open_or_close\n",
       "9428  ff038671.wav              Saxophone\n",
       "9429  ff0b5da2.wav                   Gong\n",
       "9430  ff0c153b.wav              Saxophone\n",
       "9431  ff0d3545.wav             Snare_drum\n",
       "9433  ff11628d.wav              Bass_drum\n",
       "9434  ff12dece.wav              Saxophone\n",
       "9438  ff3f21e7.wav             Snare_drum\n",
       "9439  ff402c67.wav              Fireworks\n",
       "9440  ff462e1b.wav                Cowbell\n",
       "9444  ff752a0c.wav               Clarinet\n",
       "9445  ff758ee0.wav     Gunshot_or_gunfire\n",
       "9450  ff95ac47.wav        Finger_snapping\n",
       "9452  ff9eae6f.wav                   Gong\n",
       "9453  ffa4a506.wav                  Cough\n",
       "9454  ffa61f00.wav                Tearing\n",
       "9458  ffc92b01.wav                  Cello\n",
       "9459  ffcb5c56.wav      Computer_keyboard\n",
       "9460  ffcefb78.wav                  Knock\n",
       "9461  ffd52400.wav         Microwave_oven\n",
       "9462  ffd6b26c.wav                   Fart\n",
       "9463  ffda1d2b.wav          Keys_jangling\n",
       "9472  fff81f55.wav                  Cough\n",
       "\n",
       "[3710 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifiedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=44100\n",
    "# Based on https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis?scriptVersionId=3019309\n",
    "def load_wav_file(name):\n",
    "    _, b = wavfile.read(train_wav_loc + name)\n",
    "    assert _ == sample_rate\n",
    "    return b\n",
    "\n",
    "verifiedData['time_series'] = verifiedData['name'].apply(load_wav_file)\n",
    "verifiedData['nframes'] = verifiedData['time_series'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>time_series</th>\n",
       "      <th>nframes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>[-33, -32, -34, -34, -37, -37, -39, -39, -41, ...</td>\n",
       "      <td>455112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>[0, 10, 39, -66, -49, 29, 4, -57, -133, -158, ...</td>\n",
       "      <td>352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>[-173, -162, -172, -142, -170, -139, -139, -13...</td>\n",
       "      <td>199332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>003da8e5.wav</td>\n",
       "      <td>Knock</td>\n",
       "      <td>[2, -1, -2, 0, -2, -2, 1, -3, -1, 0, -1, 1, -3...</td>\n",
       "      <td>59976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0048fd00.wav</td>\n",
       "      <td>Gunshot_or_gunfire</td>\n",
       "      <td>[-20, -23, -23, -15, -7, -5, -4, -7, -11, -16,...</td>\n",
       "      <td>45864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>006f2f32.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>[80, -14, 5, -98, 116, 32, -283, 444, -741, 24...</td>\n",
       "      <td>74088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0091fc7f.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>[19, 19, 17, 17, 16, 16, 16, 17, 17, 17, 16, 1...</td>\n",
       "      <td>251370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0097160c.wav</td>\n",
       "      <td>Laughter</td>\n",
       "      <td>[-3, -4, -6, -3, 4, 9, 13, 12, 11, -2, -1, -15...</td>\n",
       "      <td>116424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00c934d7.wav</td>\n",
       "      <td>Laughter</td>\n",
       "      <td>[0, -2, 1, 0, -1, -1, 0, 1, 1, 4, 0, 4, 4, 4, ...</td>\n",
       "      <td>110250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00cb787c.wav</td>\n",
       "      <td>Flute</td>\n",
       "      <td>[-4, -7, -6, -7, -5, -7, -4, -5, -5, -2, -2, -...</td>\n",
       "      <td>313110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00d3bba3.wav</td>\n",
       "      <td>Telephone</td>\n",
       "      <td>[-1, 0, -1, -2, 0, 0, 0, -2, 1, 0, 0, 0, -1, -...</td>\n",
       "      <td>429534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00e2b4cd.wav</td>\n",
       "      <td>Bark</td>\n",
       "      <td>[-1, 1, 0, -1, -1, -1, -2, -1, -2, 0, -2, -1, ...</td>\n",
       "      <td>620928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00f88dc5.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>[14, -41, -194, -134, 332, 663, 379, 636, 4639...</td>\n",
       "      <td>352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>011a2185.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>[-4, -2, -3, -3, -2, -2, -3, -3, -3, -2, -2, -...</td>\n",
       "      <td>275184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>01257aad.wav</td>\n",
       "      <td>Scissors</td>\n",
       "      <td>[-48, 21, 49, 24, -5, -19, -20, -24, -21, -20,...</td>\n",
       "      <td>391608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0160d55e.wav</td>\n",
       "      <td>Gong</td>\n",
       "      <td>[-1, 0, -1, -1, -1, 0, -1, -2, -1, 0, 0, -2, -...</td>\n",
       "      <td>277830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0172a2a5.wav</td>\n",
       "      <td>Microwave_oven</td>\n",
       "      <td>[105, 87, 69, 65, 65, 80, 99, 119, 128, 143, 1...</td>\n",
       "      <td>49392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>018b1df6.wav</td>\n",
       "      <td>Shatter</td>\n",
       "      <td>[51, 55, 55, 52, 49, 39, 33, 35, 36, 42, 50, 6...</td>\n",
       "      <td>89964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>019d2a2c.wav</td>\n",
       "      <td>Bark</td>\n",
       "      <td>[-1, 1, -1, -1, 0, -1, 0, 2, -3, 0, -1, -1, -1...</td>\n",
       "      <td>91728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>01a59c11.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "      <td>[-4, -4, 0, -2, 0, -5, -4, 1, -1, -1, 1, 2, 3,...</td>\n",
       "      <td>298998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01b9f44a.wav</td>\n",
       "      <td>Telephone</td>\n",
       "      <td>[-1, 1, 0, 1, -1, 0, -1, -1, 1, -1, -2, 0, 0, ...</td>\n",
       "      <td>134064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>01c2f88b.wav</td>\n",
       "      <td>Bass_drum</td>\n",
       "      <td>[2, 0, 1, 0, -1, 0, 1, 0, 2, 0, 0, 0, 1, 2, 1,...</td>\n",
       "      <td>91728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>01d4dafd.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "      <td>[5, 6, -5, 30, 27, 1, 11, 28, 42, 41, 22, -5, ...</td>\n",
       "      <td>167580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>01e723f5.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "      <td>[-1, -1, -3, -1, -1, -3, -1, -2, -2, -3, -1, -...</td>\n",
       "      <td>418068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>01ee18fd.wav</td>\n",
       "      <td>Microwave_oven</td>\n",
       "      <td>[-198, -211, -205, -197, -187, -195, -198, -20...</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>01f2e70b.wav</td>\n",
       "      <td>Gunshot_or_gunfire</td>\n",
       "      <td>[43, 46, 61, 57, 53, 58, 48, 80, 81, 89, 109, ...</td>\n",
       "      <td>1063692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>01fc4661.wav</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>[-15, -17, -15, -18, -17, -16, -17, -15, -16, ...</td>\n",
       "      <td>85554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>020eb9f6.wav</td>\n",
       "      <td>Bark</td>\n",
       "      <td>[105, 111, 89, 120, 108, 55, 144, 117, 123, 15...</td>\n",
       "      <td>29988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>022a3507.wav</td>\n",
       "      <td>Bus</td>\n",
       "      <td>[6, 5, 4, 1, -2, 0, 0, 0, -2, -3, -3, -5, -9, ...</td>\n",
       "      <td>155232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>022cc908.wav</td>\n",
       "      <td>Knock</td>\n",
       "      <td>[7, -8, -14, -11, -16, -22, -29, -27, -22, -25...</td>\n",
       "      <td>77616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9403</th>\n",
       "      <td>fe626e30.wav</td>\n",
       "      <td>Tambourine</td>\n",
       "      <td>[1, 1, 1, 4, 19, 38, 50, 54, 59, 65, 64, 69, 7...</td>\n",
       "      <td>60858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9405</th>\n",
       "      <td>fe76c972.wav</td>\n",
       "      <td>Flute</td>\n",
       "      <td>[3, 4, -2, -12, -8, -6, -7, -10, -13, -15, -20...</td>\n",
       "      <td>402192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9411</th>\n",
       "      <td>fea8ae24.wav</td>\n",
       "      <td>Double_bass</td>\n",
       "      <td>[-82, -78, -72, -67, -63, -59, -55, -46, -48, ...</td>\n",
       "      <td>156996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>fec00143.wav</td>\n",
       "      <td>Violin_or_fiddle</td>\n",
       "      <td>[488, 491, 474, 484, 481, 450, 538, 555, 525, ...</td>\n",
       "      <td>276948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>fec180d4.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>[2, -2, -4, -6, -7, -2, -3, -3, -3, -3, -5, -4...</td>\n",
       "      <td>470106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>fef2f4dd.wav</td>\n",
       "      <td>Burping_or_eructation</td>\n",
       "      <td>[0, -2, -2, -2, 0, 0, -1, 0, -1, 0, -1, 1, -2,...</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9424</th>\n",
       "      <td>fef60012.wav</td>\n",
       "      <td>Double_bass</td>\n",
       "      <td>[5, 8, 9, 8, 7, 6, 8, 4, 6, 7, 6, 8, 5, 6, 6, ...</td>\n",
       "      <td>82026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9426</th>\n",
       "      <td>fefcacd6.wav</td>\n",
       "      <td>Drawer_open_or_close</td>\n",
       "      <td>[-2, -1, 0, 0, -1, -1, 1, 2, 0, 1, -1, 1, 2, 0...</td>\n",
       "      <td>68796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9428</th>\n",
       "      <td>ff038671.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>[3, 4, 4, 2, 2, 1, 1, 3, 2, 2, 3, 5, 5, 6, 6, ...</td>\n",
       "      <td>232848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9429</th>\n",
       "      <td>ff0b5da2.wav</td>\n",
       "      <td>Gong</td>\n",
       "      <td>[-84, -88, -90, -93, -96, -95, -97, -101, -102...</td>\n",
       "      <td>176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9430</th>\n",
       "      <td>ff0c153b.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>[-1, -14, -24, -37, -53, -68, -80, -94, -116, ...</td>\n",
       "      <td>233730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9431</th>\n",
       "      <td>ff0d3545.wav</td>\n",
       "      <td>Snare_drum</td>\n",
       "      <td>[-107, 245, 362, -606, -577, -912, -214, 319, ...</td>\n",
       "      <td>65268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>ff11628d.wav</td>\n",
       "      <td>Bass_drum</td>\n",
       "      <td>[80, 41, 12, 14, 52, 109, 162, 191, 185, 154, ...</td>\n",
       "      <td>91728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>ff12dece.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>[0, 3, 1, -18, -15, 2, -8, -12, 1, 0, -9, -1, ...</td>\n",
       "      <td>283122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9438</th>\n",
       "      <td>ff3f21e7.wav</td>\n",
       "      <td>Snare_drum</td>\n",
       "      <td>[7, 7, 7, 12, 9, 8, 8, 4, 6, 3, 0, -2, -2, -3,...</td>\n",
       "      <td>274302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9439</th>\n",
       "      <td>ff402c67.wav</td>\n",
       "      <td>Fireworks</td>\n",
       "      <td>[1, 3, 0, 2, 2, -2, -1, -1, 1, -1, -4, -1, 2, ...</td>\n",
       "      <td>63504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>ff462e1b.wav</td>\n",
       "      <td>Cowbell</td>\n",
       "      <td>[-430, -316, -397, -241, -344, -461, 5052, 221...</td>\n",
       "      <td>15876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9444</th>\n",
       "      <td>ff752a0c.wav</td>\n",
       "      <td>Clarinet</td>\n",
       "      <td>[-8, -10, -9, -8, -10, -8, -7, -6, -9, -11, -1...</td>\n",
       "      <td>264600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>ff758ee0.wav</td>\n",
       "      <td>Gunshot_or_gunfire</td>\n",
       "      <td>[-2813, -2681, -2061, -972, 476, 2111, 3699, 5...</td>\n",
       "      <td>113778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>ff95ac47.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>[-28, -23, -24, -44, -15, -9, -37, -9, -17, -1...</td>\n",
       "      <td>26460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>ff9eae6f.wav</td>\n",
       "      <td>Gong</td>\n",
       "      <td>[1, 2, 0, 3, 2, 4, 4, 2, 1, -2, 0, 0, 0, 2, 2,...</td>\n",
       "      <td>75852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9453</th>\n",
       "      <td>ffa4a506.wav</td>\n",
       "      <td>Cough</td>\n",
       "      <td>[0, -1, 0, 1, 1, 0, 0, -1, 0, 0, 0, -1, -2, -1...</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>ffa61f00.wav</td>\n",
       "      <td>Tearing</td>\n",
       "      <td>[0, -3, -1, -3, 0, 1, 0, -1, 0, 0, 0, 0, -1, -...</td>\n",
       "      <td>67914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9458</th>\n",
       "      <td>ffc92b01.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>[-12, -15, -14, -15, -15, -13, -14, -14, -17, ...</td>\n",
       "      <td>275184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9459</th>\n",
       "      <td>ffcb5c56.wav</td>\n",
       "      <td>Computer_keyboard</td>\n",
       "      <td>[-1, -1, -1, -1, 0, 0, 0, -1, 0, -3, -1, 0, 0,...</td>\n",
       "      <td>57330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>ffcefb78.wav</td>\n",
       "      <td>Knock</td>\n",
       "      <td>[-1, -1, -1, 0, 1, 0, 0, 0, 0, 1, 0, -2, -3, -...</td>\n",
       "      <td>70560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9461</th>\n",
       "      <td>ffd52400.wav</td>\n",
       "      <td>Microwave_oven</td>\n",
       "      <td>[-32, -41, -33, -35, -55, -56, -23, -15, -36, ...</td>\n",
       "      <td>20286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>ffd6b26c.wav</td>\n",
       "      <td>Fart</td>\n",
       "      <td>[-71, -135, -152, -200, -278, -305, -260, -127...</td>\n",
       "      <td>94374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>ffda1d2b.wav</td>\n",
       "      <td>Keys_jangling</td>\n",
       "      <td>[-95, -97, -89, -91, -86, -89, -87, -84, -87, ...</td>\n",
       "      <td>98784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>fff81f55.wav</td>\n",
       "      <td>Cough</td>\n",
       "      <td>[9, 9, 4, 5, 6, 8, 6, 6, 1, 2, 9, -1, 7, 5, 5,...</td>\n",
       "      <td>33516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3710 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                  label  \\\n",
       "1     001ca53d.wav              Saxophone   \n",
       "3     0033e230.wav           Glockenspiel   \n",
       "4     00353774.wav                  Cello   \n",
       "6     003da8e5.wav                  Knock   \n",
       "7     0048fd00.wav     Gunshot_or_gunfire   \n",
       "10    006f2f32.wav                 Hi-hat   \n",
       "14    0091fc7f.wav                  Cello   \n",
       "15    0097160c.wav               Laughter   \n",
       "19    00c934d7.wav               Laughter   \n",
       "21    00cb787c.wav                  Flute   \n",
       "24    00d3bba3.wav              Telephone   \n",
       "27    00e2b4cd.wav                   Bark   \n",
       "28    00f88dc5.wav           Glockenspiel   \n",
       "32    011a2185.wav                  Cello   \n",
       "35    01257aad.wav               Scissors   \n",
       "41    0160d55e.wav                   Gong   \n",
       "43    0172a2a5.wav         Microwave_oven   \n",
       "49    018b1df6.wav                Shatter   \n",
       "54    019d2a2c.wav                   Bark   \n",
       "58    01a59c11.wav              Harmonica   \n",
       "60    01b9f44a.wav              Telephone   \n",
       "61    01c2f88b.wav              Bass_drum   \n",
       "63    01d4dafd.wav              Harmonica   \n",
       "65    01e723f5.wav              Harmonica   \n",
       "67    01ee18fd.wav         Microwave_oven   \n",
       "68    01f2e70b.wav     Gunshot_or_gunfire   \n",
       "69    01fc4661.wav                   Oboe   \n",
       "70    020eb9f6.wav                   Bark   \n",
       "75    022a3507.wav                    Bus   \n",
       "76    022cc908.wav                  Knock   \n",
       "...            ...                    ...   \n",
       "9403  fe626e30.wav             Tambourine   \n",
       "9405  fe76c972.wav                  Flute   \n",
       "9411  fea8ae24.wav            Double_bass   \n",
       "9415  fec00143.wav       Violin_or_fiddle   \n",
       "9416  fec180d4.wav                Trumpet   \n",
       "9423  fef2f4dd.wav  Burping_or_eructation   \n",
       "9424  fef60012.wav            Double_bass   \n",
       "9426  fefcacd6.wav   Drawer_open_or_close   \n",
       "9428  ff038671.wav              Saxophone   \n",
       "9429  ff0b5da2.wav                   Gong   \n",
       "9430  ff0c153b.wav              Saxophone   \n",
       "9431  ff0d3545.wav             Snare_drum   \n",
       "9433  ff11628d.wav              Bass_drum   \n",
       "9434  ff12dece.wav              Saxophone   \n",
       "9438  ff3f21e7.wav             Snare_drum   \n",
       "9439  ff402c67.wav              Fireworks   \n",
       "9440  ff462e1b.wav                Cowbell   \n",
       "9444  ff752a0c.wav               Clarinet   \n",
       "9445  ff758ee0.wav     Gunshot_or_gunfire   \n",
       "9450  ff95ac47.wav        Finger_snapping   \n",
       "9452  ff9eae6f.wav                   Gong   \n",
       "9453  ffa4a506.wav                  Cough   \n",
       "9454  ffa61f00.wav                Tearing   \n",
       "9458  ffc92b01.wav                  Cello   \n",
       "9459  ffcb5c56.wav      Computer_keyboard   \n",
       "9460  ffcefb78.wav                  Knock   \n",
       "9461  ffd52400.wav         Microwave_oven   \n",
       "9462  ffd6b26c.wav                   Fart   \n",
       "9463  ffda1d2b.wav          Keys_jangling   \n",
       "9472  fff81f55.wav                  Cough   \n",
       "\n",
       "                                            time_series  nframes  \n",
       "1     [-33, -32, -34, -34, -37, -37, -39, -39, -41, ...   455112  \n",
       "3     [0, 10, 39, -66, -49, 29, 4, -57, -133, -158, ...   352800  \n",
       "4     [-173, -162, -172, -142, -170, -139, -139, -13...   199332  \n",
       "6     [2, -1, -2, 0, -2, -2, 1, -3, -1, 0, -1, 1, -3...    59976  \n",
       "7     [-20, -23, -23, -15, -7, -5, -4, -7, -11, -16,...    45864  \n",
       "10    [80, -14, 5, -98, 116, 32, -283, 444, -741, 24...    74088  \n",
       "14    [19, 19, 17, 17, 16, 16, 16, 17, 17, 17, 16, 1...   251370  \n",
       "15    [-3, -4, -6, -3, 4, 9, 13, 12, 11, -2, -1, -15...   116424  \n",
       "19    [0, -2, 1, 0, -1, -1, 0, 1, 1, 4, 0, 4, 4, 4, ...   110250  \n",
       "21    [-4, -7, -6, -7, -5, -7, -4, -5, -5, -2, -2, -...   313110  \n",
       "24    [-1, 0, -1, -2, 0, 0, 0, -2, 1, 0, 0, 0, -1, -...   429534  \n",
       "27    [-1, 1, 0, -1, -1, -1, -2, -1, -2, 0, -2, -1, ...   620928  \n",
       "28    [14, -41, -194, -134, 332, 663, 379, 636, 4639...   352800  \n",
       "32    [-4, -2, -3, -3, -2, -2, -3, -3, -3, -2, -2, -...   275184  \n",
       "35    [-48, 21, 49, 24, -5, -19, -20, -24, -21, -20,...   391608  \n",
       "41    [-1, 0, -1, -1, -1, 0, -1, -2, -1, 0, 0, -2, -...   277830  \n",
       "43    [105, 87, 69, 65, 65, 80, 99, 119, 128, 143, 1...    49392  \n",
       "49    [51, 55, 55, 52, 49, 39, 33, 35, 36, 42, 50, 6...    89964  \n",
       "54    [-1, 1, -1, -1, 0, -1, 0, 2, -3, 0, -1, -1, -1...    91728  \n",
       "58    [-4, -4, 0, -2, 0, -5, -4, 1, -1, -1, 1, 2, 3,...   298998  \n",
       "60    [-1, 1, 0, 1, -1, 0, -1, -1, 1, -1, -2, 0, 0, ...   134064  \n",
       "61    [2, 0, 1, 0, -1, 0, 1, 0, 2, 0, 0, 0, 1, 2, 1,...    91728  \n",
       "63    [5, 6, -5, 30, 27, 1, 11, 28, 42, 41, 22, -5, ...   167580  \n",
       "65    [-1, -1, -3, -1, -1, -3, -1, -2, -2, -3, -1, -...   418068  \n",
       "67    [-198, -211, -205, -197, -187, -195, -198, -20...    44100  \n",
       "68    [43, 46, 61, 57, 53, 58, 48, 80, 81, 89, 109, ...  1063692  \n",
       "69    [-15, -17, -15, -18, -17, -16, -17, -15, -16, ...    85554  \n",
       "70    [105, 111, 89, 120, 108, 55, 144, 117, 123, 15...    29988  \n",
       "75    [6, 5, 4, 1, -2, 0, 0, 0, -2, -3, -3, -5, -9, ...   155232  \n",
       "76    [7, -8, -14, -11, -16, -22, -29, -27, -22, -25...    77616  \n",
       "...                                                 ...      ...  \n",
       "9403  [1, 1, 1, 4, 19, 38, 50, 54, 59, 65, 64, 69, 7...    60858  \n",
       "9405  [3, 4, -2, -12, -8, -6, -7, -10, -13, -15, -20...   402192  \n",
       "9411  [-82, -78, -72, -67, -63, -59, -55, -46, -48, ...   156996  \n",
       "9415  [488, 491, 474, 484, 481, 450, 538, 555, 525, ...   276948  \n",
       "9416  [2, -2, -4, -6, -7, -2, -3, -3, -3, -3, -5, -4...   470106  \n",
       "9423  [0, -2, -2, -2, 0, 0, -1, 0, -1, 0, -1, 1, -2,...   132300  \n",
       "9424  [5, 8, 9, 8, 7, 6, 8, 4, 6, 7, 6, 8, 5, 6, 6, ...    82026  \n",
       "9426  [-2, -1, 0, 0, -1, -1, 1, 2, 0, 1, -1, 1, 2, 0...    68796  \n",
       "9428  [3, 4, 4, 2, 2, 1, 1, 3, 2, 2, 3, 5, 5, 6, 6, ...   232848  \n",
       "9429  [-84, -88, -90, -93, -96, -95, -97, -101, -102...   176400  \n",
       "9430  [-1, -14, -24, -37, -53, -68, -80, -94, -116, ...   233730  \n",
       "9431  [-107, 245, 362, -606, -577, -912, -214, 319, ...    65268  \n",
       "9433  [80, 41, 12, 14, 52, 109, 162, 191, 185, 154, ...    91728  \n",
       "9434  [0, 3, 1, -18, -15, 2, -8, -12, 1, 0, -9, -1, ...   283122  \n",
       "9438  [7, 7, 7, 12, 9, 8, 8, 4, 6, 3, 0, -2, -2, -3,...   274302  \n",
       "9439  [1, 3, 0, 2, 2, -2, -1, -1, 1, -1, -4, -1, 2, ...    63504  \n",
       "9440  [-430, -316, -397, -241, -344, -461, 5052, 221...    15876  \n",
       "9444  [-8, -10, -9, -8, -10, -8, -7, -6, -9, -11, -1...   264600  \n",
       "9445  [-2813, -2681, -2061, -972, 476, 2111, 3699, 5...   113778  \n",
       "9450  [-28, -23, -24, -44, -15, -9, -37, -9, -17, -1...    26460  \n",
       "9452  [1, 2, 0, 3, 2, 4, 4, 2, 1, -2, 0, 0, 0, 2, 2,...    75852  \n",
       "9453  [0, -1, 0, 1, 1, 0, 0, -1, 0, 0, 0, -1, -2, -1...   132300  \n",
       "9454  [0, -3, -1, -3, 0, 1, 0, -1, 0, 0, 0, 0, -1, -...    67914  \n",
       "9458  [-12, -15, -14, -15, -15, -13, -14, -14, -17, ...   275184  \n",
       "9459  [-1, -1, -1, -1, 0, 0, 0, -1, 0, -3, -1, 0, 0,...    57330  \n",
       "9460  [-1, -1, -1, 0, 1, 0, 0, 0, 0, 1, 0, -2, -3, -...    70560  \n",
       "9461  [-32, -41, -33, -35, -55, -56, -23, -15, -36, ...    20286  \n",
       "9462  [-71, -135, -152, -200, -278, -305, -260, -127...    94374  \n",
       "9463  [-95, -97, -89, -91, -86, -89, -87, -84, -87, ...    98784  \n",
       "9472  [9, 9, 4, 5, 6, 8, 6, 6, 1, 2, 9, -1, 7, 5, 5,...    33516  \n",
       "\n",
       "[3710 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifiedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_estimator(df):\n",
    "    #return  0.5(np.tanh(0.01*(df-df.mean(axis=0))/df.std(axis=0))+ 1)\n",
    "    return (df - df.mean(axis=0)) / (df.std(axis=0))\n",
    "\n",
    "    \n",
    "def getData(df, wav_path,train=True):\n",
    "    dset=[]\n",
    "    audiolen=2*sample_rate\n",
    "    \n",
    "    if train==False:\n",
    "        ddir=data_loc+\"audio_test/\"\n",
    "        files=[f for f in listdir(ddir) if isfile(join(testpath, f))]\n",
    "    else:\n",
    "        ddir=wav_path\n",
    "        files=df.name.values\n",
    "    \n",
    "    for file in files:\n",
    "        wav,_= librosa.core.load(ddir+file, sr=sample_rate)\n",
    "        \n",
    "        # Pad/trim WAV data\n",
    "        if len(wav) > audiolen:\n",
    "            wav = wav[:audiolen]\n",
    "        elif len(wav) < audiolen:\n",
    "            off=audiolen - len(wav) \n",
    "            wav=np.pad(wav, (off, audiolen - len(wav) - off), 'constant')\n",
    "            \n",
    "        mfcc = librosa.feature.mfcc(wav, sr = sample_rate, n_mfcc=100)\n",
    "        dset.append(mfcc)\n",
    "    \n",
    "    return (tanh_estimator(np.array(dset))) # Return normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = getData(verifiedData,wav_path=train_wav_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3710, 40, 173)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode(data, oneHot=False):\n",
    "    # Encode labels into integers or onehot\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data)\n",
    "    trans = le.transform(data)\n",
    "    \n",
    "    if oneHot== True:\n",
    "        ohlen = (len(set(trans)))\n",
    "        eye=np.eye(ohlen)\n",
    "        return to_categorical(trans)\n",
    "        #return np.array([eye[i] for i in set(verifiedData['label'])])\n",
    "    else:\n",
    "        return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sizes:\n",
      "(2597, 100, 173)\n",
      "(2597, 41)\n",
      "\n",
      "Validation sizes:\n",
      "(556, 100, 173)\n",
      "(556, 41)\n",
      "\n",
      "Test sizes:\n",
      "(557, 100, 173)\n",
      "(557, 41)\n"
     ]
    }
   ],
   "source": [
    "yt=encode(verifiedData.label.values, oneHot=True)\n",
    "# Get validation set - keep 70% for train, 15% validation, 15% test\n",
    "training_size = int(x_train1.shape[0] * 0.7)\n",
    "validate_size = int(x_train1.shape[0]*.15)\n",
    "\n",
    "x_train=x_train1[:training_size] # shape (2968, 40, 28)\n",
    "x_val=x_train1[training_size:training_size+validate_size] # shape (742, 40, 28)\n",
    "x_test=x_train1[training_size+validate_size:]\n",
    "\n",
    "y_train=yt[:training_size] # shape 2968, 41\n",
    "y_val=yt[training_size:training_size+validate_size] # shape 742, 41\n",
    "y_test=yt[training_size+validate_size:]\n",
    "\n",
    "print ('Train sizes:')\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "print ('\\nValidation sizes:')\n",
    "print (x_val.shape)\n",
    "print (y_val.shape)\n",
    "\n",
    "print ('\\nTest sizes:')\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 40, 40)            55400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 40, 40)            160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 40, 40)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 40, 40)            12840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 40, 40)            160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 40, 40)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 40, 40)            12840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 40, 40)            160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 40, 40)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 40, 40)            12840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 40, 40)            160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 40, 40)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 40, 40)            12840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 40, 40)            160       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 41)                1681      \n",
      "=================================================================\n",
      "Total params: 109,241\n",
      "Trainable params: 108,841\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model = Sequential([\n",
    "    Convolution1D(40,8, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(1),\n",
    "    \n",
    "    Convolution1D(40,8, padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(1),\n",
    "    \n",
    "    Convolution1D(40,8, padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(1),\n",
    "    \n",
    "    Convolution1D(40,8, padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(1),\n",
    "    \n",
    "    Convolution1D(40,8, padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.1),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "print (conv_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/300\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 3.4180 - acc: 0.1178 - val_loss: 3.1360 - val_acc: 0.1637\n",
      "Epoch 2/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 3.0759 - acc: 0.1910 - val_loss: 3.0944 - val_acc: 0.1960\n",
      "Epoch 3/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 2.8858 - acc: 0.2360 - val_loss: 3.1045 - val_acc: 0.2086\n",
      "Epoch 4/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 2.7287 - acc: 0.2707 - val_loss: 3.0552 - val_acc: 0.2194\n",
      "Epoch 5/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 2.5886 - acc: 0.2957 - val_loss: 3.0431 - val_acc: 0.2212\n",
      "Epoch 6/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 2.4687 - acc: 0.3350 - val_loss: 2.8845 - val_acc: 0.2356\n",
      "Epoch 7/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 2.3557 - acc: 0.3535 - val_loss: 2.9978 - val_acc: 0.2572\n",
      "Epoch 8/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 2.2619 - acc: 0.3843 - val_loss: 2.9805 - val_acc: 0.2572\n",
      "Epoch 9/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 2.1492 - acc: 0.4093 - val_loss: 2.7639 - val_acc: 0.2878\n",
      "Epoch 10/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 2.0654 - acc: 0.4378 - val_loss: 2.9307 - val_acc: 0.2716\n",
      "Epoch 11/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.9813 - acc: 0.4621 - val_loss: 2.7227 - val_acc: 0.3040\n",
      "Epoch 12/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.9027 - acc: 0.4659 - val_loss: 3.0208 - val_acc: 0.2572\n",
      "Epoch 13/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.8123 - acc: 0.5013 - val_loss: 3.0558 - val_acc: 0.2860\n",
      "Epoch 14/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.7076 - acc: 0.5302 - val_loss: 3.0836 - val_acc: 0.2752\n",
      "Epoch 15/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.6080 - acc: 0.5576 - val_loss: 2.6281 - val_acc: 0.3453\n",
      "Epoch 16/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 1.5922 - acc: 0.5587 - val_loss: 2.7748 - val_acc: 0.3381\n",
      "Epoch 17/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 1.4990 - acc: 0.5891 - val_loss: 3.0763 - val_acc: 0.2968\n",
      "Epoch 18/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 1.4315 - acc: 0.6045 - val_loss: 2.8633 - val_acc: 0.3147\n",
      "Epoch 19/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.3754 - acc: 0.6246 - val_loss: 2.9378 - val_acc: 0.3273\n",
      "Epoch 20/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.2885 - acc: 0.6442 - val_loss: 3.3088 - val_acc: 0.2878\n",
      "Epoch 21/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.2478 - acc: 0.6588 - val_loss: 3.2405 - val_acc: 0.2860\n",
      "Epoch 22/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.1926 - acc: 0.6712 - val_loss: 3.1678 - val_acc: 0.2806\n",
      "Epoch 23/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 1.1174 - acc: 0.6916 - val_loss: 3.2357 - val_acc: 0.3058\n",
      "Epoch 24/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 1.0616 - acc: 0.7208 - val_loss: 3.1251 - val_acc: 0.3076\n",
      "Epoch 25/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 1.0265 - acc: 0.7162 - val_loss: 2.9808 - val_acc: 0.3543\n",
      "Epoch 26/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.9826 - acc: 0.7297 - val_loss: 3.0999 - val_acc: 0.3040\n",
      "Epoch 27/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.9182 - acc: 0.7520 - val_loss: 3.5076 - val_acc: 0.2806\n",
      "Epoch 28/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.9063 - acc: 0.7432 - val_loss: 3.6305 - val_acc: 0.2914\n",
      "Epoch 29/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.8301 - acc: 0.7690 - val_loss: 4.1118 - val_acc: 0.2464\n",
      "Epoch 30/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.8014 - acc: 0.7844 - val_loss: 3.8178 - val_acc: 0.2806\n",
      "Epoch 31/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.7383 - acc: 0.8021 - val_loss: 3.3136 - val_acc: 0.3597\n",
      "Epoch 32/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.7236 - acc: 0.8040 - val_loss: 3.5873 - val_acc: 0.3273\n",
      "Epoch 33/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.7028 - acc: 0.8017 - val_loss: 3.7714 - val_acc: 0.3058\n",
      "Epoch 34/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.6564 - acc: 0.8159 - val_loss: 3.9386 - val_acc: 0.2842\n",
      "Epoch 35/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.6431 - acc: 0.8252 - val_loss: 4.2895 - val_acc: 0.2950\n",
      "Epoch 36/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.6137 - acc: 0.8325 - val_loss: 3.8802 - val_acc: 0.2842\n",
      "Epoch 37/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5779 - acc: 0.8390 - val_loss: 4.4245 - val_acc: 0.3058\n",
      "Epoch 38/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5773 - acc: 0.8437 - val_loss: 4.0689 - val_acc: 0.2752\n",
      "Epoch 39/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5517 - acc: 0.8514 - val_loss: 3.8566 - val_acc: 0.3237\n",
      "Epoch 40/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.5305 - acc: 0.8548 - val_loss: 4.1068 - val_acc: 0.2896\n",
      "Epoch 41/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.4827 - acc: 0.8691 - val_loss: 4.1985 - val_acc: 0.2770\n",
      "Epoch 42/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.4860 - acc: 0.8660 - val_loss: 4.2843 - val_acc: 0.3022\n",
      "Epoch 43/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.4355 - acc: 0.8845 - val_loss: 4.3340 - val_acc: 0.2932\n",
      "Epoch 44/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.4315 - acc: 0.8829 - val_loss: 4.3978 - val_acc: 0.2716\n",
      "Epoch 45/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.3973 - acc: 0.8937 - val_loss: 4.3048 - val_acc: 0.3345\n",
      "Epoch 46/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.4276 - acc: 0.8776 - val_loss: 4.1312 - val_acc: 0.3255\n",
      "Epoch 47/300\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.3711 - acc: 0.9057 - val_loss: 4.2358 - val_acc: 0.3219\n",
      "Epoch 48/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.3799 - acc: 0.8949 - val_loss: 4.6685 - val_acc: 0.2824\n",
      "Epoch 49/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.3641 - acc: 0.9026 - val_loss: 4.4787 - val_acc: 0.3165\n",
      "Epoch 50/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.3582 - acc: 0.9041 - val_loss: 4.7320 - val_acc: 0.2860\n",
      "Epoch 51/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.3381 - acc: 0.9103 - val_loss: 4.8163 - val_acc: 0.3183\n",
      "Epoch 52/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.3374 - acc: 0.9037 - val_loss: 5.2396 - val_acc: 0.2266\n",
      "Epoch 53/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.3013 - acc: 0.9241 - val_loss: 4.8634 - val_acc: 0.2968\n",
      "Epoch 54/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.3169 - acc: 0.9114 - val_loss: 4.3783 - val_acc: 0.3237\n",
      "Epoch 55/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2918 - acc: 0.9157 - val_loss: 5.2519 - val_acc: 0.2914\n",
      "Epoch 56/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2840 - acc: 0.9191 - val_loss: 4.5505 - val_acc: 0.3058\n",
      "Epoch 57/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2717 - acc: 0.9276 - val_loss: 4.6562 - val_acc: 0.3076\n",
      "Epoch 58/300\n",
      "2597/2597 [==============================] - 6s 3ms/step - loss: 0.2792 - acc: 0.9172 - val_loss: 4.6552 - val_acc: 0.3219\n",
      "Epoch 59/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2687 - acc: 0.9257 - val_loss: 4.5158 - val_acc: 0.3219\n",
      "Epoch 60/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2514 - acc: 0.9249 - val_loss: 4.8451 - val_acc: 0.3022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2726 - acc: 0.9261 - val_loss: 5.2468 - val_acc: 0.3058\n",
      "Epoch 62/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2464 - acc: 0.9353 - val_loss: 5.3299 - val_acc: 0.2860\n",
      "Epoch 63/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2417 - acc: 0.9291 - val_loss: 4.6059 - val_acc: 0.3112\n",
      "Epoch 64/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2339 - acc: 0.9411 - val_loss: 4.8825 - val_acc: 0.2950\n",
      "Epoch 65/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2180 - acc: 0.9415 - val_loss: 5.0116 - val_acc: 0.2860\n",
      "Epoch 66/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2275 - acc: 0.9330 - val_loss: 4.9965 - val_acc: 0.3255\n",
      "Epoch 67/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2097 - acc: 0.9426 - val_loss: 4.8323 - val_acc: 0.2986\n",
      "Epoch 68/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2441 - acc: 0.9342 - val_loss: 4.8114 - val_acc: 0.3129\n",
      "Epoch 69/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1921 - acc: 0.9496 - val_loss: 5.5164 - val_acc: 0.2932\n",
      "Epoch 70/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2070 - acc: 0.9461 - val_loss: 5.1207 - val_acc: 0.3112\n",
      "Epoch 71/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.2128 - acc: 0.9422 - val_loss: 4.8573 - val_acc: 0.3453\n",
      "Epoch 72/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1657 - acc: 0.9573 - val_loss: 5.0309 - val_acc: 0.3165\n",
      "Epoch 73/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1988 - acc: 0.9430 - val_loss: 5.7169 - val_acc: 0.2806\n",
      "Epoch 74/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1870 - acc: 0.9472 - val_loss: 4.8851 - val_acc: 0.3183\n",
      "Epoch 75/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1755 - acc: 0.9542 - val_loss: 5.0964 - val_acc: 0.3094\n",
      "Epoch 76/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1966 - acc: 0.9415 - val_loss: 5.4120 - val_acc: 0.3112\n",
      "Epoch 77/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1731 - acc: 0.9499 - val_loss: 5.5646 - val_acc: 0.3058\n",
      "Epoch 78/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1747 - acc: 0.9557 - val_loss: 5.4528 - val_acc: 0.3345\n",
      "Epoch 79/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1861 - acc: 0.9469 - val_loss: 5.4613 - val_acc: 0.2986\n",
      "Epoch 80/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1572 - acc: 0.9557 - val_loss: 5.0822 - val_acc: 0.3147\n",
      "Epoch 81/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1429 - acc: 0.9603 - val_loss: 5.2284 - val_acc: 0.2968\n",
      "Epoch 82/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1647 - acc: 0.9511 - val_loss: 5.1197 - val_acc: 0.3327\n",
      "Epoch 83/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1787 - acc: 0.9526 - val_loss: 5.2422 - val_acc: 0.3129\n",
      "Epoch 84/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1508 - acc: 0.9573 - val_loss: 6.0012 - val_acc: 0.2770\n",
      "Epoch 85/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1376 - acc: 0.9611 - val_loss: 5.4351 - val_acc: 0.3112\n",
      "Epoch 86/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1379 - acc: 0.9638 - val_loss: 5.6290 - val_acc: 0.2788\n",
      "Epoch 87/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1516 - acc: 0.9576 - val_loss: 5.6580 - val_acc: 0.3165\n",
      "Epoch 88/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1502 - acc: 0.9565 - val_loss: 5.6648 - val_acc: 0.3022\n",
      "Epoch 89/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1283 - acc: 0.9657 - val_loss: 5.8097 - val_acc: 0.3004\n",
      "Epoch 90/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1603 - acc: 0.9484 - val_loss: 5.2555 - val_acc: 0.3291\n",
      "Epoch 91/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1433 - acc: 0.9603 - val_loss: 5.8462 - val_acc: 0.2788\n",
      "Epoch 92/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1074 - acc: 0.9704 - val_loss: 5.4819 - val_acc: 0.3219\n",
      "Epoch 93/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1384 - acc: 0.9549 - val_loss: 6.0101 - val_acc: 0.3004\n",
      "Epoch 94/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1334 - acc: 0.9634 - val_loss: 5.7780 - val_acc: 0.3022\n",
      "Epoch 95/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1514 - acc: 0.9573 - val_loss: 5.2347 - val_acc: 0.3489\n",
      "Epoch 96/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1408 - acc: 0.9611 - val_loss: 5.3507 - val_acc: 0.3237\n",
      "Epoch 97/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1114 - acc: 0.9669 - val_loss: 5.9317 - val_acc: 0.2572\n",
      "Epoch 98/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1417 - acc: 0.9619 - val_loss: 5.7757 - val_acc: 0.2950\n",
      "Epoch 99/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1285 - acc: 0.9600 - val_loss: 5.6334 - val_acc: 0.3147\n",
      "Epoch 100/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1046 - acc: 0.9696 - val_loss: 5.4960 - val_acc: 0.2914\n",
      "Epoch 101/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1230 - acc: 0.9638 - val_loss: 5.8956 - val_acc: 0.2968\n",
      "Epoch 102/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1263 - acc: 0.9638 - val_loss: 5.6878 - val_acc: 0.3040\n",
      "Epoch 103/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1173 - acc: 0.9665 - val_loss: 6.0219 - val_acc: 0.2932\n",
      "Epoch 104/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1307 - acc: 0.9650 - val_loss: 5.6800 - val_acc: 0.3058\n",
      "Epoch 105/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0999 - acc: 0.9715 - val_loss: 5.8108 - val_acc: 0.3129\n",
      "Epoch 106/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.1105 - acc: 0.9704 - val_loss: 5.6130 - val_acc: 0.3022\n",
      "Epoch 107/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0950 - acc: 0.9742 - val_loss: 6.0842 - val_acc: 0.2842\n",
      "Epoch 108/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1291 - acc: 0.9623 - val_loss: 5.6686 - val_acc: 0.3183\n",
      "Epoch 109/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.1003 - acc: 0.9723 - val_loss: 5.5430 - val_acc: 0.3058\n",
      "Epoch 110/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.1238 - acc: 0.9623 - val_loss: 5.6656 - val_acc: 0.3219\n",
      "Epoch 111/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1071 - acc: 0.9665 - val_loss: 5.8028 - val_acc: 0.3399\n",
      "Epoch 112/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.1196 - acc: 0.9619 - val_loss: 6.6990 - val_acc: 0.2734\n",
      "Epoch 113/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0959 - acc: 0.9765 - val_loss: 6.0137 - val_acc: 0.3129\n",
      "Epoch 114/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0977 - acc: 0.9673 - val_loss: 5.8242 - val_acc: 0.3417\n",
      "Epoch 115/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0834 - acc: 0.9769 - val_loss: 5.9630 - val_acc: 0.3309\n",
      "Epoch 116/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0875 - acc: 0.9750 - val_loss: 6.5598 - val_acc: 0.2644\n",
      "Epoch 117/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0911 - acc: 0.9727 - val_loss: 5.9385 - val_acc: 0.3165\n",
      "Epoch 118/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1021 - acc: 0.9723 - val_loss: 6.2570 - val_acc: 0.3004\n",
      "Epoch 119/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.1188 - acc: 0.9657 - val_loss: 5.9764 - val_acc: 0.3201\n",
      "Epoch 120/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0818 - acc: 0.9773 - val_loss: 6.0080 - val_acc: 0.3094\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.1041 - acc: 0.9700 - val_loss: 5.7984 - val_acc: 0.2950\n",
      "Epoch 122/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0992 - acc: 0.9715 - val_loss: 5.8231 - val_acc: 0.3291\n",
      "Epoch 123/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0793 - acc: 0.9800 - val_loss: 6.4616 - val_acc: 0.2842\n",
      "Epoch 124/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0869 - acc: 0.9754 - val_loss: 5.9224 - val_acc: 0.3147\n",
      "Epoch 125/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0895 - acc: 0.9707 - val_loss: 6.2287 - val_acc: 0.2824\n",
      "Epoch 126/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0812 - acc: 0.9761 - val_loss: 6.8664 - val_acc: 0.2878\n",
      "Epoch 127/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0984 - acc: 0.9761 - val_loss: 6.1503 - val_acc: 0.2662\n",
      "Epoch 128/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0941 - acc: 0.9730 - val_loss: 6.0235 - val_acc: 0.3040\n",
      "Epoch 129/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.1238 - acc: 0.9623 - val_loss: 5.9684 - val_acc: 0.3147\n",
      "Epoch 130/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0982 - acc: 0.9723 - val_loss: 6.4097 - val_acc: 0.2788\n",
      "Epoch 131/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0700 - acc: 0.9838 - val_loss: 5.8493 - val_acc: 0.3004\n",
      "Epoch 132/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0883 - acc: 0.9734 - val_loss: 5.9366 - val_acc: 0.3022\n",
      "Epoch 133/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0702 - acc: 0.9761 - val_loss: 6.2094 - val_acc: 0.3129\n",
      "Epoch 134/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0972 - acc: 0.9692 - val_loss: 5.9955 - val_acc: 0.3094\n",
      "Epoch 135/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0807 - acc: 0.9738 - val_loss: 6.1142 - val_acc: 0.2986\n",
      "Epoch 136/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0834 - acc: 0.9769 - val_loss: 6.2449 - val_acc: 0.3058\n",
      "Epoch 137/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0813 - acc: 0.9750 - val_loss: 6.1296 - val_acc: 0.3129\n",
      "Epoch 138/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0924 - acc: 0.9757 - val_loss: 6.2156 - val_acc: 0.3040\n",
      "Epoch 139/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0806 - acc: 0.9777 - val_loss: 6.3066 - val_acc: 0.2896\n",
      "Epoch 140/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0687 - acc: 0.9792 - val_loss: 6.5361 - val_acc: 0.3183\n",
      "Epoch 141/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0909 - acc: 0.9727 - val_loss: 6.3287 - val_acc: 0.2950\n",
      "Epoch 142/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0761 - acc: 0.9757 - val_loss: 6.2677 - val_acc: 0.2914\n",
      "Epoch 143/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0821 - acc: 0.9738 - val_loss: 6.2824 - val_acc: 0.2842\n",
      "Epoch 144/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0697 - acc: 0.9819 - val_loss: 5.9236 - val_acc: 0.3201\n",
      "Epoch 145/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0768 - acc: 0.9730 - val_loss: 6.1627 - val_acc: 0.3201\n",
      "Epoch 146/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0742 - acc: 0.9777 - val_loss: 6.2658 - val_acc: 0.3004\n",
      "Epoch 147/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0890 - acc: 0.9738 - val_loss: 5.8093 - val_acc: 0.3471\n",
      "Epoch 148/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0773 - acc: 0.9765 - val_loss: 6.1907 - val_acc: 0.2878\n",
      "Epoch 149/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0687 - acc: 0.9788 - val_loss: 6.3350 - val_acc: 0.2914\n",
      "Epoch 150/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.1024 - acc: 0.9677 - val_loss: 6.1417 - val_acc: 0.3058\n",
      "Epoch 151/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0742 - acc: 0.9792 - val_loss: 6.9220 - val_acc: 0.3094\n",
      "Epoch 152/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0684 - acc: 0.9800 - val_loss: 6.8662 - val_acc: 0.2770\n",
      "Epoch 153/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0698 - acc: 0.9804 - val_loss: 6.0730 - val_acc: 0.3129\n",
      "Epoch 154/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0773 - acc: 0.9781 - val_loss: 6.7210 - val_acc: 0.2878\n",
      "Epoch 155/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0632 - acc: 0.9807 - val_loss: 6.2159 - val_acc: 0.3129\n",
      "Epoch 156/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0699 - acc: 0.9800 - val_loss: 6.2041 - val_acc: 0.3183\n",
      "Epoch 157/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0755 - acc: 0.9765 - val_loss: 6.0022 - val_acc: 0.3309\n",
      "Epoch 158/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0745 - acc: 0.9804 - val_loss: 6.3295 - val_acc: 0.3219\n",
      "Epoch 159/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0775 - acc: 0.9773 - val_loss: 6.1085 - val_acc: 0.3219\n",
      "Epoch 160/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0683 - acc: 0.9807 - val_loss: 6.8953 - val_acc: 0.2662\n",
      "Epoch 161/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0660 - acc: 0.9827 - val_loss: 7.3571 - val_acc: 0.2770\n",
      "Epoch 162/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0629 - acc: 0.9819 - val_loss: 6.0948 - val_acc: 0.3345\n",
      "Epoch 163/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0793 - acc: 0.9796 - val_loss: 6.1594 - val_acc: 0.3129\n",
      "Epoch 164/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0607 - acc: 0.9823 - val_loss: 6.2472 - val_acc: 0.3219\n",
      "Epoch 165/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0697 - acc: 0.9796 - val_loss: 6.7008 - val_acc: 0.2626\n",
      "Epoch 166/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0809 - acc: 0.9750 - val_loss: 6.6044 - val_acc: 0.2914\n",
      "Epoch 167/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0692 - acc: 0.9800 - val_loss: 6.2720 - val_acc: 0.3094\n",
      "Epoch 168/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0856 - acc: 0.9719 - val_loss: 6.3553 - val_acc: 0.3058\n",
      "Epoch 169/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0537 - acc: 0.9846 - val_loss: 6.1739 - val_acc: 0.3040\n",
      "Epoch 170/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0662 - acc: 0.9792 - val_loss: 6.4946 - val_acc: 0.3094\n",
      "Epoch 171/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0641 - acc: 0.9804 - val_loss: 6.1967 - val_acc: 0.3165\n",
      "Epoch 172/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0782 - acc: 0.9765 - val_loss: 6.4130 - val_acc: 0.3183\n",
      "Epoch 173/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0600 - acc: 0.9819 - val_loss: 6.2273 - val_acc: 0.3147\n",
      "Epoch 174/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0809 - acc: 0.9746 - val_loss: 6.0918 - val_acc: 0.3525\n",
      "Epoch 175/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0596 - acc: 0.9823 - val_loss: 6.3797 - val_acc: 0.3094\n",
      "Epoch 176/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0815 - acc: 0.9781 - val_loss: 6.6746 - val_acc: 0.2914\n",
      "Epoch 177/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0682 - acc: 0.9788 - val_loss: 5.8863 - val_acc: 0.3345\n",
      "Epoch 178/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0587 - acc: 0.9819 - val_loss: 6.1083 - val_acc: 0.2968\n",
      "Epoch 179/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0539 - acc: 0.9827 - val_loss: 6.0779 - val_acc: 0.3219\n",
      "Epoch 180/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0647 - acc: 0.9792 - val_loss: 6.3596 - val_acc: 0.3112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0429 - acc: 0.9873 - val_loss: 6.2259 - val_acc: 0.3076\n",
      "Epoch 182/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0705 - acc: 0.9796 - val_loss: 6.4612 - val_acc: 0.3147\n",
      "Epoch 183/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0540 - acc: 0.9877 - val_loss: 6.2568 - val_acc: 0.3129\n",
      "Epoch 184/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0516 - acc: 0.9854 - val_loss: 6.8037 - val_acc: 0.2878\n",
      "Epoch 185/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0704 - acc: 0.9831 - val_loss: 6.3298 - val_acc: 0.3219\n",
      "Epoch 186/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0641 - acc: 0.9834 - val_loss: 6.4419 - val_acc: 0.3129\n",
      "Epoch 187/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0572 - acc: 0.9823 - val_loss: 6.3840 - val_acc: 0.3129\n",
      "Epoch 188/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0720 - acc: 0.9788 - val_loss: 6.5001 - val_acc: 0.2842\n",
      "Epoch 189/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0580 - acc: 0.9834 - val_loss: 6.3278 - val_acc: 0.3040\n",
      "Epoch 190/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0553 - acc: 0.9846 - val_loss: 6.6751 - val_acc: 0.3076\n",
      "Epoch 191/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0657 - acc: 0.9792 - val_loss: 6.3406 - val_acc: 0.2968\n",
      "Epoch 192/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0698 - acc: 0.9769 - val_loss: 7.4928 - val_acc: 0.2536\n",
      "Epoch 193/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0581 - acc: 0.9815 - val_loss: 6.1911 - val_acc: 0.3165\n",
      "Epoch 194/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0494 - acc: 0.9858 - val_loss: 6.2234 - val_acc: 0.3147\n",
      "Epoch 195/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0627 - acc: 0.9800 - val_loss: 6.1933 - val_acc: 0.3273\n",
      "Epoch 196/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0675 - acc: 0.9800 - val_loss: 6.5973 - val_acc: 0.2950\n",
      "Epoch 197/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0563 - acc: 0.9807 - val_loss: 6.5937 - val_acc: 0.3165\n",
      "Epoch 198/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0540 - acc: 0.9842 - val_loss: 6.3406 - val_acc: 0.3219\n",
      "Epoch 199/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0582 - acc: 0.9811 - val_loss: 6.4078 - val_acc: 0.3022\n",
      "Epoch 200/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0590 - acc: 0.9815 - val_loss: 6.7744 - val_acc: 0.3058\n",
      "Epoch 201/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0569 - acc: 0.9815 - val_loss: 6.4724 - val_acc: 0.2968\n",
      "Epoch 202/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0643 - acc: 0.9784 - val_loss: 6.5493 - val_acc: 0.2896\n",
      "Epoch 203/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0644 - acc: 0.9815 - val_loss: 6.5037 - val_acc: 0.3094\n",
      "Epoch 204/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0568 - acc: 0.9831 - val_loss: 6.4206 - val_acc: 0.3255\n",
      "Epoch 205/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0478 - acc: 0.9858 - val_loss: 6.3589 - val_acc: 0.3255\n",
      "Epoch 206/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0389 - acc: 0.9911 - val_loss: 6.4344 - val_acc: 0.3237\n",
      "Epoch 207/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0560 - acc: 0.9842 - val_loss: 6.8826 - val_acc: 0.3004\n",
      "Epoch 208/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0629 - acc: 0.9842 - val_loss: 6.5128 - val_acc: 0.3147\n",
      "Epoch 209/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0616 - acc: 0.9811 - val_loss: 6.3410 - val_acc: 0.3309\n",
      "Epoch 210/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0539 - acc: 0.9815 - val_loss: 6.4898 - val_acc: 0.3183\n",
      "Epoch 211/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0590 - acc: 0.9807 - val_loss: 6.5416 - val_acc: 0.3363\n",
      "Epoch 212/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0454 - acc: 0.9873 - val_loss: 6.9029 - val_acc: 0.2806\n",
      "Epoch 213/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0506 - acc: 0.9834 - val_loss: 6.7393 - val_acc: 0.3058\n",
      "Epoch 214/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0676 - acc: 0.9804 - val_loss: 6.7550 - val_acc: 0.3040\n",
      "Epoch 215/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0439 - acc: 0.9861 - val_loss: 6.5212 - val_acc: 0.3309\n",
      "Epoch 216/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0630 - acc: 0.9834 - val_loss: 6.6546 - val_acc: 0.3058\n",
      "Epoch 217/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0456 - acc: 0.9846 - val_loss: 6.6078 - val_acc: 0.3219\n",
      "Epoch 218/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0630 - acc: 0.9831 - val_loss: 6.2896 - val_acc: 0.3309\n",
      "Epoch 219/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0488 - acc: 0.9861 - val_loss: 6.7557 - val_acc: 0.3004\n",
      "Epoch 220/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0495 - acc: 0.9854 - val_loss: 6.4941 - val_acc: 0.3273\n",
      "Epoch 221/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0601 - acc: 0.9831 - val_loss: 6.8896 - val_acc: 0.3004\n",
      "Epoch 222/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0477 - acc: 0.9869 - val_loss: 6.4830 - val_acc: 0.2986\n",
      "Epoch 223/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0501 - acc: 0.9834 - val_loss: 7.2851 - val_acc: 0.2770\n",
      "Epoch 224/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0705 - acc: 0.9781 - val_loss: 6.3437 - val_acc: 0.3004\n",
      "Epoch 225/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0623 - acc: 0.9788 - val_loss: 6.5796 - val_acc: 0.2968\n",
      "Epoch 226/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0310 - acc: 0.9896 - val_loss: 6.6143 - val_acc: 0.3076\n",
      "Epoch 227/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0336 - acc: 0.9892 - val_loss: 6.7904 - val_acc: 0.3147\n",
      "Epoch 228/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0541 - acc: 0.9796 - val_loss: 7.0132 - val_acc: 0.2896\n",
      "Epoch 229/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0476 - acc: 0.9865 - val_loss: 6.2885 - val_acc: 0.3399\n",
      "Epoch 230/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0453 - acc: 0.9865 - val_loss: 6.8605 - val_acc: 0.2734\n",
      "Epoch 231/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0491 - acc: 0.9838 - val_loss: 6.6272 - val_acc: 0.3076\n",
      "Epoch 232/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0482 - acc: 0.9861 - val_loss: 6.7560 - val_acc: 0.3273\n",
      "Epoch 233/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0499 - acc: 0.9861 - val_loss: 6.3924 - val_acc: 0.3201\n",
      "Epoch 234/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0631 - acc: 0.9823 - val_loss: 6.5865 - val_acc: 0.3058\n",
      "Epoch 235/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0494 - acc: 0.9834 - val_loss: 6.2908 - val_acc: 0.3327\n",
      "Epoch 236/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0401 - acc: 0.9900 - val_loss: 6.8937 - val_acc: 0.2824\n",
      "Epoch 237/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0452 - acc: 0.9842 - val_loss: 6.3862 - val_acc: 0.3435\n",
      "Epoch 238/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0527 - acc: 0.9827 - val_loss: 6.4999 - val_acc: 0.3255\n",
      "Epoch 239/300\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0376 - acc: 0.9888 - val_loss: 6.5003 - val_acc: 0.3489\n",
      "Epoch 240/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0562 - acc: 0.9846 - val_loss: 6.8089 - val_acc: 0.3094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0571 - acc: 0.9811 - val_loss: 6.4836 - val_acc: 0.3076\n",
      "Epoch 242/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0390 - acc: 0.9884 - val_loss: 6.6966 - val_acc: 0.3183\n",
      "Epoch 243/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0287 - acc: 0.9908 - val_loss: 7.0228 - val_acc: 0.2914\n",
      "Epoch 244/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0424 - acc: 0.9892 - val_loss: 6.4495 - val_acc: 0.3219\n",
      "Epoch 245/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0557 - acc: 0.9819 - val_loss: 6.6793 - val_acc: 0.3237\n",
      "Epoch 246/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0405 - acc: 0.9892 - val_loss: 6.5791 - val_acc: 0.3147\n",
      "Epoch 247/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0596 - acc: 0.9796 - val_loss: 6.8326 - val_acc: 0.2914\n",
      "Epoch 248/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0479 - acc: 0.9854 - val_loss: 6.8542 - val_acc: 0.3022\n",
      "Epoch 249/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0437 - acc: 0.9869 - val_loss: 7.4897 - val_acc: 0.2806\n",
      "Epoch 250/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0429 - acc: 0.9858 - val_loss: 6.5530 - val_acc: 0.2968\n",
      "Epoch 251/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0361 - acc: 0.9896 - val_loss: 6.1134 - val_acc: 0.3435\n",
      "Epoch 252/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0615 - acc: 0.9842 - val_loss: 6.3629 - val_acc: 0.3507\n",
      "Epoch 253/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0360 - acc: 0.9900 - val_loss: 6.5547 - val_acc: 0.3040\n",
      "Epoch 254/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0476 - acc: 0.9861 - val_loss: 6.6822 - val_acc: 0.3076\n",
      "Epoch 255/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0517 - acc: 0.9819 - val_loss: 6.6140 - val_acc: 0.2986\n",
      "Epoch 256/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0299 - acc: 0.9923 - val_loss: 6.7715 - val_acc: 0.3165\n",
      "Epoch 257/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0440 - acc: 0.9892 - val_loss: 6.3451 - val_acc: 0.3201\n",
      "Epoch 258/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0465 - acc: 0.9846 - val_loss: 6.3648 - val_acc: 0.3291\n",
      "Epoch 259/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0429 - acc: 0.9865 - val_loss: 6.4319 - val_acc: 0.3507\n",
      "Epoch 260/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0402 - acc: 0.9884 - val_loss: 6.9643 - val_acc: 0.3201\n",
      "Epoch 261/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0401 - acc: 0.9865 - val_loss: 6.4861 - val_acc: 0.3255\n",
      "Epoch 262/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0536 - acc: 0.9827 - val_loss: 6.4801 - val_acc: 0.3291\n",
      "Epoch 263/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0503 - acc: 0.9865 - val_loss: 6.7943 - val_acc: 0.3255\n",
      "Epoch 264/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0337 - acc: 0.9923 - val_loss: 6.8074 - val_acc: 0.3147\n",
      "Epoch 265/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0430 - acc: 0.9854 - val_loss: 6.6294 - val_acc: 0.3291\n",
      "Epoch 266/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0371 - acc: 0.9884 - val_loss: 6.6626 - val_acc: 0.3237\n",
      "Epoch 267/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0570 - acc: 0.9815 - val_loss: 6.5654 - val_acc: 0.3237\n",
      "Epoch 268/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0379 - acc: 0.9884 - val_loss: 6.6106 - val_acc: 0.3094\n",
      "Epoch 269/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0481 - acc: 0.9858 - val_loss: 6.4959 - val_acc: 0.3327\n",
      "Epoch 270/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0463 - acc: 0.9865 - val_loss: 6.6364 - val_acc: 0.2914\n",
      "Epoch 271/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0286 - acc: 0.9931 - val_loss: 6.8062 - val_acc: 0.3094\n",
      "Epoch 272/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0322 - acc: 0.9911 - val_loss: 6.5128 - val_acc: 0.3022\n",
      "Epoch 273/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0510 - acc: 0.9804 - val_loss: 6.6767 - val_acc: 0.3022\n",
      "Epoch 274/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0313 - acc: 0.9915 - val_loss: 6.9843 - val_acc: 0.2968\n",
      "Epoch 275/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0545 - acc: 0.9842 - val_loss: 6.8190 - val_acc: 0.3165\n",
      "Epoch 276/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0443 - acc: 0.9888 - val_loss: 6.8774 - val_acc: 0.2986\n",
      "Epoch 277/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0250 - acc: 0.9927 - val_loss: 6.9358 - val_acc: 0.2932\n",
      "Epoch 278/300\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0489 - acc: 0.9842 - val_loss: 6.6086 - val_acc: 0.3273\n",
      "Epoch 279/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0465 - acc: 0.9873 - val_loss: 7.2653 - val_acc: 0.2896\n",
      "Epoch 280/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 6.8003 - val_acc: 0.3129\n",
      "Epoch 281/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0353 - acc: 0.9896 - val_loss: 6.7522 - val_acc: 0.3129\n",
      "Epoch 282/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0599 - acc: 0.9834 - val_loss: 6.7533 - val_acc: 0.3237\n",
      "Epoch 283/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0432 - acc: 0.9858 - val_loss: 6.8396 - val_acc: 0.3058\n",
      "Epoch 284/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0312 - acc: 0.9923 - val_loss: 6.6287 - val_acc: 0.3219\n",
      "Epoch 285/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0265 - acc: 0.9923 - val_loss: 6.8350 - val_acc: 0.3076\n",
      "Epoch 286/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0333 - acc: 0.9892 - val_loss: 6.9178 - val_acc: 0.2950\n",
      "Epoch 287/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0328 - acc: 0.9900 - val_loss: 6.7694 - val_acc: 0.3112\n",
      "Epoch 288/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0412 - acc: 0.9877 - val_loss: 6.8663 - val_acc: 0.3183\n",
      "Epoch 289/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0436 - acc: 0.9858 - val_loss: 6.4824 - val_acc: 0.3363\n",
      "Epoch 290/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0296 - acc: 0.9900 - val_loss: 6.5634 - val_acc: 0.3363\n",
      "Epoch 291/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0406 - acc: 0.9884 - val_loss: 6.8634 - val_acc: 0.3219\n",
      "Epoch 292/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0327 - acc: 0.9900 - val_loss: 6.7120 - val_acc: 0.3237\n",
      "Epoch 293/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0454 - acc: 0.9823 - val_loss: 6.8088 - val_acc: 0.3147\n",
      "Epoch 294/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0309 - acc: 0.9911 - val_loss: 7.2490 - val_acc: 0.3094\n",
      "Epoch 295/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0409 - acc: 0.9888 - val_loss: 6.6389 - val_acc: 0.3273\n",
      "Epoch 296/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0370 - acc: 0.9919 - val_loss: 6.6918 - val_acc: 0.3255\n",
      "Epoch 297/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0534 - acc: 0.9819 - val_loss: 6.7551 - val_acc: 0.3147\n",
      "Epoch 298/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0402 - acc: 0.9865 - val_loss: 6.7045 - val_acc: 0.3273\n",
      "Epoch 299/300\n",
      "2597/2597 [==============================] - 5s 2ms/step - loss: 0.0428 - acc: 0.9865 - val_loss: 6.8567 - val_acc: 0.3219\n",
      "Epoch 300/300\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.0356 - acc: 0.9884 - val_loss: 6.8843 - val_acc: 0.3022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83083e3668>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=300,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 0s 680us/step\n",
      "[6.590025870975515, 0.2962298025402175]\n"
     ]
    }
   ],
   "source": [
    "conv_result = conv_model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(conv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_32 (Conv1D)           (None, 40, 40)            55400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 40, 40)            160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 40, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 40, 28)            7728      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40, 173)           5017      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 40, 173)           692       \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 40, 40)            55400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 40, 40)            160       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 41)                1681      \n",
      "=================================================================\n",
      "Total params: 126,238\n",
      "Trainable params: 125,732\n",
      "Non-trainable params: 506\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model2 = Sequential([\n",
    "    Convolution1D(40,8, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(1),\n",
    "    \n",
    "    LSTM(28, return_sequences=True, input_shape=(40,40)),\n",
    "    Dense(173, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "     \n",
    "    Convolution1D(40,8, padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.1),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "print (conv_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 3.2264 - acc: 0.1640 - val_loss: 2.8387 - val_acc: 0.2374\n",
      "Epoch 2/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 2.7393 - acc: 0.2622 - val_loss: 2.6515 - val_acc: 0.2698\n",
      "Epoch 3/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 2.4573 - acc: 0.3462 - val_loss: 2.4616 - val_acc: 0.3381\n",
      "Epoch 4/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 2.2366 - acc: 0.4043 - val_loss: 2.4390 - val_acc: 0.3525\n",
      "Epoch 5/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 2.0479 - acc: 0.4571 - val_loss: 2.2628 - val_acc: 0.3813\n",
      "Epoch 6/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 1.8774 - acc: 0.5010 - val_loss: 2.1837 - val_acc: 0.3957\n",
      "Epoch 7/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 1.7333 - acc: 0.5314 - val_loss: 2.1554 - val_acc: 0.4191\n",
      "Epoch 8/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 1.6086 - acc: 0.5880 - val_loss: 2.1020 - val_acc: 0.4083\n",
      "Epoch 9/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 1.4944 - acc: 0.6099 - val_loss: 2.0659 - val_acc: 0.4299\n",
      "Epoch 10/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 1.3807 - acc: 0.6334 - val_loss: 2.0591 - val_acc: 0.4388\n",
      "Epoch 11/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 1.2543 - acc: 0.6700 - val_loss: 2.1262 - val_acc: 0.4371\n",
      "Epoch 12/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 1.1826 - acc: 0.6835 - val_loss: 2.1747 - val_acc: 0.4299\n",
      "Epoch 13/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 1.0696 - acc: 0.7170 - val_loss: 2.1294 - val_acc: 0.4281\n",
      "Epoch 14/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.9853 - acc: 0.7432 - val_loss: 2.1500 - val_acc: 0.4424\n",
      "Epoch 15/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.8942 - acc: 0.7590 - val_loss: 2.2352 - val_acc: 0.4424\n",
      "Epoch 16/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.8352 - acc: 0.7763 - val_loss: 2.3000 - val_acc: 0.4263\n",
      "Epoch 17/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.7729 - acc: 0.7990 - val_loss: 2.3275 - val_acc: 0.4371\n",
      "Epoch 18/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.7207 - acc: 0.8179 - val_loss: 2.4844 - val_acc: 0.4263\n",
      "Epoch 19/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.6428 - acc: 0.8348 - val_loss: 2.3755 - val_acc: 0.4406\n",
      "Epoch 20/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.6031 - acc: 0.8479 - val_loss: 2.3754 - val_acc: 0.4604\n",
      "Epoch 21/100\n",
      "2597/2597 [==============================] - 12s 4ms/step - loss: 0.5624 - acc: 0.8529 - val_loss: 2.4765 - val_acc: 0.4478\n",
      "Epoch 22/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.4960 - acc: 0.8756 - val_loss: 2.5023 - val_acc: 0.4227\n",
      "Epoch 23/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.4688 - acc: 0.8814 - val_loss: 2.5097 - val_acc: 0.4263\n",
      "Epoch 24/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.4316 - acc: 0.8956 - val_loss: 2.6714 - val_acc: 0.4424\n",
      "Epoch 25/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.3975 - acc: 0.8980 - val_loss: 2.7189 - val_acc: 0.4263\n",
      "Epoch 26/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.3862 - acc: 0.9010 - val_loss: 2.7409 - val_acc: 0.4478\n",
      "Epoch 27/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.3161 - acc: 0.9222 - val_loss: 2.8845 - val_acc: 0.4353\n",
      "Epoch 28/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.3150 - acc: 0.9134 - val_loss: 2.7873 - val_acc: 0.4388\n",
      "Epoch 29/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.3079 - acc: 0.9195 - val_loss: 2.9099 - val_acc: 0.4281\n",
      "Epoch 30/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.2554 - acc: 0.9376 - val_loss: 3.0254 - val_acc: 0.4263\n",
      "Epoch 31/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.2808 - acc: 0.9330 - val_loss: 2.9756 - val_acc: 0.4317\n",
      "Epoch 32/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.2312 - acc: 0.9461 - val_loss: 2.9505 - val_acc: 0.4281\n",
      "Epoch 33/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.2189 - acc: 0.9480 - val_loss: 3.2245 - val_acc: 0.4299\n",
      "Epoch 34/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.2181 - acc: 0.9457 - val_loss: 3.0629 - val_acc: 0.4353\n",
      "Epoch 35/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.1966 - acc: 0.9503 - val_loss: 3.1377 - val_acc: 0.4299\n",
      "Epoch 36/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1968 - acc: 0.9453 - val_loss: 3.1292 - val_acc: 0.4335\n",
      "Epoch 37/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.1855 - acc: 0.9515 - val_loss: 3.2308 - val_acc: 0.4353\n",
      "Epoch 38/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.1686 - acc: 0.9561 - val_loss: 3.2521 - val_acc: 0.4460\n",
      "Epoch 39/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.1807 - acc: 0.9523 - val_loss: 3.3244 - val_acc: 0.4478\n",
      "Epoch 40/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.1531 - acc: 0.9646 - val_loss: 3.2396 - val_acc: 0.4406\n",
      "Epoch 41/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1535 - acc: 0.9630 - val_loss: 3.2685 - val_acc: 0.4460\n",
      "Epoch 42/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.1663 - acc: 0.9553 - val_loss: 3.3168 - val_acc: 0.4460\n",
      "Epoch 43/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1501 - acc: 0.9657 - val_loss: 3.5217 - val_acc: 0.4137\n",
      "Epoch 44/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.1428 - acc: 0.9650 - val_loss: 3.3114 - val_acc: 0.4460\n",
      "Epoch 45/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1247 - acc: 0.9688 - val_loss: 3.3447 - val_acc: 0.4263\n",
      "Epoch 46/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1368 - acc: 0.9626 - val_loss: 3.6165 - val_acc: 0.4083\n",
      "Epoch 47/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.1115 - acc: 0.9742 - val_loss: 3.6122 - val_acc: 0.4245\n",
      "Epoch 48/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1188 - acc: 0.9696 - val_loss: 3.5613 - val_acc: 0.4442\n",
      "Epoch 49/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1468 - acc: 0.9661 - val_loss: 3.5030 - val_acc: 0.4676\n",
      "Epoch 50/100\n",
      "2597/2597 [==============================] - 12s 4ms/step - loss: 0.0977 - acc: 0.9788 - val_loss: 3.6512 - val_acc: 0.4622\n",
      "Epoch 51/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.1178 - acc: 0.9723 - val_loss: 3.6218 - val_acc: 0.4496\n",
      "Epoch 52/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.1282 - acc: 0.9669 - val_loss: 3.6359 - val_acc: 0.4424\n",
      "Epoch 53/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.1004 - acc: 0.9757 - val_loss: 3.6532 - val_acc: 0.4424\n",
      "Epoch 54/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0826 - acc: 0.9823 - val_loss: 3.5777 - val_acc: 0.4550\n",
      "Epoch 55/100\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.1164 - acc: 0.9673 - val_loss: 3.8435 - val_acc: 0.4263\n",
      "Epoch 56/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0926 - acc: 0.9719 - val_loss: 3.7580 - val_acc: 0.4442\n",
      "Epoch 57/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0889 - acc: 0.9788 - val_loss: 3.7160 - val_acc: 0.4317\n",
      "Epoch 58/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0884 - acc: 0.9777 - val_loss: 3.7946 - val_acc: 0.4496\n",
      "Epoch 59/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0965 - acc: 0.9757 - val_loss: 3.7559 - val_acc: 0.4514\n",
      "Epoch 60/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0840 - acc: 0.9761 - val_loss: 3.8230 - val_acc: 0.4478\n",
      "Epoch 61/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0835 - acc: 0.9754 - val_loss: 3.9782 - val_acc: 0.4353\n",
      "Epoch 62/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0866 - acc: 0.9738 - val_loss: 3.8508 - val_acc: 0.4496\n",
      "Epoch 63/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0833 - acc: 0.9761 - val_loss: 3.8693 - val_acc: 0.4640\n",
      "Epoch 64/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0671 - acc: 0.9827 - val_loss: 4.0242 - val_acc: 0.4640\n",
      "Epoch 65/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0904 - acc: 0.9746 - val_loss: 4.0157 - val_acc: 0.4496\n",
      "Epoch 66/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0714 - acc: 0.9827 - val_loss: 3.8835 - val_acc: 0.4406\n",
      "Epoch 67/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0996 - acc: 0.9746 - val_loss: 4.0726 - val_acc: 0.4317\n",
      "Epoch 68/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0805 - acc: 0.9761 - val_loss: 3.9158 - val_acc: 0.4514\n",
      "Epoch 69/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0730 - acc: 0.9792 - val_loss: 3.9669 - val_acc: 0.4119\n",
      "Epoch 70/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0771 - acc: 0.9807 - val_loss: 4.1888 - val_acc: 0.4550\n",
      "Epoch 71/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0896 - acc: 0.9777 - val_loss: 4.2225 - val_acc: 0.4442\n",
      "Epoch 72/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0567 - acc: 0.9842 - val_loss: 4.1952 - val_acc: 0.4442\n",
      "Epoch 73/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0707 - acc: 0.9754 - val_loss: 4.1981 - val_acc: 0.4478\n",
      "Epoch 74/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0787 - acc: 0.9792 - val_loss: 4.3327 - val_acc: 0.4388\n",
      "Epoch 75/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0699 - acc: 0.9788 - val_loss: 4.1862 - val_acc: 0.4245\n",
      "Epoch 76/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0588 - acc: 0.9869 - val_loss: 4.2951 - val_acc: 0.4101\n",
      "Epoch 77/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0672 - acc: 0.9796 - val_loss: 4.0383 - val_acc: 0.4317\n",
      "Epoch 78/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0823 - acc: 0.9761 - val_loss: 4.3021 - val_acc: 0.4281\n",
      "Epoch 79/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0600 - acc: 0.9823 - val_loss: 4.3544 - val_acc: 0.4335\n",
      "Epoch 80/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.0646 - acc: 0.9781 - val_loss: 4.4140 - val_acc: 0.4173\n",
      "Epoch 81/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0627 - acc: 0.9819 - val_loss: 4.3426 - val_acc: 0.4155\n",
      "Epoch 82/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0635 - acc: 0.9800 - val_loss: 4.1972 - val_acc: 0.4137\n",
      "Epoch 83/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0803 - acc: 0.9765 - val_loss: 4.2034 - val_acc: 0.4317\n",
      "Epoch 84/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.0549 - acc: 0.9846 - val_loss: 4.0827 - val_acc: 0.4604\n",
      "Epoch 85/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0577 - acc: 0.9846 - val_loss: 4.0902 - val_acc: 0.4622\n",
      "Epoch 86/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.0605 - acc: 0.9842 - val_loss: 4.5578 - val_acc: 0.3957\n",
      "Epoch 87/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0575 - acc: 0.9877 - val_loss: 4.6501 - val_acc: 0.4209\n",
      "Epoch 88/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0490 - acc: 0.9858 - val_loss: 4.2377 - val_acc: 0.4604\n",
      "Epoch 89/100\n",
      "2597/2597 [==============================] - 12s 4ms/step - loss: 0.0430 - acc: 0.9896 - val_loss: 4.2486 - val_acc: 0.4496\n",
      "Epoch 90/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0664 - acc: 0.9831 - val_loss: 4.3052 - val_acc: 0.4478\n",
      "Epoch 91/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0638 - acc: 0.9831 - val_loss: 4.3043 - val_acc: 0.4424\n",
      "Epoch 92/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0432 - acc: 0.9911 - val_loss: 4.2392 - val_acc: 0.4604\n",
      "Epoch 93/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0474 - acc: 0.9881 - val_loss: 4.4214 - val_acc: 0.4317\n",
      "Epoch 94/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0541 - acc: 0.9854 - val_loss: 4.5855 - val_acc: 0.4047\n",
      "Epoch 95/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0681 - acc: 0.9819 - val_loss: 4.3868 - val_acc: 0.4388\n",
      "Epoch 96/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0640 - acc: 0.9807 - val_loss: 4.3545 - val_acc: 0.4514\n",
      "Epoch 97/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0377 - acc: 0.9900 - val_loss: 4.3551 - val_acc: 0.4424\n",
      "Epoch 98/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0629 - acc: 0.9811 - val_loss: 4.2743 - val_acc: 0.4353\n",
      "Epoch 99/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0546 - acc: 0.9834 - val_loss: 4.5855 - val_acc: 0.4496\n",
      "Epoch 100/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0553 - acc: 0.9819 - val_loss: 4.5710 - val_acc: 0.4281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8303346278>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model2.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=100,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 1ms/step\n",
      "[4.6556819970560674, 0.4452423703199657]\n"
     ]
    }
   ],
   "source": [
    "conv_result2 = conv_model2.evaluate(x_test, y_test, batch_size=128)\n",
    "print(conv_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 40, 80)            110800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 40, 80)            320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 13, 80)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 13, 140)           84560     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 13, 173)           24393     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 13, 173)           692       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 13, 80)            110800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 13, 80)            320       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 41)                3321      \n",
      "=================================================================\n",
      "Total params: 335,206\n",
      "Trainable params: 334,540\n",
      "Non-trainable params: 666\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model3 = Sequential([\n",
    "    Convolution1D(80,8, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(70, return_sequences=True)),\n",
    "    Dense(173, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "     \n",
    "    Convolution1D(80,8, padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.1),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print (conv_model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 2.7914 - acc: 0.2553 - val_loss: 2.3482 - val_acc: 0.3597\n",
      "Epoch 2/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 1.9271 - acc: 0.4740 - val_loss: 2.1050 - val_acc: 0.4281\n",
      "Epoch 3/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 1.4691 - acc: 0.6092 - val_loss: 1.8660 - val_acc: 0.4784\n",
      "Epoch 4/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 1.1778 - acc: 0.6777 - val_loss: 1.8322 - val_acc: 0.4982\n",
      "Epoch 5/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.9020 - acc: 0.7636 - val_loss: 1.7648 - val_acc: 0.5576\n",
      "Epoch 6/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.6930 - acc: 0.8132 - val_loss: 1.7552 - val_acc: 0.5252\n",
      "Epoch 7/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.5409 - acc: 0.8725 - val_loss: 1.8573 - val_acc: 0.5540\n",
      "Epoch 8/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.3790 - acc: 0.9114 - val_loss: 1.7691 - val_acc: 0.5665\n",
      "Epoch 9/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.2979 - acc: 0.9380 - val_loss: 1.8115 - val_acc: 0.5647\n",
      "Epoch 10/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.2050 - acc: 0.9634 - val_loss: 1.8439 - val_acc: 0.5791\n",
      "Epoch 11/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.1622 - acc: 0.9684 - val_loss: 1.9489 - val_acc: 0.5845\n",
      "Epoch 12/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.1324 - acc: 0.9765 - val_loss: 1.9884 - val_acc: 0.5647\n",
      "Epoch 13/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.1160 - acc: 0.9788 - val_loss: 1.9881 - val_acc: 0.5665\n",
      "Epoch 14/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0654 - acc: 0.9923 - val_loss: 1.8759 - val_acc: 0.5665\n",
      "Epoch 15/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0813 - acc: 0.9888 - val_loss: 2.2582 - val_acc: 0.5522\n",
      "Epoch 16/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0851 - acc: 0.9819 - val_loss: 2.0773 - val_acc: 0.5504\n",
      "Epoch 17/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0994 - acc: 0.9773 - val_loss: 2.2520 - val_acc: 0.5432\n",
      "Epoch 18/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0967 - acc: 0.9800 - val_loss: 2.2399 - val_acc: 0.5396\n",
      "Epoch 19/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.1056 - acc: 0.9773 - val_loss: 2.4984 - val_acc: 0.5612\n",
      "Epoch 20/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0865 - acc: 0.9792 - val_loss: 2.2771 - val_acc: 0.5558\n",
      "Epoch 21/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0499 - acc: 0.9911 - val_loss: 2.1483 - val_acc: 0.5629\n",
      "Epoch 22/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0313 - acc: 0.9973 - val_loss: 2.0718 - val_acc: 0.5935\n",
      "Epoch 23/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0182 - acc: 0.9973 - val_loss: 1.9383 - val_acc: 0.6043\n",
      "Epoch 24/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.9913 - val_acc: 0.6079\n",
      "Epoch 25/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.9757 - val_acc: 0.5917\n",
      "Epoch 26/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.9879 - val_acc: 0.6025\n",
      "Epoch 27/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.9528 - val_acc: 0.6061\n",
      "Epoch 28/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.9797 - val_acc: 0.6151\n",
      "Epoch 29/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 2.0377 - val_acc: 0.6079\n",
      "Epoch 30/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0077 - acc: 0.9992 - val_loss: 2.0209 - val_acc: 0.5935\n",
      "Epoch 31/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0185 - acc: 0.9969 - val_loss: 2.0839 - val_acc: 0.5953\n",
      "Epoch 32/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0131 - acc: 0.9981 - val_loss: 2.1243 - val_acc: 0.5935\n",
      "Epoch 33/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0509 - acc: 0.9850 - val_loss: 2.4271 - val_acc: 0.5558\n",
      "Epoch 34/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.2747 - acc: 0.9191 - val_loss: 3.4843 - val_acc: 0.4928\n",
      "Epoch 35/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.4643 - acc: 0.8544 - val_loss: 3.3960 - val_acc: 0.4838\n",
      "Epoch 36/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.2240 - acc: 0.9276 - val_loss: 2.6684 - val_acc: 0.5450\n",
      "Epoch 37/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.1122 - acc: 0.9715 - val_loss: 2.6936 - val_acc: 0.5683\n",
      "Epoch 38/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0696 - acc: 0.9823 - val_loss: 2.3261 - val_acc: 0.5809\n",
      "Epoch 39/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0279 - acc: 0.9958 - val_loss: 2.1713 - val_acc: 0.5917\n",
      "Epoch 40/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0100 - acc: 0.9996 - val_loss: 2.1057 - val_acc: 0.5989\n",
      "Epoch 41/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0076 - acc: 0.9992 - val_loss: 2.1054 - val_acc: 0.6097\n",
      "Epoch 42/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0077 - acc: 0.9992 - val_loss: 2.1848 - val_acc: 0.5971\n",
      "Epoch 43/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0099 - acc: 0.9992 - val_loss: 2.2470 - val_acc: 0.5989\n",
      "Epoch 44/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0117 - acc: 0.9977 - val_loss: 2.1683 - val_acc: 0.6097\n",
      "Epoch 45/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0115 - acc: 0.9973 - val_loss: 2.1251 - val_acc: 0.6025\n",
      "Epoch 46/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.1634 - val_acc: 0.6169\n",
      "Epoch 47/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 2.1323 - val_acc: 0.6079\n",
      "Epoch 48/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.1331 - val_acc: 0.6133\n",
      "Epoch 49/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.1264 - val_acc: 0.6115\n",
      "Epoch 50/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.1311 - val_acc: 0.6097\n",
      "Epoch 51/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.1304 - val_acc: 0.6169\n",
      "Epoch 52/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.1433 - val_acc: 0.6079\n",
      "Epoch 53/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.1434 - val_acc: 0.6133\n",
      "Epoch 54/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.1570 - val_acc: 0.6169\n",
      "Epoch 55/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.1631 - val_acc: 0.6151\n",
      "Epoch 56/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.1781 - val_acc: 0.6061\n",
      "Epoch 57/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.1932 - val_acc: 0.6061\n",
      "Epoch 58/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 9.5938e-04 - acc: 1.0000 - val_loss: 2.1809 - val_acc: 0.6061\n",
      "Epoch 59/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 9.8242e-04 - acc: 1.0000 - val_loss: 2.1753 - val_acc: 0.6115\n",
      "Epoch 60/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 8.3284e-04 - acc: 1.0000 - val_loss: 2.1665 - val_acc: 0.6115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.2134 - val_acc: 0.6151\n",
      "Epoch 62/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 9.0335e-04 - acc: 1.0000 - val_loss: 2.2332 - val_acc: 0.6043\n",
      "Epoch 63/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 8.5412e-04 - acc: 1.0000 - val_loss: 2.2166 - val_acc: 0.6079\n",
      "Epoch 64/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 7.8872e-04 - acc: 1.0000 - val_loss: 2.2172 - val_acc: 0.6115\n",
      "Epoch 65/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 7.7390e-04 - acc: 1.0000 - val_loss: 2.2320 - val_acc: 0.6025\n",
      "Epoch 66/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 6.8641e-04 - acc: 1.0000 - val_loss: 2.2264 - val_acc: 0.5953\n",
      "Epoch 67/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 7.3769e-04 - acc: 1.0000 - val_loss: 2.2245 - val_acc: 0.6079\n",
      "Epoch 68/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 6.6511e-04 - acc: 1.0000 - val_loss: 2.2144 - val_acc: 0.6079\n",
      "Epoch 69/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 7.0557e-04 - acc: 1.0000 - val_loss: 2.2040 - val_acc: 0.6079\n",
      "Epoch 70/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0716 - acc: 0.9807 - val_loss: 3.4379 - val_acc: 0.4946\n",
      "Epoch 71/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.6402 - acc: 0.8113 - val_loss: 5.0356 - val_acc: 0.3741\n",
      "Epoch 72/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.4890 - acc: 0.8544 - val_loss: 3.4806 - val_acc: 0.5162\n",
      "Epoch 73/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.1882 - acc: 0.9403 - val_loss: 2.7744 - val_acc: 0.5522\n",
      "Epoch 74/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0630 - acc: 0.9846 - val_loss: 2.2256 - val_acc: 0.6223\n",
      "Epoch 75/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0211 - acc: 0.9965 - val_loss: 2.1463 - val_acc: 0.6025\n",
      "Epoch 76/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0133 - acc: 0.9985 - val_loss: 2.0630 - val_acc: 0.6115\n",
      "Epoch 77/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0092 - acc: 0.9988 - val_loss: 2.0915 - val_acc: 0.6025\n",
      "Epoch 78/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0087 - acc: 0.9988 - val_loss: 2.1292 - val_acc: 0.6133\n",
      "Epoch 79/100\n",
      "2597/2597 [==============================] - 12s 4ms/step - loss: 0.0085 - acc: 0.9985 - val_loss: 2.1348 - val_acc: 0.6241\n",
      "Epoch 80/100\n",
      "2597/2597 [==============================] - 12s 4ms/step - loss: 0.0054 - acc: 0.9996 - val_loss: 2.1995 - val_acc: 0.6025\n",
      "Epoch 81/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.0075 - acc: 0.9988 - val_loss: 2.1989 - val_acc: 0.6097\n",
      "Epoch 82/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 2.1774 - val_acc: 0.6205\n",
      "Epoch 83/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.1713 - val_acc: 0.6169\n",
      "Epoch 84/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.1376 - val_acc: 0.6187\n",
      "Epoch 85/100\n",
      "2597/2597 [==============================] - 9s 4ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.1629 - val_acc: 0.6151\n",
      "Epoch 86/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.1790 - val_acc: 0.6187\n",
      "Epoch 87/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.1788 - val_acc: 0.6151\n",
      "Epoch 88/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.1620 - val_acc: 0.6169\n",
      "Epoch 89/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.1664 - val_acc: 0.6223\n",
      "Epoch 90/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.1615 - val_acc: 0.6169\n",
      "Epoch 91/100\n",
      "2597/2597 [==============================] - 12s 5ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1648 - val_acc: 0.6187\n",
      "Epoch 92/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1771 - val_acc: 0.6169\n",
      "Epoch 93/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 9.6119e-04 - acc: 1.0000 - val_loss: 2.1826 - val_acc: 0.6241\n",
      "Epoch 94/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1827 - val_acc: 0.6187\n",
      "Epoch 95/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 9.9764e-04 - acc: 1.0000 - val_loss: 2.1862 - val_acc: 0.6277\n",
      "Epoch 96/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 7.2119e-04 - acc: 1.0000 - val_loss: 2.1827 - val_acc: 0.6241\n",
      "Epoch 97/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 8.8166e-04 - acc: 1.0000 - val_loss: 2.1815 - val_acc: 0.6241\n",
      "Epoch 98/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1967 - val_acc: 0.6187\n",
      "Epoch 99/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 6.6100e-04 - acc: 1.0000 - val_loss: 2.1864 - val_acc: 0.6241\n",
      "Epoch 100/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 6.5979e-04 - acc: 1.0000 - val_loss: 2.2018 - val_acc: 0.6241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f833c5189b0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model3.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=100,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 1ms/step\n",
      "[1.8687530124636913, 0.6552962247730372]\n"
     ]
    }
   ],
   "source": [
    "conv_result3 = conv_model3.evaluate(x_test, y_test, batch_size=150)\n",
    "print(conv_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 8, 150)            519150    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 8, 150)            600       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 1, 150)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_27 (Bidirectio (None, 1, 200)            200800    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1, 173)            34773     \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 1, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 1, 150)            519150    \n",
      "_________________________________________________________________\n",
      "elu_14 (ELU)                 (None, 1, 150)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_23  (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 41)                6191      \n",
      "=================================================================\n",
      "Total params: 1,281,356\n",
      "Trainable params: 1,280,710\n",
      "Non-trainable params: 646\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model4 = Sequential([\n",
    "    Convolution1D(150,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='tanh',strides=5),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(8),\n",
    "    \n",
    "    Bidirectional(LSTM(100, return_sequences=True)),\n",
    "    Dense(173, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(150,20, padding=\"same\",strides=5),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.4),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/100\n",
      "2597/2597 [==============================] - 25s 10ms/step - loss: 3.0357 - acc: 0.2033 - val_loss: 2.8385 - val_acc: 0.2464\n",
      "Epoch 2/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 2.3573 - acc: 0.3685 - val_loss: 3.4318 - val_acc: 0.2158\n",
      "Epoch 3/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 2.0074 - acc: 0.4428 - val_loss: 4.2631 - val_acc: 0.1619\n",
      "Epoch 4/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 1.7519 - acc: 0.5025 - val_loss: 4.7026 - val_acc: 0.1457\n",
      "Epoch 5/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 1.5958 - acc: 0.5418 - val_loss: 5.3339 - val_acc: 0.1421\n",
      "Epoch 6/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 1.4884 - acc: 0.5718 - val_loss: 5.3606 - val_acc: 0.2266\n",
      "Epoch 7/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 1.3986 - acc: 0.5968 - val_loss: 4.2162 - val_acc: 0.2230\n",
      "Epoch 8/100\n",
      "2597/2597 [==============================] - 6s 3ms/step - loss: 1.2901 - acc: 0.6380 - val_loss: 4.3863 - val_acc: 0.2176\n",
      "Epoch 9/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 1.2196 - acc: 0.6481 - val_loss: 4.2864 - val_acc: 0.2212\n",
      "Epoch 10/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 1.1870 - acc: 0.6646 - val_loss: 4.3051 - val_acc: 0.2752\n",
      "Epoch 11/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 1.0827 - acc: 0.6800 - val_loss: 4.1935 - val_acc: 0.2500\n",
      "Epoch 12/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 1.0365 - acc: 0.6935 - val_loss: 6.4569 - val_acc: 0.1835\n",
      "Epoch 13/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 1.0050 - acc: 0.6997 - val_loss: 5.4917 - val_acc: 0.1745\n",
      "Epoch 14/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.9827 - acc: 0.7039 - val_loss: 5.2198 - val_acc: 0.1888\n",
      "Epoch 15/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.9152 - acc: 0.7289 - val_loss: 5.7740 - val_acc: 0.2104\n",
      "Epoch 16/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.8774 - acc: 0.7293 - val_loss: 4.8480 - val_acc: 0.2554\n",
      "Epoch 17/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.8605 - acc: 0.7412 - val_loss: 4.9538 - val_acc: 0.2644\n",
      "Epoch 18/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.9188 - acc: 0.7212 - val_loss: 6.8938 - val_acc: 0.1475\n",
      "Epoch 19/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.8701 - acc: 0.7497 - val_loss: 6.0433 - val_acc: 0.2050\n",
      "Epoch 20/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.8622 - acc: 0.7505 - val_loss: 6.6575 - val_acc: 0.1781\n",
      "Epoch 21/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.8082 - acc: 0.7643 - val_loss: 5.8289 - val_acc: 0.2428\n",
      "Epoch 22/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.8299 - acc: 0.7539 - val_loss: 5.8356 - val_acc: 0.2104\n",
      "Epoch 23/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.7809 - acc: 0.7728 - val_loss: 5.6307 - val_acc: 0.1924\n",
      "Epoch 24/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.7827 - acc: 0.7771 - val_loss: 4.5106 - val_acc: 0.2428\n",
      "Epoch 25/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.7208 - acc: 0.7824 - val_loss: 5.5039 - val_acc: 0.2248\n",
      "Epoch 26/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.7311 - acc: 0.7790 - val_loss: 5.3396 - val_acc: 0.2356\n",
      "Epoch 27/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.7293 - acc: 0.7859 - val_loss: 5.4506 - val_acc: 0.2176\n",
      "Epoch 28/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.6779 - acc: 0.8021 - val_loss: 4.6366 - val_acc: 0.2590\n",
      "Epoch 29/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.6884 - acc: 0.7932 - val_loss: 5.8203 - val_acc: 0.2356\n",
      "Epoch 30/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.6605 - acc: 0.8017 - val_loss: 4.8031 - val_acc: 0.2752\n",
      "Epoch 31/100\n",
      "2597/2597 [==============================] - 10s 4ms/step - loss: 0.6576 - acc: 0.8017 - val_loss: 5.7403 - val_acc: 0.2302\n",
      "Epoch 32/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.7075 - acc: 0.7855 - val_loss: 6.1278 - val_acc: 0.2104\n",
      "Epoch 33/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.7011 - acc: 0.7917 - val_loss: 6.5529 - val_acc: 0.2122\n",
      "Epoch 34/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.7010 - acc: 0.7917 - val_loss: 6.6755 - val_acc: 0.1673\n",
      "Epoch 35/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.7231 - acc: 0.7848 - val_loss: 6.5322 - val_acc: 0.1727\n",
      "Epoch 36/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.7409 - acc: 0.7809 - val_loss: 5.3531 - val_acc: 0.2410\n",
      "Epoch 37/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.7040 - acc: 0.7898 - val_loss: 5.7734 - val_acc: 0.2392\n",
      "Epoch 38/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.6725 - acc: 0.8009 - val_loss: 5.1465 - val_acc: 0.2572\n",
      "Epoch 39/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.6620 - acc: 0.8055 - val_loss: 4.6025 - val_acc: 0.2932\n",
      "Epoch 40/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.6338 - acc: 0.8125 - val_loss: 7.1359 - val_acc: 0.1960\n",
      "Epoch 41/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.6861 - acc: 0.7975 - val_loss: 5.4420 - val_acc: 0.2230\n",
      "Epoch 42/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.6297 - acc: 0.8136 - val_loss: 6.2893 - val_acc: 0.1960\n",
      "Epoch 43/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5984 - acc: 0.8209 - val_loss: 5.3844 - val_acc: 0.2554\n",
      "Epoch 44/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.6671 - acc: 0.8025 - val_loss: 6.5246 - val_acc: 0.1888\n",
      "Epoch 45/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.6902 - acc: 0.7882 - val_loss: 5.0946 - val_acc: 0.2590\n",
      "Epoch 46/100\n",
      "2597/2597 [==============================] - 11s 4ms/step - loss: 0.6423 - acc: 0.8090 - val_loss: 5.7635 - val_acc: 0.2428\n",
      "Epoch 47/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.6423 - acc: 0.8152 - val_loss: 5.4312 - val_acc: 0.2824\n",
      "Epoch 48/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.6423 - acc: 0.8090 - val_loss: 6.5159 - val_acc: 0.1960\n",
      "Epoch 49/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.6232 - acc: 0.8059 - val_loss: 5.4314 - val_acc: 0.2500\n",
      "Epoch 50/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.5747 - acc: 0.8313 - val_loss: 6.6588 - val_acc: 0.2212\n",
      "Epoch 51/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.6069 - acc: 0.8229 - val_loss: 5.1909 - val_acc: 0.3040\n",
      "Epoch 52/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.6109 - acc: 0.8198 - val_loss: 4.8911 - val_acc: 0.2662\n",
      "Epoch 53/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5721 - acc: 0.8310 - val_loss: 5.3522 - val_acc: 0.2968\n",
      "Epoch 54/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5465 - acc: 0.8340 - val_loss: 4.9782 - val_acc: 0.2842\n",
      "Epoch 55/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5157 - acc: 0.8483 - val_loss: 4.9478 - val_acc: 0.2626\n",
      "Epoch 56/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5500 - acc: 0.8344 - val_loss: 6.4130 - val_acc: 0.2140\n",
      "Epoch 57/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5881 - acc: 0.8325 - val_loss: 5.8705 - val_acc: 0.2194\n",
      "Epoch 58/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5749 - acc: 0.8333 - val_loss: 5.9412 - val_acc: 0.2356\n",
      "Epoch 59/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5633 - acc: 0.8290 - val_loss: 4.7101 - val_acc: 0.3094\n",
      "Epoch 60/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5692 - acc: 0.8321 - val_loss: 5.5567 - val_acc: 0.2608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5768 - acc: 0.8290 - val_loss: 6.0777 - val_acc: 0.2518\n",
      "Epoch 62/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5846 - acc: 0.8279 - val_loss: 5.0303 - val_acc: 0.2680\n",
      "Epoch 63/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.6343 - acc: 0.8167 - val_loss: 5.3564 - val_acc: 0.2554\n",
      "Epoch 64/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.6130 - acc: 0.8217 - val_loss: 8.5067 - val_acc: 0.1403\n",
      "Epoch 65/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5918 - acc: 0.8256 - val_loss: 4.9190 - val_acc: 0.2842\n",
      "Epoch 66/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5496 - acc: 0.8348 - val_loss: 5.3194 - val_acc: 0.2374\n",
      "Epoch 67/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5506 - acc: 0.8375 - val_loss: 5.3722 - val_acc: 0.2662\n",
      "Epoch 68/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.6048 - acc: 0.8217 - val_loss: 5.0969 - val_acc: 0.2662\n",
      "Epoch 69/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.6305 - acc: 0.8183 - val_loss: 5.8776 - val_acc: 0.2446\n",
      "Epoch 70/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5785 - acc: 0.8252 - val_loss: 6.5670 - val_acc: 0.1906\n",
      "Epoch 71/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5760 - acc: 0.8340 - val_loss: 5.2259 - val_acc: 0.2608\n",
      "Epoch 72/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5942 - acc: 0.8140 - val_loss: 5.6315 - val_acc: 0.2788\n",
      "Epoch 73/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.6214 - acc: 0.8213 - val_loss: 5.2783 - val_acc: 0.2788\n",
      "Epoch 74/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5653 - acc: 0.8306 - val_loss: 5.2396 - val_acc: 0.2590\n",
      "Epoch 75/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5284 - acc: 0.8448 - val_loss: 5.3807 - val_acc: 0.2806\n",
      "Epoch 76/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5611 - acc: 0.8375 - val_loss: 6.2064 - val_acc: 0.2158\n",
      "Epoch 77/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5711 - acc: 0.8356 - val_loss: 6.2880 - val_acc: 0.2338\n",
      "Epoch 78/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5407 - acc: 0.8310 - val_loss: 4.8126 - val_acc: 0.2896\n",
      "Epoch 79/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5321 - acc: 0.8464 - val_loss: 5.0046 - val_acc: 0.2680\n",
      "Epoch 80/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5411 - acc: 0.8414 - val_loss: 4.8683 - val_acc: 0.2860\n",
      "Epoch 81/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5230 - acc: 0.8429 - val_loss: 5.4750 - val_acc: 0.2500\n",
      "Epoch 82/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.5105 - acc: 0.8483 - val_loss: 5.0200 - val_acc: 0.2806\n",
      "Epoch 83/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5182 - acc: 0.8471 - val_loss: 6.2244 - val_acc: 0.2086\n",
      "Epoch 84/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.4902 - acc: 0.8533 - val_loss: 6.4116 - val_acc: 0.2356\n",
      "Epoch 85/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.4586 - acc: 0.8587 - val_loss: 5.1319 - val_acc: 0.2806\n",
      "Epoch 86/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.4702 - acc: 0.8552 - val_loss: 5.4193 - val_acc: 0.2698\n",
      "Epoch 87/100\n",
      "2597/2597 [==============================] - 8s 3ms/step - loss: 0.4718 - acc: 0.8641 - val_loss: 5.0062 - val_acc: 0.2824\n",
      "Epoch 88/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.4608 - acc: 0.8621 - val_loss: 5.0350 - val_acc: 0.2662\n",
      "Epoch 89/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.4569 - acc: 0.8587 - val_loss: 5.9827 - val_acc: 0.2446\n",
      "Epoch 90/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.4970 - acc: 0.8494 - val_loss: 5.9785 - val_acc: 0.2212\n",
      "Epoch 91/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5380 - acc: 0.8433 - val_loss: 5.9266 - val_acc: 0.2266\n",
      "Epoch 92/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5213 - acc: 0.8448 - val_loss: 5.5015 - val_acc: 0.2626\n",
      "Epoch 93/100\n",
      "2597/2597 [==============================] - 7s 3ms/step - loss: 0.5147 - acc: 0.8471 - val_loss: 5.8783 - val_acc: 0.2590\n",
      "Epoch 94/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5152 - acc: 0.8498 - val_loss: 5.3122 - val_acc: 0.2536\n",
      "Epoch 95/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5132 - acc: 0.8456 - val_loss: 5.8039 - val_acc: 0.2788\n",
      "Epoch 96/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5649 - acc: 0.8379 - val_loss: 5.0698 - val_acc: 0.2860\n",
      "Epoch 97/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5746 - acc: 0.8337 - val_loss: 5.8688 - val_acc: 0.2356\n",
      "Epoch 98/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5682 - acc: 0.8371 - val_loss: 7.8593 - val_acc: 0.1978\n",
      "Epoch 99/100\n",
      "2597/2597 [==============================] - 6s 2ms/step - loss: 0.5516 - acc: 0.8394 - val_loss: 5.9169 - val_acc: 0.2554\n",
      "Epoch 100/100\n",
      "2597/2597 [==============================] - 9s 3ms/step - loss: 0.5343 - acc: 0.8387 - val_loss: 5.6582 - val_acc: 0.2752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82846bf6d8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model4.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=100,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 902us/step\n",
      "[1.8687530124636913, 0.6552962247730372]\n"
     ]
    }
   ],
   "source": [
    "conv_result4 = conv_model3.evaluate(x_test, y_test, batch_size=150)\n",
    "print(conv_result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_37 (Conv1D)           (None, 8, 256)            886016    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 2, 200)            285600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2, 173)            34773     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 2, 512)            1772032   \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 41)                21033     \n",
      "=================================================================\n",
      "Total params: 3,000,146\n",
      "Trainable params: 2,999,800\n",
      "Non-trainable params: 346\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model4 = Sequential([\n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='tanh',strides=5),\n",
    "    MaxPool1D(3,strides=3),\n",
    "    \n",
    "    Bidirectional(LSTM(100, return_sequences=True)),\n",
    "    Dense(173, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(512,20, padding=\"same\",strides=1),\n",
    "    ELU(alpha=1.0),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.5),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "])\n",
    "conv_model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/100\n",
      "2597/2597 [==============================] - 19s 7ms/step - loss: 2.6888 - acc: 0.2926 - val_loss: 2.2145 - val_acc: 0.4281\n",
      "Epoch 2/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 1.5942 - acc: 0.5583 - val_loss: 2.2528 - val_acc: 0.4065\n",
      "Epoch 3/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 1.0751 - acc: 0.6889 - val_loss: 2.1175 - val_acc: 0.4802\n",
      "Epoch 4/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.7384 - acc: 0.7836 - val_loss: 2.4334 - val_acc: 0.4820\n",
      "Epoch 5/100\n",
      "2597/2597 [==============================] - 19s 7ms/step - loss: 0.5102 - acc: 0.8498 - val_loss: 2.8297 - val_acc: 0.4442\n",
      "Epoch 6/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.4254 - acc: 0.8645 - val_loss: 2.6133 - val_acc: 0.4802\n",
      "Epoch 7/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.3235 - acc: 0.9030 - val_loss: 2.8922 - val_acc: 0.4676\n",
      "Epoch 8/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.3037 - acc: 0.9049 - val_loss: 2.9153 - val_acc: 0.4658\n",
      "Epoch 9/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2684 - acc: 0.9176 - val_loss: 3.0865 - val_acc: 0.4856\n",
      "Epoch 10/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2676 - acc: 0.9195 - val_loss: 3.0288 - val_acc: 0.4874\n",
      "Epoch 11/100\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.2254 - acc: 0.9265 - val_loss: 3.1308 - val_acc: 0.4712\n",
      "Epoch 12/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2261 - acc: 0.9299 - val_loss: 3.1963 - val_acc: 0.4622\n",
      "Epoch 13/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2683 - acc: 0.9211 - val_loss: 3.4381 - val_acc: 0.4712\n",
      "Epoch 14/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.2591 - acc: 0.9188 - val_loss: 3.3046 - val_acc: 0.4712\n",
      "Epoch 15/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2255 - acc: 0.9272 - val_loss: 3.1295 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2103 - acc: 0.9334 - val_loss: 3.3631 - val_acc: 0.4910\n",
      "Epoch 17/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2140 - acc: 0.9276 - val_loss: 3.6572 - val_acc: 0.4748\n",
      "Epoch 18/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1874 - acc: 0.9349 - val_loss: 3.3158 - val_acc: 0.4730\n",
      "Epoch 19/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1713 - acc: 0.9419 - val_loss: 3.5603 - val_acc: 0.4748\n",
      "Epoch 20/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1964 - acc: 0.9357 - val_loss: 3.4275 - val_acc: 0.4820\n",
      "Epoch 21/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1603 - acc: 0.9488 - val_loss: 3.6594 - val_acc: 0.4712\n",
      "Epoch 22/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1514 - acc: 0.9492 - val_loss: 3.8539 - val_acc: 0.4964\n",
      "Epoch 23/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1802 - acc: 0.9446 - val_loss: 3.6733 - val_acc: 0.4694\n",
      "Epoch 24/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1624 - acc: 0.9469 - val_loss: 3.7905 - val_acc: 0.4802\n",
      "Epoch 25/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1581 - acc: 0.9503 - val_loss: 3.6760 - val_acc: 0.5036\n",
      "Epoch 26/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1505 - acc: 0.9523 - val_loss: 3.6097 - val_acc: 0.4928\n",
      "Epoch 27/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1757 - acc: 0.9480 - val_loss: 3.6548 - val_acc: 0.4820\n",
      "Epoch 28/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1238 - acc: 0.9611 - val_loss: 3.8019 - val_acc: 0.4856\n",
      "Epoch 29/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1323 - acc: 0.9569 - val_loss: 4.2359 - val_acc: 0.4281\n",
      "Epoch 30/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1134 - acc: 0.9580 - val_loss: 4.0455 - val_acc: 0.4766\n",
      "Epoch 31/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1262 - acc: 0.9600 - val_loss: 4.1617 - val_acc: 0.4586\n",
      "Epoch 32/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1385 - acc: 0.9565 - val_loss: 3.9532 - val_acc: 0.4874\n",
      "Epoch 33/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1350 - acc: 0.9607 - val_loss: 3.8298 - val_acc: 0.4874\n",
      "Epoch 34/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1577 - acc: 0.9530 - val_loss: 3.5810 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1222 - acc: 0.9580 - val_loss: 4.1169 - val_acc: 0.4748\n",
      "Epoch 36/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1454 - acc: 0.9561 - val_loss: 4.1072 - val_acc: 0.4730\n",
      "Epoch 37/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1363 - acc: 0.9573 - val_loss: 3.8509 - val_acc: 0.4766\n",
      "Epoch 38/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1071 - acc: 0.9661 - val_loss: 4.2038 - val_acc: 0.5036\n",
      "Epoch 39/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1229 - acc: 0.9619 - val_loss: 4.3163 - val_acc: 0.4820\n",
      "Epoch 40/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1204 - acc: 0.9607 - val_loss: 4.0954 - val_acc: 0.4946\n",
      "Epoch 41/100\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1212 - acc: 0.9611 - val_loss: 4.2343 - val_acc: 0.4766\n",
      "Epoch 42/100\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1104 - acc: 0.9657 - val_loss: 3.9822 - val_acc: 0.4892\n",
      "Epoch 43/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1630 - acc: 0.9538 - val_loss: 4.1142 - val_acc: 0.4748\n",
      "Epoch 44/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1595 - acc: 0.9480 - val_loss: 4.3353 - val_acc: 0.5072\n",
      "Epoch 45/100\n",
      "2597/2597 [==============================] - 19s 7ms/step - loss: 0.1342 - acc: 0.9576 - val_loss: 3.9603 - val_acc: 0.4964\n",
      "Epoch 46/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.0998 - acc: 0.9680 - val_loss: 4.0650 - val_acc: 0.4964\n",
      "Epoch 47/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.0937 - acc: 0.9700 - val_loss: 4.2546 - val_acc: 0.4910\n",
      "Epoch 48/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.0979 - acc: 0.9692 - val_loss: 4.2402 - val_acc: 0.4946\n",
      "Epoch 49/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.0747 - acc: 0.9754 - val_loss: 4.4735 - val_acc: 0.4838\n",
      "Epoch 50/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1164 - acc: 0.9642 - val_loss: 4.3002 - val_acc: 0.4820\n",
      "Epoch 51/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1062 - acc: 0.9650 - val_loss: 4.4468 - val_acc: 0.4640\n",
      "Epoch 52/100\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1302 - acc: 0.9596 - val_loss: 4.3337 - val_acc: 0.4856\n",
      "Epoch 53/100\n",
      "2597/2597 [==============================] - 19s 7ms/step - loss: 0.1455 - acc: 0.9561 - val_loss: 4.4285 - val_acc: 0.5252\n",
      "Epoch 54/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1381 - acc: 0.9584 - val_loss: 4.3915 - val_acc: 0.4694\n",
      "Epoch 55/100\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1214 - acc: 0.9584 - val_loss: 4.9049 - val_acc: 0.4622\n",
      "Epoch 56/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1865 - acc: 0.9461 - val_loss: 4.7903 - val_acc: 0.4838\n",
      "Epoch 57/100\n",
      "2597/2597 [==============================] - 23s 9ms/step - loss: 0.1626 - acc: 0.9530 - val_loss: 4.4375 - val_acc: 0.4874\n",
      "Epoch 58/100\n",
      "2597/2597 [==============================] - 19s 7ms/step - loss: 0.1569 - acc: 0.9546 - val_loss: 4.4656 - val_acc: 0.4874\n",
      "Epoch 59/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1311 - acc: 0.9607 - val_loss: 4.4351 - val_acc: 0.4874\n",
      "Epoch 60/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.0750 - acc: 0.9719 - val_loss: 4.7112 - val_acc: 0.4766\n",
      "Epoch 61/100\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.0749 - acc: 0.9750 - val_loss: 4.4266 - val_acc: 0.4928\n",
      "Epoch 62/100\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.0574 - acc: 0.9823 - val_loss: 4.3182 - val_acc: 0.4910\n",
      "Epoch 63/100\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.0746 - acc: 0.9757 - val_loss: 4.4759 - val_acc: 0.4874\n",
      "Epoch 64/100\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.0548 - acc: 0.9823 - val_loss: 4.4999 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "2597/2597 [==============================] - 19s 7ms/step - loss: 0.0395 - acc: 0.9881 - val_loss: 4.5209 - val_acc: 0.4910\n",
      "Epoch 66/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.0537 - acc: 0.9788 - val_loss: 4.2657 - val_acc: 0.4874\n",
      "Epoch 67/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.0778 - acc: 0.9761 - val_loss: 4.3608 - val_acc: 0.5054\n",
      "Epoch 68/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0933 - acc: 0.9711 - val_loss: 4.7826 - val_acc: 0.4892\n",
      "Epoch 69/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0751 - acc: 0.9754 - val_loss: 4.5739 - val_acc: 0.4802\n",
      "Epoch 70/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1237 - acc: 0.9619 - val_loss: 4.8535 - val_acc: 0.4784\n",
      "Epoch 71/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1105 - acc: 0.9638 - val_loss: 4.5104 - val_acc: 0.5072\n",
      "Epoch 72/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0975 - acc: 0.9692 - val_loss: 4.6446 - val_acc: 0.5036\n",
      "Epoch 73/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0878 - acc: 0.9746 - val_loss: 4.6005 - val_acc: 0.5108\n",
      "Epoch 74/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1264 - acc: 0.9600 - val_loss: 4.9032 - val_acc: 0.4766\n",
      "Epoch 75/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1170 - acc: 0.9650 - val_loss: 4.6785 - val_acc: 0.4784\n",
      "Epoch 76/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.1332 - acc: 0.9600 - val_loss: 4.6571 - val_acc: 0.4658\n",
      "Epoch 77/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1239 - acc: 0.9592 - val_loss: 4.6516 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "2597/2597 [==============================] - 19s 7ms/step - loss: 0.1316 - acc: 0.9619 - val_loss: 4.6225 - val_acc: 0.4982\n",
      "Epoch 79/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.1246 - acc: 0.9611 - val_loss: 4.6477 - val_acc: 0.4892\n",
      "Epoch 80/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1102 - acc: 0.9680 - val_loss: 4.4034 - val_acc: 0.4910\n",
      "Epoch 81/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.1191 - acc: 0.9677 - val_loss: 4.6026 - val_acc: 0.4766\n",
      "Epoch 82/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.0943 - acc: 0.9750 - val_loss: 4.8206 - val_acc: 0.4820\n",
      "Epoch 83/100\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.0946 - acc: 0.9692 - val_loss: 4.7226 - val_acc: 0.4964\n",
      "Epoch 84/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.0950 - acc: 0.9688 - val_loss: 4.5942 - val_acc: 0.4748\n",
      "Epoch 85/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0862 - acc: 0.9730 - val_loss: 4.5930 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0972 - acc: 0.9719 - val_loss: 4.3811 - val_acc: 0.5054\n",
      "Epoch 87/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.0810 - acc: 0.9734 - val_loss: 4.5810 - val_acc: 0.5108\n",
      "Epoch 88/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0918 - acc: 0.9711 - val_loss: 4.4759 - val_acc: 0.5180\n",
      "Epoch 89/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0704 - acc: 0.9819 - val_loss: 4.5330 - val_acc: 0.5072\n",
      "Epoch 90/100\n",
      "2597/2597 [==============================] - 23s 9ms/step - loss: 0.0668 - acc: 0.9765 - val_loss: 4.3926 - val_acc: 0.5198\n",
      "Epoch 91/100\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.0548 - acc: 0.9831 - val_loss: 4.7710 - val_acc: 0.5054\n",
      "Epoch 92/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.0347 - acc: 0.9881 - val_loss: 4.5552 - val_acc: 0.5180\n",
      "Epoch 93/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0492 - acc: 0.9869 - val_loss: 4.6697 - val_acc: 0.5036\n",
      "Epoch 94/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0524 - acc: 0.9834 - val_loss: 4.8201 - val_acc: 0.4820\n",
      "Epoch 95/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0613 - acc: 0.9788 - val_loss: 4.8361 - val_acc: 0.4982\n",
      "Epoch 96/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0845 - acc: 0.9715 - val_loss: 4.7515 - val_acc: 0.5198\n",
      "Epoch 97/100\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.0924 - acc: 0.9727 - val_loss: 4.7699 - val_acc: 0.4838\n",
      "Epoch 98/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.0960 - acc: 0.9704 - val_loss: 4.8242 - val_acc: 0.5036\n",
      "Epoch 99/100\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.1079 - acc: 0.9653 - val_loss: 4.7878 - val_acc: 0.4784\n",
      "Epoch 100/100\n",
      "2597/2597 [==============================] - 17s 7ms/step - loss: 0.0963 - acc: 0.9696 - val_loss: 4.7603 - val_acc: 0.4802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a11e84c18>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model4.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=100,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 0s 311us/step\n",
      "[4.9980170414306535, 0.5008976827618036]\n"
     ]
    }
   ],
   "source": [
    "conv_result4 = conv_model4.evaluate(x_test, y_test, batch_size=150)\n",
    "print(conv_result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 40, 256)           886016    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 40, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 13, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 5, 256)            1310976   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 5, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 1, 512)            1050624   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1, 173)            88749     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 1, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 1, 128)            443008    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 41)                5289      \n",
      "=================================================================\n",
      "Total params: 3,787,914\n",
      "Trainable params: 3,786,288\n",
      "Non-trainable params: 1,626\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model4 = Sequential([\n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=1),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=3),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dense(173, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(128,20, padding=\"same\",strides=3),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.3),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/300\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 2.9181 - acc: 0.2291 - val_loss: 2.4009 - val_acc: 0.3741\n",
      "Epoch 2/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 1.9132 - acc: 0.4625 - val_loss: 2.0023 - val_acc: 0.4442\n",
      "Epoch 3/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.4636 - acc: 0.5934 - val_loss: 2.0219 - val_acc: 0.4514\n",
      "Epoch 4/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.0825 - acc: 0.6835 - val_loss: 1.7217 - val_acc: 0.5288\n",
      "Epoch 5/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.7352 - acc: 0.7894 - val_loss: 1.7222 - val_acc: 0.5342\n",
      "Epoch 6/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.5847 - acc: 0.8352 - val_loss: 1.6346 - val_acc: 0.5791\n",
      "Epoch 7/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.3873 - acc: 0.8879 - val_loss: 1.7918 - val_acc: 0.5594\n",
      "Epoch 8/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.3481 - acc: 0.9018 - val_loss: 1.7135 - val_acc: 0.5863\n",
      "Epoch 9/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.2642 - acc: 0.9257 - val_loss: 1.6805 - val_acc: 0.6043\n",
      "Epoch 10/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.2095 - acc: 0.9395 - val_loss: 1.7819 - val_acc: 0.5863\n",
      "Epoch 11/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1366 - acc: 0.9619 - val_loss: 1.6504 - val_acc: 0.6259\n",
      "Epoch 12/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0890 - acc: 0.9800 - val_loss: 1.7233 - val_acc: 0.6079\n",
      "Epoch 13/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1100 - acc: 0.9723 - val_loss: 1.7680 - val_acc: 0.6025\n",
      "Epoch 14/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0702 - acc: 0.9834 - val_loss: 1.5607 - val_acc: 0.6403\n",
      "Epoch 15/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0504 - acc: 0.9900 - val_loss: 1.5489 - val_acc: 0.6403\n",
      "Epoch 16/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0339 - acc: 0.9923 - val_loss: 1.5405 - val_acc: 0.6349\n",
      "Epoch 17/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0357 - acc: 0.9919 - val_loss: 1.6863 - val_acc: 0.6295\n",
      "Epoch 18/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0663 - acc: 0.9842 - val_loss: 1.7367 - val_acc: 0.6151\n",
      "Epoch 19/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0691 - acc: 0.9827 - val_loss: 1.6772 - val_acc: 0.5935\n",
      "Epoch 20/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0732 - acc: 0.9815 - val_loss: 1.7866 - val_acc: 0.6421\n",
      "Epoch 21/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0873 - acc: 0.9757 - val_loss: 1.8977 - val_acc: 0.5899\n",
      "Epoch 22/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1124 - acc: 0.9742 - val_loss: 1.8666 - val_acc: 0.6205\n",
      "Epoch 23/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0658 - acc: 0.9842 - val_loss: 1.7571 - val_acc: 0.6151\n",
      "Epoch 24/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0486 - acc: 0.9892 - val_loss: 1.6708 - val_acc: 0.6457\n",
      "Epoch 25/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0627 - acc: 0.9838 - val_loss: 1.9894 - val_acc: 0.5863\n",
      "Epoch 26/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0803 - acc: 0.9769 - val_loss: 1.9042 - val_acc: 0.6331\n",
      "Epoch 27/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0903 - acc: 0.9750 - val_loss: 1.9217 - val_acc: 0.6349\n",
      "Epoch 28/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.1252 - acc: 0.9626 - val_loss: 2.2157 - val_acc: 0.6007\n",
      "Epoch 29/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1314 - acc: 0.9588 - val_loss: 2.2200 - val_acc: 0.5827\n",
      "Epoch 30/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1089 - acc: 0.9707 - val_loss: 2.0811 - val_acc: 0.6187\n",
      "Epoch 31/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0779 - acc: 0.9781 - val_loss: 2.0510 - val_acc: 0.6115\n",
      "Epoch 32/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0557 - acc: 0.9869 - val_loss: 1.7507 - val_acc: 0.6367\n",
      "Epoch 33/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0388 - acc: 0.9896 - val_loss: 1.7381 - val_acc: 0.6619\n",
      "Epoch 34/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0218 - acc: 0.9954 - val_loss: 1.7229 - val_acc: 0.6493\n",
      "Epoch 35/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0053 - acc: 0.9996 - val_loss: 1.6508 - val_acc: 0.6637\n",
      "Epoch 36/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0069 - acc: 0.9988 - val_loss: 1.6279 - val_acc: 0.6511\n",
      "Epoch 37/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0163 - acc: 0.9958 - val_loss: 1.7902 - val_acc: 0.6385\n",
      "Epoch 38/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0709 - acc: 0.9846 - val_loss: 1.8899 - val_acc: 0.6205\n",
      "Epoch 39/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0641 - acc: 0.9819 - val_loss: 2.0358 - val_acc: 0.5917\n",
      "Epoch 40/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0599 - acc: 0.9846 - val_loss: 2.0179 - val_acc: 0.6187\n",
      "Epoch 41/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0351 - acc: 0.9911 - val_loss: 1.9028 - val_acc: 0.6421\n",
      "Epoch 42/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.0332 - acc: 0.9919 - val_loss: 1.9578 - val_acc: 0.6403\n",
      "Epoch 43/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0847 - acc: 0.9773 - val_loss: 2.2707 - val_acc: 0.5989\n",
      "Epoch 44/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0546 - acc: 0.9858 - val_loss: 1.9867 - val_acc: 0.6313\n",
      "Epoch 45/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.0751 - acc: 0.9769 - val_loss: 2.2438 - val_acc: 0.5935\n",
      "Epoch 46/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0685 - acc: 0.9815 - val_loss: 2.0940 - val_acc: 0.6151\n",
      "Epoch 47/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0827 - acc: 0.9754 - val_loss: 2.1217 - val_acc: 0.6079\n",
      "Epoch 48/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0964 - acc: 0.9711 - val_loss: 2.1977 - val_acc: 0.6313\n",
      "Epoch 49/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0816 - acc: 0.9769 - val_loss: 2.0685 - val_acc: 0.6151\n",
      "Epoch 50/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.0616 - acc: 0.9815 - val_loss: 2.0470 - val_acc: 0.6097\n",
      "Epoch 51/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0291 - acc: 0.9923 - val_loss: 1.8067 - val_acc: 0.6421\n",
      "Epoch 52/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0107 - acc: 0.9981 - val_loss: 1.7200 - val_acc: 0.6547\n",
      "Epoch 53/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 1.7038 - val_acc: 0.6709\n",
      "Epoch 54/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0140 - acc: 0.9954 - val_loss: 1.7814 - val_acc: 0.6637\n",
      "Epoch 55/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0203 - acc: 0.9931 - val_loss: 1.8113 - val_acc: 0.6403\n",
      "Epoch 56/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0190 - acc: 0.9942 - val_loss: 1.9071 - val_acc: 0.6421\n",
      "Epoch 57/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0357 - acc: 0.9915 - val_loss: 2.1190 - val_acc: 0.6241\n",
      "Epoch 58/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.0499 - acc: 0.9869 - val_loss: 2.0424 - val_acc: 0.6403\n",
      "Epoch 59/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0472 - acc: 0.9877 - val_loss: 2.0663 - val_acc: 0.6349\n",
      "Epoch 60/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0531 - acc: 0.9858 - val_loss: 2.0656 - val_acc: 0.6295\n",
      "Epoch 61/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0637 - acc: 0.9842 - val_loss: 1.9440 - val_acc: 0.6241\n",
      "Epoch 62/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0482 - acc: 0.9850 - val_loss: 2.1173 - val_acc: 0.6043\n",
      "Epoch 63/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0538 - acc: 0.9842 - val_loss: 2.2900 - val_acc: 0.6133\n",
      "Epoch 64/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0866 - acc: 0.9761 - val_loss: 2.2634 - val_acc: 0.6205\n",
      "Epoch 65/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0733 - acc: 0.9811 - val_loss: 2.0142 - val_acc: 0.6475\n",
      "Epoch 66/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0829 - acc: 0.9784 - val_loss: 2.1034 - val_acc: 0.6403\n",
      "Epoch 67/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0396 - acc: 0.9892 - val_loss: 1.9682 - val_acc: 0.6475\n",
      "Epoch 68/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0274 - acc: 0.9911 - val_loss: 2.0054 - val_acc: 0.6511\n",
      "Epoch 69/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0174 - acc: 0.9958 - val_loss: 1.8615 - val_acc: 0.6475\n",
      "Epoch 70/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0152 - acc: 0.9961 - val_loss: 2.0242 - val_acc: 0.6529\n",
      "Epoch 71/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0149 - acc: 0.9969 - val_loss: 1.9480 - val_acc: 0.6601\n",
      "Epoch 72/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0162 - acc: 0.9981 - val_loss: 1.8404 - val_acc: 0.6709\n",
      "Epoch 73/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 1.8148 - val_acc: 0.6673\n",
      "Epoch 74/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 1.8222 - val_acc: 0.6565\n",
      "Epoch 75/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.7742 - val_acc: 0.6655\n",
      "Epoch 76/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 1.8299 - val_acc: 0.6691\n",
      "Epoch 77/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0138 - acc: 0.9973 - val_loss: 1.8625 - val_acc: 0.6673\n",
      "Epoch 78/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0056 - acc: 0.9992 - val_loss: 1.8414 - val_acc: 0.6709\n",
      "Epoch 79/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 1.8208 - val_acc: 0.6763\n",
      "Epoch 80/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0199 - acc: 0.9942 - val_loss: 1.8249 - val_acc: 0.6673\n",
      "Epoch 81/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0254 - acc: 0.9954 - val_loss: 1.8642 - val_acc: 0.6637\n",
      "Epoch 82/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0119 - acc: 0.9958 - val_loss: 1.8752 - val_acc: 0.6619\n",
      "Epoch 83/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0114 - acc: 0.9973 - val_loss: 1.9536 - val_acc: 0.6619\n",
      "Epoch 84/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0377 - acc: 0.9888 - val_loss: 2.3774 - val_acc: 0.5971\n",
      "Epoch 85/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1082 - acc: 0.9711 - val_loss: 2.3821 - val_acc: 0.6097\n",
      "Epoch 86/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1334 - acc: 0.9638 - val_loss: 2.5225 - val_acc: 0.5899\n",
      "Epoch 87/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1132 - acc: 0.9665 - val_loss: 2.3793 - val_acc: 0.5935\n",
      "Epoch 88/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0988 - acc: 0.9738 - val_loss: 2.2022 - val_acc: 0.6313\n",
      "Epoch 89/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0899 - acc: 0.9781 - val_loss: 2.0193 - val_acc: 0.6547\n",
      "Epoch 90/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0388 - acc: 0.9900 - val_loss: 1.8166 - val_acc: 0.6565\n",
      "Epoch 91/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0364 - acc: 0.9900 - val_loss: 1.9571 - val_acc: 0.6385\n",
      "Epoch 92/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0157 - acc: 0.9958 - val_loss: 1.8469 - val_acc: 0.6727\n",
      "Epoch 93/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0127 - acc: 0.9973 - val_loss: 1.9025 - val_acc: 0.6529\n",
      "Epoch 94/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0097 - acc: 0.9973 - val_loss: 1.8100 - val_acc: 0.6655\n",
      "Epoch 95/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0095 - acc: 0.9985 - val_loss: 1.8453 - val_acc: 0.6637\n",
      "Epoch 96/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0087 - acc: 0.9985 - val_loss: 1.7770 - val_acc: 0.6601\n",
      "Epoch 97/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.7566 - val_acc: 0.6691\n",
      "Epoch 98/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 1.9199 - val_acc: 0.6583\n",
      "Epoch 99/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0062 - acc: 0.9985 - val_loss: 1.8424 - val_acc: 0.6619\n",
      "Epoch 100/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.0097 - acc: 0.9981 - val_loss: 1.7878 - val_acc: 0.6727\n",
      "Epoch 101/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0076 - acc: 0.9973 - val_loss: 1.8892 - val_acc: 0.6493\n",
      "Epoch 102/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0171 - acc: 0.9950 - val_loss: 1.9946 - val_acc: 0.6439\n",
      "Epoch 103/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0322 - acc: 0.9915 - val_loss: 2.0184 - val_acc: 0.6511\n",
      "Epoch 104/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0222 - acc: 0.9942 - val_loss: 2.0988 - val_acc: 0.6529\n",
      "Epoch 105/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0137 - acc: 0.9969 - val_loss: 1.9972 - val_acc: 0.6565\n",
      "Epoch 106/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0136 - acc: 0.9969 - val_loss: 2.0642 - val_acc: 0.6493\n",
      "Epoch 107/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0123 - acc: 0.9969 - val_loss: 2.0067 - val_acc: 0.6529\n",
      "Epoch 108/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0176 - acc: 0.9954 - val_loss: 1.9141 - val_acc: 0.6475\n",
      "Epoch 109/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0095 - acc: 0.9977 - val_loss: 1.8756 - val_acc: 0.6655\n",
      "Epoch 110/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0073 - acc: 0.9988 - val_loss: 1.9041 - val_acc: 0.6709\n",
      "Epoch 111/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 1.9368 - val_acc: 0.6493\n",
      "Epoch 112/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0445 - acc: 0.9896 - val_loss: 2.1256 - val_acc: 0.6223\n",
      "Epoch 113/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0586 - acc: 0.9831 - val_loss: 2.0356 - val_acc: 0.6475\n",
      "Epoch 114/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0451 - acc: 0.9869 - val_loss: 2.1657 - val_acc: 0.6223\n",
      "Epoch 115/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0697 - acc: 0.9815 - val_loss: 2.1787 - val_acc: 0.6421\n",
      "Epoch 116/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0461 - acc: 0.9873 - val_loss: 2.0957 - val_acc: 0.6475\n",
      "Epoch 117/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0413 - acc: 0.9892 - val_loss: 2.0540 - val_acc: 0.6565\n",
      "Epoch 118/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.0325 - acc: 0.9911 - val_loss: 2.1656 - val_acc: 0.6529\n",
      "Epoch 119/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0352 - acc: 0.9900 - val_loss: 2.2553 - val_acc: 0.6043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0674 - acc: 0.9811 - val_loss: 2.3791 - val_acc: 0.6043\n",
      "Epoch 121/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0574 - acc: 0.9823 - val_loss: 2.4106 - val_acc: 0.6421\n",
      "Epoch 122/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0643 - acc: 0.9827 - val_loss: 2.3410 - val_acc: 0.6349\n",
      "Epoch 123/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0474 - acc: 0.9884 - val_loss: 2.1318 - val_acc: 0.6655\n",
      "Epoch 124/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0097 - acc: 0.9977 - val_loss: 1.9096 - val_acc: 0.6817\n",
      "Epoch 125/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 1.8694 - val_acc: 0.6817\n",
      "Epoch 126/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0041 - acc: 0.9992 - val_loss: 1.9185 - val_acc: 0.6817\n",
      "Epoch 127/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0136 - acc: 0.9992 - val_loss: 1.8641 - val_acc: 0.6888\n",
      "Epoch 128/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.8449 - val_acc: 0.6924\n",
      "Epoch 129/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.6488e-04 - acc: 1.0000 - val_loss: 1.8318 - val_acc: 0.6853\n",
      "Epoch 130/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.1070e-04 - acc: 1.0000 - val_loss: 1.8161 - val_acc: 0.6871\n",
      "Epoch 131/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.9741e-04 - acc: 1.0000 - val_loss: 1.8056 - val_acc: 0.6817\n",
      "Epoch 132/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.6172e-04 - acc: 1.0000 - val_loss: 1.7986 - val_acc: 0.6835\n",
      "Epoch 133/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.9317e-04 - acc: 1.0000 - val_loss: 1.7927 - val_acc: 0.6817\n",
      "Epoch 134/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.2599e-04 - acc: 1.0000 - val_loss: 1.7712 - val_acc: 0.6871\n",
      "Epoch 135/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.7699e-04 - acc: 1.0000 - val_loss: 1.8089 - val_acc: 0.6906\n",
      "Epoch 136/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 1.8205 - val_acc: 0.6763\n",
      "Epoch 137/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 1.8353 - val_acc: 0.6781\n",
      "Epoch 138/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 1.8324 - val_acc: 0.6781\n",
      "Epoch 139/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.0728e-04 - acc: 1.0000 - val_loss: 1.8318 - val_acc: 0.6745\n",
      "Epoch 140/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.3009e-04 - acc: 1.0000 - val_loss: 1.8178 - val_acc: 0.6799\n",
      "Epoch 141/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.4889e-04 - acc: 1.0000 - val_loss: 1.8139 - val_acc: 0.6817\n",
      "Epoch 142/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.8924e-04 - acc: 1.0000 - val_loss: 1.8102 - val_acc: 0.6817\n",
      "Epoch 143/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.9149e-04 - acc: 1.0000 - val_loss: 1.8034 - val_acc: 0.6817\n",
      "Epoch 144/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.6865e-04 - acc: 1.0000 - val_loss: 1.7967 - val_acc: 0.6835\n",
      "Epoch 145/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.3640e-04 - acc: 1.0000 - val_loss: 1.7920 - val_acc: 0.6871\n",
      "Epoch 146/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.0079e-04 - acc: 1.0000 - val_loss: 1.7899 - val_acc: 0.6871\n",
      "Epoch 147/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.9960e-04 - acc: 1.0000 - val_loss: 1.7897 - val_acc: 0.6853\n",
      "Epoch 148/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0072 - acc: 0.9992 - val_loss: 1.8731 - val_acc: 0.6781\n",
      "Epoch 149/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 1.9801 - val_acc: 0.6853\n",
      "Epoch 150/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.9757 - val_acc: 0.6781\n",
      "Epoch 151/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0254 - acc: 0.9942 - val_loss: 2.0023 - val_acc: 0.6673\n",
      "Epoch 152/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1523 - acc: 0.9669 - val_loss: 2.4954 - val_acc: 0.6097\n",
      "Epoch 153/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1961 - acc: 0.9484 - val_loss: 2.7549 - val_acc: 0.5612\n",
      "Epoch 154/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.1799 - acc: 0.9526 - val_loss: 2.3558 - val_acc: 0.5935\n",
      "Epoch 155/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0961 - acc: 0.9746 - val_loss: 2.4737 - val_acc: 0.5917\n",
      "Epoch 156/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0441 - acc: 0.9884 - val_loss: 2.0958 - val_acc: 0.6493\n",
      "Epoch 157/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0175 - acc: 0.9961 - val_loss: 2.0613 - val_acc: 0.6403\n",
      "Epoch 158/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.0144 - acc: 0.9969 - val_loss: 2.0370 - val_acc: 0.6529\n",
      "Epoch 159/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 2.0367 - val_acc: 0.6511\n",
      "Epoch 160/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0112 - acc: 0.9988 - val_loss: 2.0512 - val_acc: 0.6529\n",
      "Epoch 161/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0151 - acc: 0.9965 - val_loss: 1.9975 - val_acc: 0.6511\n",
      "Epoch 162/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 1.9377 - val_acc: 0.6637\n",
      "Epoch 163/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 8.7697e-04 - acc: 1.0000 - val_loss: 1.9143 - val_acc: 0.6619\n",
      "Epoch 164/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 8.6828e-04 - acc: 1.0000 - val_loss: 1.9094 - val_acc: 0.6673\n",
      "Epoch 165/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 8.8632e-04 - acc: 1.0000 - val_loss: 1.8946 - val_acc: 0.6727\n",
      "Epoch 166/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 5.0125e-04 - acc: 1.0000 - val_loss: 1.8955 - val_acc: 0.6709\n",
      "Epoch 167/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.0330e-04 - acc: 1.0000 - val_loss: 1.8978 - val_acc: 0.6745\n",
      "Epoch 168/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 4.1496e-04 - acc: 1.0000 - val_loss: 1.8976 - val_acc: 0.6763\n",
      "Epoch 169/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 4.9273e-04 - acc: 1.0000 - val_loss: 1.9019 - val_acc: 0.6727\n",
      "Epoch 170/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 7.2095e-04 - acc: 1.0000 - val_loss: 1.9094 - val_acc: 0.6727\n",
      "Epoch 171/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.6342e-04 - acc: 1.0000 - val_loss: 1.9075 - val_acc: 0.6709\n",
      "Epoch 172/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.3117e-04 - acc: 1.0000 - val_loss: 1.9014 - val_acc: 0.6745\n",
      "Epoch 173/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.4392e-04 - acc: 1.0000 - val_loss: 1.8996 - val_acc: 0.6781\n",
      "Epoch 174/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 2.9473e-04 - acc: 1.0000 - val_loss: 1.9039 - val_acc: 0.6781\n",
      "Epoch 175/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 2.4324e-04 - acc: 1.0000 - val_loss: 1.9042 - val_acc: 0.6781\n",
      "Epoch 176/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.4514e-04 - acc: 1.0000 - val_loss: 1.9019 - val_acc: 0.6763\n",
      "Epoch 177/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.6727e-04 - acc: 1.0000 - val_loss: 1.8999 - val_acc: 0.6763\n",
      "Epoch 178/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.8964e-04 - acc: 1.0000 - val_loss: 1.9018 - val_acc: 0.6781\n",
      "Epoch 179/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.8482e-04 - acc: 1.0000 - val_loss: 1.9023 - val_acc: 0.6745\n",
      "Epoch 180/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.2845e-04 - acc: 1.0000 - val_loss: 1.9005 - val_acc: 0.6781\n",
      "Epoch 181/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.6807e-04 - acc: 1.0000 - val_loss: 1.9046 - val_acc: 0.6781\n",
      "Epoch 182/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.8398e-04 - acc: 1.0000 - val_loss: 1.9034 - val_acc: 0.6781\n",
      "Epoch 183/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.8047e-04 - acc: 1.0000 - val_loss: 1.9055 - val_acc: 0.6781\n",
      "Epoch 184/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.2112e-04 - acc: 1.0000 - val_loss: 1.9142 - val_acc: 0.6763\n",
      "Epoch 185/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.8195e-04 - acc: 1.0000 - val_loss: 1.9118 - val_acc: 0.6745\n",
      "Epoch 186/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.0320e-04 - acc: 1.0000 - val_loss: 1.9094 - val_acc: 0.6745\n",
      "Epoch 187/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.4184e-04 - acc: 1.0000 - val_loss: 1.9077 - val_acc: 0.6745\n",
      "Epoch 188/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.7845e-04 - acc: 1.0000 - val_loss: 1.9016 - val_acc: 0.6781\n",
      "Epoch 189/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.6719e-04 - acc: 1.0000 - val_loss: 1.8953 - val_acc: 0.6781\n",
      "Epoch 190/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.2849e-04 - acc: 1.0000 - val_loss: 1.8965 - val_acc: 0.6781\n",
      "Epoch 191/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.4442e-04 - acc: 1.0000 - val_loss: 1.8978 - val_acc: 0.6781\n",
      "Epoch 192/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.3576e-04 - acc: 1.0000 - val_loss: 1.9037 - val_acc: 0.6781\n",
      "Epoch 193/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.3053e-04 - acc: 1.0000 - val_loss: 1.9071 - val_acc: 0.6781\n",
      "Epoch 194/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.3007e-04 - acc: 1.0000 - val_loss: 1.9092 - val_acc: 0.6763\n",
      "Epoch 195/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 1.3245e-04 - acc: 1.0000 - val_loss: 1.9112 - val_acc: 0.6763\n",
      "Epoch 196/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 1.1450e-04 - acc: 1.0000 - val_loss: 1.9144 - val_acc: 0.6763\n",
      "Epoch 197/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 9.1080e-05 - acc: 1.0000 - val_loss: 1.9157 - val_acc: 0.6763\n",
      "Epoch 198/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 9.6342e-05 - acc: 1.0000 - val_loss: 1.9179 - val_acc: 0.6763\n",
      "Epoch 199/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.2705e-04 - acc: 1.0000 - val_loss: 1.9274 - val_acc: 0.6763\n",
      "Epoch 200/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.1199e-04 - acc: 1.0000 - val_loss: 1.9288 - val_acc: 0.6781\n",
      "Epoch 201/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.2014e-04 - acc: 1.0000 - val_loss: 1.9291 - val_acc: 0.6781\n",
      "Epoch 202/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 8.8373e-05 - acc: 1.0000 - val_loss: 1.9290 - val_acc: 0.6763\n",
      "Epoch 203/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.0829e-04 - acc: 1.0000 - val_loss: 1.9315 - val_acc: 0.6817\n",
      "Epoch 204/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 9.6481e-05 - acc: 1.0000 - val_loss: 1.9307 - val_acc: 0.6817\n",
      "Epoch 205/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 8.3324e-05 - acc: 1.0000 - val_loss: 1.9305 - val_acc: 0.6799\n",
      "Epoch 206/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 1.0484e-04 - acc: 1.0000 - val_loss: 1.9298 - val_acc: 0.6817\n",
      "Epoch 207/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.3363e-04 - acc: 1.0000 - val_loss: 1.9336 - val_acc: 0.6781\n",
      "Epoch 208/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 7.3985e-05 - acc: 1.0000 - val_loss: 1.9376 - val_acc: 0.6799\n",
      "Epoch 209/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 7.8914e-05 - acc: 1.0000 - val_loss: 1.9404 - val_acc: 0.6781\n",
      "Epoch 210/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 7.2546e-05 - acc: 1.0000 - val_loss: 1.9457 - val_acc: 0.6781\n",
      "Epoch 211/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.8465e-05 - acc: 1.0000 - val_loss: 1.9463 - val_acc: 0.6781\n",
      "Epoch 212/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.2568e-05 - acc: 1.0000 - val_loss: 1.9480 - val_acc: 0.6781\n",
      "Epoch 213/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 8.2060e-05 - acc: 1.0000 - val_loss: 1.9456 - val_acc: 0.6799\n",
      "Epoch 214/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.0009e-05 - acc: 1.0000 - val_loss: 1.9465 - val_acc: 0.6817\n",
      "Epoch 215/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 1.0369e-04 - acc: 1.0000 - val_loss: 1.9659 - val_acc: 0.6763\n",
      "Epoch 216/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.7815e-05 - acc: 1.0000 - val_loss: 1.9667 - val_acc: 0.6763\n",
      "Epoch 217/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.0167e-05 - acc: 1.0000 - val_loss: 1.9639 - val_acc: 0.6763\n",
      "Epoch 218/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 7.1383e-05 - acc: 1.0000 - val_loss: 1.9682 - val_acc: 0.6745\n",
      "Epoch 219/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.7054e-05 - acc: 1.0000 - val_loss: 1.9690 - val_acc: 0.6763\n",
      "Epoch 220/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.3702e-05 - acc: 1.0000 - val_loss: 1.9702 - val_acc: 0.6763\n",
      "Epoch 221/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.2825e-05 - acc: 1.0000 - val_loss: 1.9705 - val_acc: 0.6763\n",
      "Epoch 222/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.5676e-04 - acc: 1.0000 - val_loss: 1.9849 - val_acc: 0.6727\n",
      "Epoch 223/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 9.6388e-05 - acc: 1.0000 - val_loss: 1.9875 - val_acc: 0.6673\n",
      "Epoch 224/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.0223e-05 - acc: 1.0000 - val_loss: 1.9948 - val_acc: 0.6691\n",
      "Epoch 225/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.0868e-05 - acc: 1.0000 - val_loss: 1.9981 - val_acc: 0.6673\n",
      "Epoch 226/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 5.9979e-05 - acc: 1.0000 - val_loss: 1.9865 - val_acc: 0.6763\n",
      "Epoch 227/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.4488e-05 - acc: 1.0000 - val_loss: 1.9893 - val_acc: 0.6799\n",
      "Epoch 228/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 7.6784e-05 - acc: 1.0000 - val_loss: 2.0056 - val_acc: 0.6745\n",
      "Epoch 229/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.1678e-05 - acc: 1.0000 - val_loss: 2.0219 - val_acc: 0.6709\n",
      "Epoch 230/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 4.4731e-05 - acc: 1.0000 - val_loss: 2.0227 - val_acc: 0.6709\n",
      "Epoch 231/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 4.0782e-05 - acc: 1.0000 - val_loss: 2.0202 - val_acc: 0.6727\n",
      "Epoch 232/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 4.8311e-05 - acc: 1.0000 - val_loss: 2.0225 - val_acc: 0.6727\n",
      "Epoch 233/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.5777e-05 - acc: 1.0000 - val_loss: 2.0222 - val_acc: 0.6745\n",
      "Epoch 234/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.0751e-05 - acc: 1.0000 - val_loss: 2.0246 - val_acc: 0.6763\n",
      "Epoch 235/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.8813e-05 - acc: 1.0000 - val_loss: 2.0239 - val_acc: 0.6763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.8705e-05 - acc: 1.0000 - val_loss: 2.0220 - val_acc: 0.6763\n",
      "Epoch 237/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.4239e-05 - acc: 1.0000 - val_loss: 2.0226 - val_acc: 0.6763\n",
      "Epoch 238/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.7645e-05 - acc: 1.0000 - val_loss: 2.0247 - val_acc: 0.6781\n",
      "Epoch 239/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 4.4471e-05 - acc: 1.0000 - val_loss: 2.0435 - val_acc: 0.6781\n",
      "Epoch 240/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 4.1508e-05 - acc: 1.0000 - val_loss: 2.0455 - val_acc: 0.6763\n",
      "Epoch 241/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.4458e-05 - acc: 1.0000 - val_loss: 2.0464 - val_acc: 0.6763\n",
      "Epoch 242/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.0724e-05 - acc: 1.0000 - val_loss: 2.0530 - val_acc: 0.6745\n",
      "Epoch 243/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.6162e-05 - acc: 1.0000 - val_loss: 2.0531 - val_acc: 0.6763\n",
      "Epoch 244/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.5323e-05 - acc: 1.0000 - val_loss: 2.0531 - val_acc: 0.6781\n",
      "Epoch 245/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.6033e-05 - acc: 1.0000 - val_loss: 2.0482 - val_acc: 0.6781\n",
      "Epoch 246/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.7155e-05 - acc: 1.0000 - val_loss: 2.0508 - val_acc: 0.6781\n",
      "Epoch 247/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.9035e-05 - acc: 1.0000 - val_loss: 2.0522 - val_acc: 0.6727\n",
      "Epoch 248/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.9365e-05 - acc: 1.0000 - val_loss: 2.0537 - val_acc: 0.6745\n",
      "Epoch 249/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.7627e-05 - acc: 1.0000 - val_loss: 2.0742 - val_acc: 0.6745\n",
      "Epoch 250/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.9209e-05 - acc: 1.0000 - val_loss: 2.0709 - val_acc: 0.6745\n",
      "Epoch 251/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.2376e-05 - acc: 1.0000 - val_loss: 2.0667 - val_acc: 0.6727\n",
      "Epoch 252/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 6.4305e-05 - acc: 1.0000 - val_loss: 2.0531 - val_acc: 0.6817\n",
      "Epoch 253/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.1612e-05 - acc: 1.0000 - val_loss: 2.0498 - val_acc: 0.6817\n",
      "Epoch 254/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.0897e-05 - acc: 1.0000 - val_loss: 2.0443 - val_acc: 0.6835\n",
      "Epoch 255/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 2.6918e-05 - acc: 1.0000 - val_loss: 2.0474 - val_acc: 0.6835\n",
      "Epoch 256/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.9515e-05 - acc: 1.0000 - val_loss: 2.0440 - val_acc: 0.6871\n",
      "Epoch 257/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.2597e-05 - acc: 1.0000 - val_loss: 2.0454 - val_acc: 0.6853\n",
      "Epoch 258/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 3.0723e-05 - acc: 1.0000 - val_loss: 2.0396 - val_acc: 0.6853\n",
      "Epoch 259/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.6868e-05 - acc: 1.0000 - val_loss: 2.0516 - val_acc: 0.6781\n",
      "Epoch 260/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.4791e-05 - acc: 1.0000 - val_loss: 2.0572 - val_acc: 0.6763\n",
      "Epoch 261/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.8865e-05 - acc: 1.0000 - val_loss: 2.0571 - val_acc: 0.6799\n",
      "Epoch 262/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.4805e-05 - acc: 1.0000 - val_loss: 2.0536 - val_acc: 0.6835\n",
      "Epoch 263/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.7431e-05 - acc: 1.0000 - val_loss: 2.0500 - val_acc: 0.6817\n",
      "Epoch 264/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.6196e-05 - acc: 1.0000 - val_loss: 2.0474 - val_acc: 0.6817\n",
      "Epoch 265/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.6810e-05 - acc: 1.0000 - val_loss: 2.0588 - val_acc: 0.6799\n",
      "Epoch 266/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 2.0754e-05 - acc: 1.0000 - val_loss: 2.0592 - val_acc: 0.6835\n",
      "Epoch 267/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 2.5156e-05 - acc: 1.0000 - val_loss: 2.0564 - val_acc: 0.6835\n",
      "Epoch 268/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.9845e-05 - acc: 1.0000 - val_loss: 2.0545 - val_acc: 0.6799\n",
      "Epoch 269/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.8457e-05 - acc: 1.0000 - val_loss: 2.0539 - val_acc: 0.6817\n",
      "Epoch 270/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.5570e-05 - acc: 1.0000 - val_loss: 2.0563 - val_acc: 0.6835\n",
      "Epoch 271/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.8003e-05 - acc: 1.0000 - val_loss: 2.0605 - val_acc: 0.6817\n",
      "Epoch 272/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.2131e-05 - acc: 1.0000 - val_loss: 2.0612 - val_acc: 0.6817\n",
      "Epoch 273/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.5170e-05 - acc: 1.0000 - val_loss: 2.0649 - val_acc: 0.6817\n",
      "Epoch 274/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.5837e-05 - acc: 1.0000 - val_loss: 2.0637 - val_acc: 0.6835\n",
      "Epoch 275/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.2071e-05 - acc: 1.0000 - val_loss: 2.0642 - val_acc: 0.6835\n",
      "Epoch 276/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.7171e-05 - acc: 1.0000 - val_loss: 2.0649 - val_acc: 0.6853\n",
      "Epoch 277/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.2897e-05 - acc: 1.0000 - val_loss: 2.0666 - val_acc: 0.6853\n",
      "Epoch 278/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 1.4351e-05 - acc: 1.0000 - val_loss: 2.0648 - val_acc: 0.6853\n",
      "Epoch 279/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.2442e-05 - acc: 1.0000 - val_loss: 2.0656 - val_acc: 0.6853\n",
      "Epoch 280/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.3077e-05 - acc: 1.0000 - val_loss: 2.0751 - val_acc: 0.6853\n",
      "Epoch 281/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 1.4163e-05 - acc: 1.0000 - val_loss: 2.0799 - val_acc: 0.6871\n",
      "Epoch 282/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.0222e-05 - acc: 1.0000 - val_loss: 2.0800 - val_acc: 0.6835\n",
      "Epoch 283/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.3268e-05 - acc: 1.0000 - val_loss: 2.0820 - val_acc: 0.6853\n",
      "Epoch 284/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.1436e-05 - acc: 1.0000 - val_loss: 2.0810 - val_acc: 0.6835\n",
      "Epoch 285/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.0489e-05 - acc: 1.0000 - val_loss: 2.0849 - val_acc: 0.6853\n",
      "Epoch 286/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.0586e-05 - acc: 1.0000 - val_loss: 2.0874 - val_acc: 0.6853\n",
      "Epoch 287/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.3273e-05 - acc: 1.0000 - val_loss: 2.0864 - val_acc: 0.6853\n",
      "Epoch 288/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.1572e-05 - acc: 1.0000 - val_loss: 2.0903 - val_acc: 0.6817\n",
      "Epoch 289/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 9.9485e-06 - acc: 1.0000 - val_loss: 2.0948 - val_acc: 0.6817\n",
      "Epoch 290/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 1.1237e-05 - acc: 1.0000 - val_loss: 2.0960 - val_acc: 0.6817\n",
      "Epoch 291/300\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 8.5299e-06 - acc: 1.0000 - val_loss: 2.0959 - val_acc: 0.6817\n",
      "Epoch 292/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 8.3236e-06 - acc: 1.0000 - val_loss: 2.0961 - val_acc: 0.6835\n",
      "Epoch 293/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 8.7563e-06 - acc: 1.0000 - val_loss: 2.1022 - val_acc: 0.6835\n",
      "Epoch 294/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 8.7907e-06 - acc: 1.0000 - val_loss: 2.1052 - val_acc: 0.6835\n",
      "Epoch 295/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 7.6326e-06 - acc: 1.0000 - val_loss: 2.1101 - val_acc: 0.6835\n",
      "Epoch 296/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 7.5075e-06 - acc: 1.0000 - val_loss: 2.1123 - val_acc: 0.6835\n",
      "Epoch 297/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 1.1251e-05 - acc: 1.0000 - val_loss: 2.1146 - val_acc: 0.6835\n",
      "Epoch 298/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 9.0477e-06 - acc: 1.0000 - val_loss: 2.1119 - val_acc: 0.6835\n",
      "Epoch 299/300\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 5.3960e-06 - acc: 1.0000 - val_loss: 2.1120 - val_acc: 0.6835\n",
      "Epoch 300/300\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 8.3163e-06 - acc: 1.0000 - val_loss: 2.1129 - val_acc: 0.6835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f396f8ac6d8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model4.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=300,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 0s 701us/step\n",
      "[2.188842976756755, 0.6894075425351758]\n"
     ]
    }
   ],
   "source": [
    "conv_result4 = conv_model4.evaluate(x_test, y_test, batch_size=150)\n",
    "print(conv_result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 40, 512)           1772032   \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 40, 512)           2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 13, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 5, 512)            5243392   \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 5, 512)            2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 1, 1024)           4198400   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1, 173)            177325    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 1, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 1, 256)            886016    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 41)                10537     \n",
      "=================================================================\n",
      "Total params: 12,293,514\n",
      "Trainable params: 12,290,608\n",
      "Non-trainable params: 2,906\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model5 = Sequential([\n",
    "    Convolution1D(512,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=1),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Convolution1D(512,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=3),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(512, return_sequences=True)),\n",
    "    Dense(173, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(256,20, padding=\"same\",strides=3),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.3),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model5.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/4\n",
      "2597/2597 [==============================] - 88s 34ms/step - loss: 0.0677 - acc: 0.9815 - val_loss: 1.8499 - val_acc: 0.6331\n",
      "Epoch 2/4\n",
      "2597/2597 [==============================] - 71s 27ms/step - loss: 0.0719 - acc: 0.9800 - val_loss: 1.8130 - val_acc: 0.6421\n",
      "Epoch 3/4\n",
      "2597/2597 [==============================] - 97s 37ms/step - loss: 0.0941 - acc: 0.9730 - val_loss: 1.9676 - val_acc: 0.6349\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-5047df33a8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m conv_model5.fit(x_train, y_train,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_model5.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=4,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 2ms/step\n",
      "[1.9122092745248462, 0.6247755835899544]\n"
     ]
    }
   ],
   "source": [
    "conv_result5 = conv_model5.evaluate(x_test, y_test, batch_size=150)\n",
    "print(conv_result5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 40, 512)           1772032   \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 40, 512)           2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 13, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5, 512)            5243392   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 5, 512)            2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 1, 1024)           4198400   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1, 173)            177325    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 1, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 1, 512)            1772032   \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 41)                21033     \n",
      "=================================================================\n",
      "Total params: 13,191,050\n",
      "Trainable params: 13,187,632\n",
      "Non-trainable params: 3,418\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model6 = Sequential([\n",
    "    Convolution1D(512,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=1),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Convolution1D(512,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=3),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(512, return_sequences=True)),\n",
    "    Dense(173, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(512,20, padding=\"same\",strides=3),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.5),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model6.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/2\n",
      "2597/2597 [==============================] - 79s 30ms/step - loss: 0.0280 - acc: 0.9935 - val_loss: 2.5989 - val_acc: 0.6583\n",
      "Epoch 2/2\n",
      "2597/2597 [==============================] - 77s 30ms/step - loss: 0.0382 - acc: 0.9896 - val_loss: 2.7066 - val_acc: 0.6403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39386bd8d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model6.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=2,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 2ms/step\n",
      "[2.2103289517722824, 0.671454220100622]\n"
     ]
    }
   ],
   "source": [
    "conv_result6 = conv_model6.evaluate(x_test, y_test, batch_size=50)\n",
    "print(conv_result5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(Sequence):\n",
    "    \"\"\"\n",
    "    See [4], [5] to understand how data generators work.\n",
    "    CURRENTLY: This generator does work, but need to fix all MFCC getting related functions\n",
    "    to properly deal with our data format (and finish some of them)\n",
    "    \"\"\"\n",
    "    def __init__(self, x, labels, batch_size=2, FFT_size=2048, sr=44100):\n",
    "        self.x, self.y= x, labels\n",
    "        self.batch_size=batch_size\n",
    "        self.FFT_size = FFT_size\n",
    "        self.sr = sr\n",
    "        \n",
    "    def frame(self, audio, hop_size=10):\n",
    "        \"\"\"     \n",
    "        Convert batch of time series to batch of audio frame\n",
    "        Not currently working fully for batches, there is a cell below for\n",
    "        playing with this.\n",
    "        Taken from https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial\n",
    "        hop_size in ms\n",
    "        \"\"\"\n",
    "        audio = np.pad(audio, int(self.FFT_size / 2), mode='reflect')\n",
    "        frame_len = np.round(self.sr * hop_size / 1000).astype(int)\n",
    "        frame_num = int((len(audio) - self.FFT_size) / frame_len) + 1\n",
    "        frames = np.zeros((frame_num, self.FFT_size))\n",
    "\n",
    "        for n in range(frame_num):\n",
    "            frames[n] = audio[n*frame_len:n*frame_len+self.FFT_size]\n",
    "\n",
    "        return frames\n",
    "    \n",
    "    def freq_domain(self, frames):\n",
    "        # Convert audio frame into frequency domain\n",
    "        window = get_window(\"hann\", self.FFT_size, fftbins=True)\n",
    "        wins=[]\n",
    "        for frame in frames:\n",
    "            wins.append(frame*window)\n",
    "        return np.array(wins)\n",
    "    \n",
    "    def mfcc(self, frames):\n",
    "        # Given frequency domains, get the MFCCs\n",
    "        # Code for this function heavily based on https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "        NFFT=512\n",
    "        nfilt=41\n",
    "        num_ceps=41\n",
    "        cep_lifter = 22 # cep_lifter is a parameter typically set to 22 in most implementations. \n",
    "                        #However, it refers to the dimensionality of the MFCC vector in the original formulation\n",
    "        # First, we need to do an N point FFT on each of our frames to get the frequency spectrum\n",
    "        mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
    "        pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
    "        \n",
    "        # The final step before getting our MFCCs is to compute our filter banks\n",
    "        low_freq_mel = 0\n",
    "        high_freq_mel = (2595 * np.log10(1 + (self.sr / 2) / 700))  # Convert Hz to Mel\n",
    "        mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
    "        hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "        bin = np.floor((NFFT + 1) * hz_points / self.sr)\n",
    "\n",
    "        fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
    "        for m in range(1, nfilt + 1):\n",
    "            f_m_minus = int(bin[m - 1])   # left\n",
    "            f_m = int(bin[m])             # center\n",
    "            f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "            for k in range(f_m_minus, f_m):\n",
    "                fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "            for k in range(f_m, f_m_plus):\n",
    "                fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "        filter_banks = np.dot(pow_frames, fbank.T)\n",
    "        filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "        filter_banks = 20 * np.log10(filter_banks)  # dB\n",
    "        \n",
    "        mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13\n",
    "        (nframes, ncoeff) = mfcc.shape\n",
    "        n = np.arange(ncoeff)\n",
    "        lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)\n",
    "        mfcc *= lift  #*\n",
    "        \n",
    "        filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)\n",
    "        mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
    "        \n",
    "        return mfcc\n",
    "\n",
    "    def get_mfcc(self, batch):\n",
    "        \"\"\" \n",
    "        Given a batch of data X, we have n rows. Each row contains\n",
    "        a time series. Each of these time series needs to be converted to an audio frame and then\n",
    "        to a frequency domain. We can then use that to filter and extract useful MFCC features. \n",
    "        See [1], [2], [3].\n",
    "        \"\"\"\n",
    "        # Convert batch to MFCCs\n",
    "        \n",
    "        # First, get the frames\n",
    "        frames=[]\n",
    "        for series in batch:\n",
    "            fr=self.frame(series) # Get the frame. Our X dimension will not be the same for all - take note.\n",
    "            frames.append(fr)\n",
    "        \n",
    "        frames = np.array(frames)\n",
    "        \n",
    "        # Given frames, convert these to frequency\n",
    "        freq = self.freq_domain(frames)\n",
    "        \n",
    "        # Given freq domain, we can finally extract the MFCCs\n",
    "        mfccs=self.mfcc(freq)\n",
    "        \n",
    "        return freq\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        tmp_x=self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Pass x batch to get transformed\n",
    "        batch_x=self.get_mfcc(tmp_x)\n",
    "        \n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [-33, -32, -34, -34, -37, -37, -39, -39, -41, ...\n",
       "3    [0, 10, 39, -66, -49, 29, 4, -57, -133, -158, ...\n",
       "4    [-173, -162, -172, -142, -170, -139, -139, -13...\n",
       "Name: time_series, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifiedData['time_series'].iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sizes:\n",
      "(2597, 40, 173)\n",
      "(2597, 41)\n",
      "\n",
      "Validation sizes:\n",
      "(556, 40, 173)\n",
      "(556, 41)\n",
      "\n",
      "Test sizes:\n",
      "(557, 40, 173)\n",
      "(557, 41)\n"
     ]
    }
   ],
   "source": [
    "yt2=encode(verifiedData.label.values, oneHot=True)\n",
    "# Get validation set - keep 70% for train, 15% validation, 15% test\n",
    "training_size = int(len(verifiedData['time_series']) * 0.7)\n",
    "validate_size = int(len(verifiedData['time_series']) * 0.15)\n",
    "\n",
    "x_train2=verifiedData['time_series'].iloc[:training_size] # shape (2968, 40, 28)\n",
    "x_val2=verifiedData['time_series'].iloc[training_size:training_size+validate_size] # shape (742, 40, 28)\n",
    "x_test2=verifiedData['time_series'].iloc[training_size+validate_size:]\n",
    "\n",
    "y_train2=yt[:training_size] # shape 2968, 41\n",
    "y_val2=yt[training_size:training_size+validate_size] # shape 742, 41\n",
    "y_test2=yt[training_size+validate_size:]\n",
    "\n",
    "print ('Train sizes:')\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "print ('\\nValidation sizes:')\n",
    "print (x_val.shape)\n",
    "print (y_val.shape)\n",
    "\n",
    "print ('\\nTest sizes:')\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = DataGen(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import get_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 40, 1024)          8858624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 13, 1024)          16785408  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13, 173)           177325    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 173)           692       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5, 256)            2214656   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 128)            655488    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 41)                5289      \n",
      "=================================================================\n",
      "Total params: 28,703,114\n",
      "Trainable params: 28,699,952\n",
      "Non-trainable params: 3,162\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model4 = Sequential([\n",
    "    Convolution1D(1024,50, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=1),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(1024, return_sequences=True),merge_mode='mul'),\n",
    "    Dense(173, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(256,50, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=3),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    \n",
    "    Convolution1D(128,20, padding=\"same\",strides=3),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.5),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/10\n",
      "2597/2597 [==============================] - 199s 77ms/step - loss: 3.5797 - acc: 0.1517 - val_loss: 3.5346 - val_acc: 0.2158\n",
      "Epoch 2/10\n",
      "2597/2597 [==============================] - 194s 75ms/step - loss: 2.8255 - acc: 0.2603 - val_loss: 2.6081 - val_acc: 0.2986\n",
      "Epoch 3/10\n",
      "2597/2597 [==============================] - 196s 75ms/step - loss: 2.4463 - acc: 0.3504 - val_loss: 2.6100 - val_acc: 0.3687\n",
      "Epoch 4/10\n",
      "2597/2597 [==============================] - 202s 78ms/step - loss: 2.1487 - acc: 0.4143 - val_loss: 2.1597 - val_acc: 0.4191\n",
      "Epoch 5/10\n",
      "2597/2597 [==============================] - 210s 81ms/step - loss: 1.9278 - acc: 0.4690 - val_loss: 2.1866 - val_acc: 0.4424\n",
      "Epoch 6/10\n",
      "2597/2597 [==============================] - 200s 77ms/step - loss: 1.6258 - acc: 0.5395 - val_loss: 1.9860 - val_acc: 0.4658\n",
      "Epoch 7/10\n",
      "2597/2597 [==============================] - 177s 68ms/step - loss: 1.4224 - acc: 0.5957 - val_loss: 2.0138 - val_acc: 0.4784\n",
      "Epoch 8/10\n",
      "2597/2597 [==============================] - 182s 70ms/step - loss: 1.1545 - acc: 0.6704 - val_loss: 1.7876 - val_acc: 0.5306\n",
      "Epoch 9/10\n",
      "2597/2597 [==============================] - 181s 70ms/step - loss: 0.9274 - acc: 0.7255 - val_loss: 1.7783 - val_acc: 0.5342\n",
      "Epoch 10/10\n",
      "2597/2597 [==============================] - 188s 72ms/step - loss: 0.7958 - acc: 0.7601 - val_loss: 1.6693 - val_acc: 0.6007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd0b4b8ec88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model4.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=10,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 7s 13ms/step\n",
      "[1.67906149306888, 0.5888689454624854]\n"
     ]
    }
   ],
   "source": [
    "conv_result4 = conv_model4.evaluate(x_test, y_test, batch_size=50)\n",
    "print(conv_result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 100, 256)          886016    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100, 256)          1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 33, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 11, 256)           1310976   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 11, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 3, 512)            1050624   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3, 173)            88749     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 3, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1, 128)            443008    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 41)                5289      \n",
      "=================================================================\n",
      "Total params: 3,787,914\n",
      "Trainable params: 3,786,288\n",
      "Non-trainable params: 1,626\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model4 = Sequential([\n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=1),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2]),\\\n",
    "                 activation='relu',strides=3),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dense(173, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(128,20, padding=\"same\",strides=3),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.5),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/5\n",
      "2597/2597 [==============================] - 24s 9ms/step - loss: 0.0781 - acc: 0.9804 - val_loss: 2.0776 - val_acc: 0.5701\n",
      "Epoch 2/5\n",
      "2597/2597 [==============================] - 26s 10ms/step - loss: 0.1176 - acc: 0.9669 - val_loss: 2.3022 - val_acc: 0.5072\n",
      "Epoch 3/5\n",
      "2597/2597 [==============================] - 26s 10ms/step - loss: 0.1146 - acc: 0.9700 - val_loss: 2.0809 - val_acc: 0.5665\n",
      "Epoch 4/5\n",
      "2597/2597 [==============================] - 25s 9ms/step - loss: 0.0899 - acc: 0.9757 - val_loss: 1.9896 - val_acc: 0.5935\n",
      "Epoch 5/5\n",
      "2597/2597 [==============================] - 25s 9ms/step - loss: 0.0994 - acc: 0.9730 - val_loss: 1.7761 - val_acc: 0.6043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfab2e8b00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model4.fit(x_train, y_train,\n",
    "          batch_size=50, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 2ms/step\n",
      "[1.9560620211185202, 0.5870735935291653]\n"
     ]
    }
   ],
   "source": [
    "conv_result4 = conv_model4.evaluate(x_test, y_test, batch_size=150)\n",
    "print(conv_result4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
