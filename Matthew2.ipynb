{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import constants\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import IPython\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy.io import wavfile\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Embedding,Conv3D,Bidirectional\n",
    "from keras.layers import (Convolution1D, Convolution2D,Convolution3D,GlobalAveragePooling1D,GlobalAveragePooling2D, \n",
    "                          BatchNormalization, Flatten,\n",
    "                          GlobalMaxPool1D,LeakyReLU,GlobalMaxPool3D,\n",
    "                          MaxPool1D,MaxPool2D,MaxPool3D, Flatten, concatenate, Activation,ELU)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav_loc = \"../audio_train/\"\n",
    "test_wav_loc = \"../audio_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\",header=0,names=['name','label','verified'])\n",
    "verifiedData = dataset.loc[dataset.verified == 1,[\"name\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(verifiedData['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=44100\n",
    "# Based on https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis?scriptVersionId=3019309\n",
    "def load_wav_file(name):\n",
    "    _, b = wavfile.read(train_wav_loc + name)\n",
    "    assert _ == sample_rate\n",
    "    return b\n",
    "\n",
    "verifiedData['time_series'] = verifiedData['name'].apply(load_wav_file)\n",
    "verifiedData['nframes'] = verifiedData['time_series'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_estimator(df):\n",
    "    temp_df = []\n",
    "    for i in df:\n",
    "        temp_df.append(0.5*(np.tanh(0.01*(i-np.mean(i))/np.std(i))+ 1)) \n",
    "    return temp_df\n",
    "    #return (df - df.mean(axis=0)) / (df.std(axis=0))\n",
    "\n",
    "    \n",
    "def getData(df, wav_path,train=True):\n",
    "    dset=[]\n",
    "    audiolen=2*sample_rate\n",
    "    \n",
    "    if train==False:\n",
    "        ddir=data_loc+\"audio_test/\"\n",
    "        files=[f for f in listdir(ddir) if isfile(join(testpath, f))]\n",
    "    else:\n",
    "        ddir=wav_path\n",
    "        files=df.name.values\n",
    "    \n",
    "    for file in files:\n",
    "        wav,_= librosa.core.load(ddir+file, sr=sample_rate)\n",
    "        \n",
    "        # Pad/trim WAV data\n",
    "        if len(wav) > audiolen:\n",
    "            wav = wav[:audiolen]\n",
    "        elif len(wav) < audiolen:\n",
    "            off=audiolen - len(wav) \n",
    "            wav=np.pad(wav, (off, audiolen - len(wav) - off), 'constant')\n",
    "            \n",
    "        mfcc = librosa.feature.mfcc(wav, sr = sample_rate, n_mfcc=40)\n",
    "        dset.append(mfcc)\n",
    "    \n",
    "    return (tanh_estimator(np.array(dset))) # Return normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_estimator(df):\n",
    "    return (df - df.mean(axis=0)) / (df.std(axis=0))\n",
    "\n",
    "    \n",
    "def getData2(df, wav_path,train=True):\n",
    "    dset=[]\n",
    "    audiolen=2*sample_rate\n",
    "    \n",
    "    if train==False:\n",
    "        ddir=data_loc+\"audio_test/\"\n",
    "        files=[f for f in listdir(ddir) if isfile(join(testpath, f))]\n",
    "    else:\n",
    "        ddir=wav_path\n",
    "        files=df.name.values\n",
    "    \n",
    "    for file in files:\n",
    "        wav,_= librosa.core.load(ddir+file, sr=sample_rate)\n",
    "        \n",
    "        # Pad/trim WAV data\n",
    "        if len(wav) > audiolen:\n",
    "            wav = wav[:audiolen]\n",
    "        elif len(wav) < audiolen:\n",
    "            off=audiolen - len(wav) \n",
    "            wav=np.pad(wav, (off, audiolen - len(wav) - off), 'constant')\n",
    "            \n",
    "        mfcc = librosa.feature.melspectrogram(wav, sr = sample_rate)\n",
    "        dset.append(mfcc)\n",
    "    \n",
    "    return (tanh_estimator(np.array(dset))) # Return normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-5.51071725e+02 -5.48230601e+02 -5.50604943e+02 ... -3.13616739e+02\n",
      "   -2.79579421e+02 -2.41716183e+02]\n",
      "  [ 8.12112048e+01  8.35118348e+01  8.11529295e+01 ...  1.69817914e+02\n",
      "    2.11521237e+02  2.28720407e+02]\n",
      "  [ 7.49453576e+00  5.95448473e+00  3.43608728e+00 ... -6.87291967e+01\n",
      "   -3.98055192e+01 -2.64086023e+01]\n",
      "  ...\n",
      "  [ 7.78239823e+00  6.46160817e+00  2.95491671e+00 ...  2.66865271e+01\n",
      "    1.27676483e+01  3.97639425e+00]\n",
      "  [ 2.75955950e+00  2.27997409e+00  1.55283725e+00 ... -1.69544508e+00\n",
      "   -9.45686653e+00 -1.09585406e+01]\n",
      "  [-2.87850891e-01 -1.16869237e+00 -7.46875017e-01 ... -1.77553427e+01\n",
      "   -1.91719061e+01 -1.26074113e+01]]\n",
      "\n",
      " [[-2.66613791e+02 -3.14772225e+02 -4.56226166e+02 ... -7.67030993e+02\n",
      "   -7.46648208e+02 -7.06407422e+02]\n",
      "  [-1.30817772e+00  3.70002406e+00  8.90681810e+00 ...  2.85422603e+01\n",
      "    5.06317229e+01  9.14606479e+01]\n",
      "  [-1.43385265e+02 -1.33259042e+02 -9.78326385e+01 ... -5.03349569e-01\n",
      "    5.98699270e+00  1.51138550e+01]\n",
      "  ...\n",
      "  [ 1.74359887e+00 -1.30906879e+00 -8.85007180e+00 ...  8.14961709e+00\n",
      "    5.06060548e+00  2.82005115e+00]\n",
      "  [ 4.04178891e+00  2.65692958e+00  6.60479719e+00 ...  1.34246168e+01\n",
      "    1.07339795e+01  9.83427275e+00]\n",
      "  [ 7.70413380e+00  6.74251619e+00  1.68199627e+01 ...  1.12037325e+01\n",
      "    9.25095823e+00  8.27865667e+00]]\n",
      "\n",
      " [[-5.03101562e+02 -4.97304941e+02 -4.92827380e+02 ... -2.74081426e+02\n",
      "   -2.49460270e+02 -2.33544466e+02]\n",
      "  [ 9.14130038e+01  9.73877472e+01  9.93207810e+01 ...  1.50730040e+02\n",
      "    1.81652756e+02  2.00672957e+02]\n",
      "  [ 2.25421649e+01  2.16233762e+01  1.93880270e+01 ... -5.48155713e+01\n",
      "   -4.56251671e+01 -4.19451558e+01]\n",
      "  ...\n",
      "  [ 3.11491522e+00  3.63064427e+00  3.19141052e+00 ... -1.26077018e+01\n",
      "   -5.41335365e+00 -6.20296150e-01]\n",
      "  [ 9.54515849e+00  9.95121097e+00  1.07655507e+01 ... -1.70956058e+01\n",
      "   -9.82244660e+00 -6.12625633e+00]\n",
      "  [ 8.82553466e+00  5.80739050e+00  5.26506100e+00 ... -1.00701775e+01\n",
      "   -3.20472728e+00  1.25880108e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.00057224e+02 -2.90217766e+02 -2.78364281e+02 ... -2.46015265e+02\n",
      "   -2.84710168e+02 -2.96398791e+02]\n",
      "  [ 6.68990603e+01  9.41054308e+01  1.12070673e+02 ...  5.66569912e+01\n",
      "    6.75213076e+01  7.67996112e+01]\n",
      "  [-3.15700972e+01 -2.40155037e+01 -3.21867758e+01 ... -5.34000317e+01\n",
      "   -4.54060368e+01 -4.10608019e+01]\n",
      "  ...\n",
      "  [-7.69723234e+00 -2.25384770e+00 -2.24054765e+00 ... -4.02368158e+00\n",
      "   -8.38304414e+00 -4.40911852e+00]\n",
      "  [-6.84528111e+00 -2.82026334e+00 -2.02948905e+00 ... -1.05961710e+01\n",
      "   -9.61783558e+00 -9.80342414e+00]\n",
      "  [-4.06558407e-01 -1.55443076e+00 -3.65095509e+00 ...  1.49057679e+00\n",
      "    3.33648532e+00  6.11579323e+00]]\n",
      "\n",
      " [[-5.74785303e+02 -5.71610521e+02 -5.70596988e+02 ... -5.63259392e+02\n",
      "   -5.61536852e+02 -5.63127713e+02]\n",
      "  [ 4.32946125e+01  4.71917921e+01  4.86370029e+01 ...  5.35891016e+01\n",
      "    5.64094369e+01  5.38367973e+01]\n",
      "  [ 3.64521191e+01  3.89188001e+01  4.05990111e+01 ...  3.58478058e+01\n",
      "    3.88383160e+01  3.73697012e+01]\n",
      "  ...\n",
      "  [-5.50104582e+00 -2.46950485e+00 -6.12004178e-01 ...  2.07579345e+00\n",
      "    4.18892631e+00  3.41002158e+00]\n",
      "  [-5.23070879e+00 -3.38042243e+00 -2.16206380e+00 ...  3.86750393e+00\n",
      "    3.31719887e+00  3.91377832e+00]\n",
      "  [-4.25412555e+00 -3.48035984e+00 -2.77394725e+00 ...  3.02062474e+00\n",
      "    2.17446840e+00  2.77309306e+00]]\n",
      "\n",
      " [[-7.01555938e+02 -7.01555938e+02 -7.01555938e+02 ... -5.78900348e+02\n",
      "   -6.15721982e+02 -6.85530565e+02]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  1.22244895e+02\n",
      "    9.28690282e+01  2.12236277e+01]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.41276788e+01\n",
      "    3.65960383e+01  1.73138820e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.49619567e+00\n",
      "    5.88512067e+00  1.98318600e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.70019793e+00\n",
      "    7.88993352e+00  1.51121614e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -3.69149790e+00\n",
      "    1.81325510e+00  9.95495050e-01]]]\n"
     ]
    }
   ],
   "source": [
    "x_train1 = getData(verifiedData,wav_path=train_wav_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = getData2(verifiedData,wav_path=train_wav_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode(data, oneHot=False):\n",
    "    # Encode labels into integers or onehot\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data)\n",
    "    trans = le.transform(data)\n",
    "    \n",
    "    if oneHot== True:\n",
    "        ohlen = (len(set(trans)))\n",
    "        eye=np.eye(ohlen)\n",
    "        return to_categorical(trans)\n",
    "        #return np.array([eye[i] for i in set(verifiedData['label'])])\n",
    "    else:\n",
    "        return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sizes:\n",
      "(2597, 40, 173)\n",
      "(2597, 41)\n",
      "\n",
      "Validation sizes:\n",
      "(556, 40, 173)\n",
      "(556, 41)\n",
      "\n",
      "Test sizes:\n",
      "(557, 40, 173)\n",
      "(557, 41)\n"
     ]
    }
   ],
   "source": [
    "yt=encode(verifiedData.label.values, oneHot=True)\n",
    "# Get validation set - keep 70% for train, 15% validation, 15% test\n",
    "training_size = int(np.shape(x_train1)[0] * 0.7)\n",
    "validate_size = int(np.shape(x_train1)[0]*.15)\n",
    "\n",
    "x_train=x_train1[:training_size] # shape (2968, 40, 28)\n",
    "x_val=x_train1[training_size:training_size+validate_size] # shape (742, 40, 28)\n",
    "x_test=x_train1[training_size+validate_size:]\n",
    "\n",
    "y_train=yt[:training_size] # shape 2968, 41\n",
    "y_val=yt[training_size:training_size+validate_size] # shape 742, 41\n",
    "y_test=yt[training_size+validate_size:]\n",
    "\n",
    "print ('Train sizes:')\n",
    "print (np.shape(x_train))\n",
    "print (np.shape(y_train))\n",
    "\n",
    "print ('\\nValidation sizes:')\n",
    "print (np.shape(x_val))\n",
    "print (np.shape(y_val))\n",
    "\n",
    "print ('\\nTest sizes:')\n",
    "print (np.shape(x_test))\n",
    "print (np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sizes:\n",
      "(3710, 128, 173)\n",
      "(2597, 41)\n",
      "\n",
      "Validation sizes:\n",
      "(556, 128, 173)\n",
      "(556, 41)\n",
      "\n",
      "Test sizes:\n",
      "(557, 128, 173)\n",
      "(557, 41)\n"
     ]
    }
   ],
   "source": [
    "yt2=encode(verifiedData.label.values, oneHot=True)\n",
    "# Get validation set - keep 70% for train, 15% validation, 15% test\n",
    "training_size2 = int(np.shape(x_train2)[0] * 0.7)\n",
    "validate_size2 = int(np.shape(x_train2)[0]*.15)\n",
    "\n",
    "x_train3=x_train2[:training_size2] # shape (2968, 40, 28)\n",
    "x_val2=x_train2[training_size2:training_size2+validate_size2] # shape (742, 40, 28)\n",
    "x_test2=x_train2[training_size2+validate_size2:]\n",
    "\n",
    "y_train3=yt2[:training_size2] # shape 2968, 41\n",
    "y_val2=yt2[training_size2:training_size2+validate_size2] # shape 742, 41\n",
    "y_test2=yt2[training_size2+validate_size2:]\n",
    "\n",
    "print ('Train sizes:')\n",
    "print (np.shape(x_train2))\n",
    "print (np.shape(y_train2))\n",
    "\n",
    "print ('\\nValidation sizes:')\n",
    "print (np.shape(x_val2))\n",
    "print (np.shape(y_val2))\n",
    "\n",
    "print ('\\nTest sizes:')\n",
    "print (np.shape(x_test2))\n",
    "print (np.shape(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2597, 40, 173)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 40, 256)           886016    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5, 256)            1310976   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1, 512)            1050624   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 173)            88749     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 128)            443008    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 41)                5289      \n",
      "=================================================================\n",
      "Total params: 3,787,914\n",
      "Trainable params: 3,786,288\n",
      "Non-trainable params: 1,626\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model4 = Sequential([\n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(np.shape(x_train)[1], np.shape(x_train)[2]),\\\n",
    "                 activation='relu',strides=1),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(np.shape(x_train)[1], np.shape(x_train)[2]),\\\n",
    "                 activation='relu',strides=3),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dense(173, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(128,20, padding=\"same\",strides=3),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.3),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.4781 - acc: 0.8568 - val_loss: 15.8862 - val_acc: 0.0144\n",
      "Epoch 2/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.4598 - acc: 0.8664 - val_loss: 14.7556 - val_acc: 0.0845\n",
      "Epoch 3/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.4221 - acc: 0.8818 - val_loss: 15.6543 - val_acc: 0.0288\n",
      "Epoch 4/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.4205 - acc: 0.8787 - val_loss: 15.3848 - val_acc: 0.0378\n",
      "Epoch 5/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.4661 - acc: 0.8637 - val_loss: 15.8572 - val_acc: 0.0162\n",
      "Epoch 6/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.5144 - acc: 0.8363 - val_loss: 15.5383 - val_acc: 0.0360\n",
      "Epoch 7/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.4624 - acc: 0.8633 - val_loss: 14.7556 - val_acc: 0.0845\n",
      "Epoch 8/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.3885 - acc: 0.8895 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 9/50\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.3839 - acc: 0.8860 - val_loss: 15.0165 - val_acc: 0.0683\n",
      "Epoch 10/50\n",
      "2597/2597 [==============================] - 14s 6ms/step - loss: 0.3709 - acc: 0.8837 - val_loss: 15.5963 - val_acc: 0.0324\n",
      "Epoch 11/50\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.3784 - acc: 0.8879 - val_loss: 15.8862 - val_acc: 0.0144\n",
      "Epoch 12/50\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.5230 - acc: 0.8414 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 13/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.3848 - acc: 0.8826 - val_loss: 15.8862 - val_acc: 0.0144\n",
      "Epoch 14/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.3618 - acc: 0.8976 - val_loss: 15.0165 - val_acc: 0.0683\n",
      "Epoch 15/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.3612 - acc: 0.8883 - val_loss: 15.7412 - val_acc: 0.0234\n",
      "Epoch 16/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.2840 - acc: 0.9199 - val_loss: 15.7412 - val_acc: 0.0234\n",
      "Epoch 17/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.3613 - acc: 0.8972 - val_loss: 15.6543 - val_acc: 0.0288\n",
      "Epoch 18/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.3550 - acc: 0.8887 - val_loss: 15.7992 - val_acc: 0.0198\n",
      "Epoch 19/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.3791 - acc: 0.8856 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 20/50\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.3149 - acc: 0.9103 - val_loss: 15.6543 - val_acc: 0.0288\n",
      "Epoch 21/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.3087 - acc: 0.9037 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 22/50\n",
      "2597/2597 [==============================] - 17s 6ms/step - loss: 0.3002 - acc: 0.9095 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 23/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.2629 - acc: 0.9284 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 24/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.2870 - acc: 0.9107 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 25/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.3644 - acc: 0.8841 - val_loss: 15.7122 - val_acc: 0.0252\n",
      "Epoch 26/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.2497 - acc: 0.9211 - val_loss: 15.7412 - val_acc: 0.0234\n",
      "Epoch 27/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.2210 - acc: 0.9349 - val_loss: 14.9311 - val_acc: 0.0486\n",
      "Epoch 28/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.2809 - acc: 0.9168 - val_loss: 15.7122 - val_acc: 0.0252\n",
      "Epoch 29/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.2959 - acc: 0.9068 - val_loss: 15.8572 - val_acc: 0.0162\n",
      "Epoch 30/50\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.3267 - acc: 0.8980 - val_loss: 15.7122 - val_acc: 0.0252\n",
      "Epoch 31/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.3073 - acc: 0.9118 - val_loss: 15.5963 - val_acc: 0.0324\n",
      "Epoch 32/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.3065 - acc: 0.8995 - val_loss: 15.8862 - val_acc: 0.0144\n",
      "Epoch 33/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.4172 - acc: 0.8725 - val_loss: 15.6543 - val_acc: 0.0288\n",
      "Epoch 34/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.4361 - acc: 0.8664 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 35/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.3935 - acc: 0.8826 - val_loss: 15.7702 - val_acc: 0.0216\n",
      "Epoch 36/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.2967 - acc: 0.9153 - val_loss: 15.5093 - val_acc: 0.0378\n",
      "Epoch 37/50\n",
      "2597/2597 [==============================] - 13s 5ms/step - loss: 0.2122 - acc: 0.9380 - val_loss: 15.8572 - val_acc: 0.0162\n",
      "Epoch 38/50\n",
      "2597/2597 [==============================] - 14s 5ms/step - loss: 0.2459 - acc: 0.9315 - val_loss: 15.9442 - val_acc: 0.0108\n",
      "Epoch 39/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.2412 - acc: 0.9299 - val_loss: 15.4124 - val_acc: 0.0342\n",
      "Epoch 40/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.2216 - acc: 0.9384 - val_loss: 15.6543 - val_acc: 0.0288\n",
      "Epoch 41/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.2181 - acc: 0.9345 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 42/50\n",
      "2597/2597 [==============================] - 15s 6ms/step - loss: 0.3310 - acc: 0.9014 - val_loss: 15.7702 - val_acc: 0.0216\n",
      "Epoch 43/50\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.3604 - acc: 0.8976 - val_loss: 15.7992 - val_acc: 0.0198\n",
      "Epoch 44/50\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.2266 - acc: 0.9361 - val_loss: 15.8862 - val_acc: 0.0144\n",
      "Epoch 45/50\n",
      "2597/2597 [==============================] - 18s 7ms/step - loss: 0.2320 - acc: 0.9307 - val_loss: 15.6253 - val_acc: 0.0306\n",
      "Epoch 46/50\n",
      "2597/2597 [==============================] - 16s 6ms/step - loss: 0.2571 - acc: 0.9207 - val_loss: 15.8282 - val_acc: 0.0180\n",
      "Epoch 47/50\n",
      "2597/2597 [==============================] - 27s 10ms/step - loss: 0.2501 - acc: 0.9168 - val_loss: 15.5963 - val_acc: 0.0324\n",
      "Epoch 48/50\n",
      "2597/2597 [==============================] - 28s 11ms/step - loss: 0.1778 - acc: 0.9503 - val_loss: 15.7702 - val_acc: 0.0216\n",
      "Epoch 49/50\n",
      "2597/2597 [==============================] - 30s 11ms/step - loss: 0.2037 - acc: 0.9407 - val_loss: 15.6807 - val_acc: 0.0252\n",
      "Epoch 50/50\n",
      "2597/2597 [==============================] - 31s 12ms/step - loss: 0.2533 - acc: 0.9214 - val_loss: 15.8282 - val_acc: 0.0180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f412a322b00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model4.fit(np.array(x_train), np.array(y_train),\n",
    "          batch_size=50, epochs=50,\n",
    "          validation_data=(np.array(x_val), np.array(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 1ms/step\n",
      "[15.770850791109314, 0.021543986209178315]\n"
     ]
    }
   ],
   "source": [
    "conv_result4 = conv_model4.evaluate(np.array(x_test), np.array(y_test), batch_size=150)\n",
    "print(conv_result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 128, 256)          886016    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 256)          1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 42, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 14, 256)           1310976   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 4, 512)            1050624   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4, 173)            88749     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 173)            692       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2, 128)            443008    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 128)            512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 41)                5289      \n",
      "=================================================================\n",
      "Total params: 3,787,914\n",
      "Trainable params: 3,786,288\n",
      "Non-trainable params: 1,626\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_model4 = Sequential([\n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(x_train2.shape[1], x_train2.shape[2]),\\\n",
    "                 activation='relu',strides=1),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Convolution1D(256,20, padding=\"same\", input_shape=(x_train2.shape[1], x_train2.shape[2]),\\\n",
    "                 activation='relu',strides=3),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(3),\n",
    "    \n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dense(173, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(128,20, padding=\"same\",strides=3),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(rate=0.3),\n",
    "    \n",
    "#     Dense(28, activation='relu'),\n",
    "    Dense(41, activation='softmax')\n",
    "    \n",
    "])\n",
    "conv_model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10,\\\n",
    "                      verbose=0, mode='auto', baseline=None)\n",
    "print (conv_model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2597 samples, validate on 556 samples\n",
      "Epoch 1/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1365 - acc: 0.9630 - val_loss: 6.3653 - val_acc: 0.3651\n",
      "Epoch 2/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1513 - acc: 0.9592 - val_loss: 4.5230 - val_acc: 0.3957\n",
      "Epoch 3/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1368 - acc: 0.9619 - val_loss: 4.7214 - val_acc: 0.3939\n",
      "Epoch 4/40\n",
      "2597/2597 [==============================] - 24s 9ms/step - loss: 0.1332 - acc: 0.9638 - val_loss: 5.4134 - val_acc: 0.3525\n",
      "Epoch 5/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1330 - acc: 0.9630 - val_loss: 4.9467 - val_acc: 0.3921\n",
      "Epoch 6/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1245 - acc: 0.9692 - val_loss: 5.3896 - val_acc: 0.3525\n",
      "Epoch 7/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1307 - acc: 0.9638 - val_loss: 4.7016 - val_acc: 0.3777\n",
      "Epoch 8/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1281 - acc: 0.9638 - val_loss: 5.7285 - val_acc: 0.3813\n",
      "Epoch 9/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1249 - acc: 0.9653 - val_loss: 5.3537 - val_acc: 0.3993\n",
      "Epoch 10/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1239 - acc: 0.9677 - val_loss: 4.7375 - val_acc: 0.3957\n",
      "Epoch 11/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1332 - acc: 0.9638 - val_loss: 5.9368 - val_acc: 0.3561\n",
      "Epoch 12/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1394 - acc: 0.9646 - val_loss: 5.0511 - val_acc: 0.3939\n",
      "Epoch 13/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1180 - acc: 0.9692 - val_loss: 4.6805 - val_acc: 0.3903\n",
      "Epoch 14/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1343 - acc: 0.9646 - val_loss: 6.1518 - val_acc: 0.3669\n",
      "Epoch 15/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1434 - acc: 0.9576 - val_loss: 5.7385 - val_acc: 0.3921\n",
      "Epoch 16/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1252 - acc: 0.9677 - val_loss: 5.8823 - val_acc: 0.3579\n",
      "Epoch 17/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1480 - acc: 0.9592 - val_loss: 5.4120 - val_acc: 0.3597\n",
      "Epoch 18/40\n",
      "2597/2597 [==============================] - 24s 9ms/step - loss: 0.1477 - acc: 0.9600 - val_loss: 6.9543 - val_acc: 0.3040\n",
      "Epoch 19/40\n",
      "2597/2597 [==============================] - 22s 8ms/step - loss: 0.1446 - acc: 0.9642 - val_loss: 4.7260 - val_acc: 0.4155\n",
      "Epoch 20/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1346 - acc: 0.9619 - val_loss: 5.6274 - val_acc: 0.3723\n",
      "Epoch 21/40\n",
      "2597/2597 [==============================] - 20s 8ms/step - loss: 0.1454 - acc: 0.9619 - val_loss: 6.2771 - val_acc: 0.3705\n",
      "Epoch 22/40\n",
      "2597/2597 [==============================] - 23s 9ms/step - loss: 0.1291 - acc: 0.9661 - val_loss: 5.2378 - val_acc: 0.3759\n",
      "Epoch 23/40\n",
      "2597/2597 [==============================] - 23s 9ms/step - loss: 0.1184 - acc: 0.9680 - val_loss: 5.9193 - val_acc: 0.3669\n",
      "Epoch 24/40\n",
      "2597/2597 [==============================] - 22s 9ms/step - loss: 0.1107 - acc: 0.9723 - val_loss: 5.6369 - val_acc: 0.3741\n",
      "Epoch 25/40\n",
      "2597/2597 [==============================] - 25s 10ms/step - loss: 0.1072 - acc: 0.9719 - val_loss: 5.6338 - val_acc: 0.3453\n",
      "Epoch 26/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1157 - acc: 0.9707 - val_loss: 6.3458 - val_acc: 0.3453\n",
      "Epoch 27/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1262 - acc: 0.9665 - val_loss: 4.3320 - val_acc: 0.4388\n",
      "Epoch 28/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1178 - acc: 0.9677 - val_loss: 5.0944 - val_acc: 0.4155\n",
      "Epoch 29/40\n",
      "2597/2597 [==============================] - 23s 9ms/step - loss: 0.1179 - acc: 0.9696 - val_loss: 7.1895 - val_acc: 0.3076\n",
      "Epoch 30/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1317 - acc: 0.9653 - val_loss: 5.4834 - val_acc: 0.3669\n",
      "Epoch 31/40\n",
      "2597/2597 [==============================] - 25s 10ms/step - loss: 0.1397 - acc: 0.9611 - val_loss: 4.4752 - val_acc: 0.3993\n",
      "Epoch 32/40\n",
      "2597/2597 [==============================] - 24s 9ms/step - loss: 0.1432 - acc: 0.9607 - val_loss: 5.5418 - val_acc: 0.3669\n",
      "Epoch 33/40\n",
      "2597/2597 [==============================] - 23s 9ms/step - loss: 0.1375 - acc: 0.9619 - val_loss: 8.1223 - val_acc: 0.2680\n",
      "Epoch 34/40\n",
      "2597/2597 [==============================] - 24s 9ms/step - loss: 0.1557 - acc: 0.9553 - val_loss: 5.1679 - val_acc: 0.4083\n",
      "Epoch 35/40\n",
      "2597/2597 [==============================] - 22s 9ms/step - loss: 0.1417 - acc: 0.9611 - val_loss: 4.4674 - val_acc: 0.4227\n",
      "Epoch 36/40\n",
      "2597/2597 [==============================] - 24s 9ms/step - loss: 0.1098 - acc: 0.9704 - val_loss: 4.8520 - val_acc: 0.4011\n",
      "Epoch 37/40\n",
      "2597/2597 [==============================] - 25s 9ms/step - loss: 0.1189 - acc: 0.9684 - val_loss: 5.1109 - val_acc: 0.3723\n",
      "Epoch 38/40\n",
      "2597/2597 [==============================] - 21s 8ms/step - loss: 0.1380 - acc: 0.9626 - val_loss: 6.7023 - val_acc: 0.3058\n",
      "Epoch 39/40\n",
      "2597/2597 [==============================] - 23s 9ms/step - loss: 0.1199 - acc: 0.9657 - val_loss: 5.4035 - val_acc: 0.4065\n",
      "Epoch 40/40\n",
      "2597/2597 [==============================] - 22s 9ms/step - loss: 0.1260 - acc: 0.9657 - val_loss: 5.5401 - val_acc: 0.3831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26b40db4e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model4.fit(x_train3, y_train3,\n",
    "          batch_size=75, epochs=40,\n",
    "          validation_data=(x_val2, y_val2))\n",
    "#87+10+10 0.456\n",
    "#87+10+10+10+10 0.4057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 2ms/step\n",
      "[5.211197773472839, 0.39856373616352114]\n"
     ]
    }
   ],
   "source": [
    "conv_result4 = conv_model4.evaluate(x_test2, y_test2, batch_size=150)\n",
    "print(conv_result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1614216e-01 1.8269170e-06 2.6338446e-05 ... 5.0648025e-05\n",
      "  2.8887248e-04 3.8126094e-05]\n",
      " [3.6046094e-10 9.4241299e-09 1.4185495e-09 ... 1.2730460e-06\n",
      "  2.7120292e-08 9.5570629e-10]\n",
      " [2.6239851e-04 3.2038125e-07 1.1406928e-04 ... 3.0498835e-01\n",
      "  6.1274786e-04 1.0755531e-06]\n",
      " ...\n",
      " [4.5884686e-04 1.4165133e-07 1.8191237e-04 ... 5.0693416e-06\n",
      "  4.1005164e-03 4.4900533e-03]\n",
      " [8.4080708e-01 2.8532647e-06 3.8869883e-04 ... 4.6513549e-05\n",
      "  4.5087272e-03 5.6794239e-04]\n",
      " [3.4586665e-07 1.9014162e-06 2.3823643e-06 ... 4.9705943e-04\n",
      "  8.2273714e-02 4.3776050e-05]]\n"
     ]
    }
   ],
   "source": [
    "conv_result_p_4 = conv_model4.predict(x_test2, batch_size=150)\n",
    "print(conv_result_p_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5637342908438061\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(conv_result_p_4)):\n",
    "    temp = conv_result_p_4[i].argsort()[-3:][::-1]\n",
    "    if y_test2[i][temp[0]]==1:\n",
    "        count+=1\n",
    "    elif y_test2[i][temp[1]]==1:\n",
    "        count+=1\n",
    "    elif y_test2[i][temp[2]]==1:\n",
    "        count+=1\n",
    "        \n",
    "print(count/len(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2597, 128, 173)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train3.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
