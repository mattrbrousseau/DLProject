{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Useful links for this notebook:<br><br>\n",
    "For converting the data:<br>\n",
    "[1] https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial <br>\n",
    "[2] https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html <br>\n",
    "[3] http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/ <br><br>\n",
    "\n",
    "Data generators:<br>\n",
    "[4] https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html <br>\n",
    "[5] https://keras.io/utils/#sequence <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import constants\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "np.random.seed(1001)\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import IPython\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy.io import wavfile\n",
    "from sklearn import preprocessing\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc=\"database/\"\n",
    "wav_path = data_loc+\"audio_train/\"\n",
    "sr=44100\n",
    "dataset = pd.read_csv(data_loc+\"train.csv\",header=0,names=['fname','label','verified'])\n",
    "checkedDataset = dataset.loc[dataset.verified == 1,[\"fname\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_file(name):\n",
    "    _, b = wavfile.read(wav_path + name)\n",
    "    assert _ == sr\n",
    "    return b\n",
    "\n",
    "checkedDataset['time_series'] = checkedDataset['fname'].apply(load_wav_file)\n",
    "checkedDataset['nframes'] = checkedDataset['time_series'].apply(len)\n",
    "checkedDataset=checkedDataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in short_scalars\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# First, lets normalize the time series\n",
    "# Perhaps we should address the warning given below?\n",
    "for i in range(checkedDataset.shape[0]):\n",
    "    c=checkedDataset.time_series[i]\n",
    "#     checkedDataset.time_series[i] = c/np.linalg.norm(c)\n",
    "    npmin=np.min(c)\n",
    "    npmax=np.max(c)\n",
    "    checkedDataset.time_series[i] = (c-npmin) / (npmax - npmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x,y,keep):\n",
    "    # test/train split\n",
    "    # trainsz - size of train set to retain; eg 0.7\n",
    "    trsize=int(x.shape[0] * keep)\n",
    "\n",
    "    x_train=x[:trsize]\n",
    "    x_val=x[trsize:] \n",
    "\n",
    "    y_train=y[:trsize] \n",
    "    y_val=y[trsize:] \n",
    "    \n",
    "    return x_train,x_val,y_train,y_val\n",
    "\n",
    "def encode(data, oneHot=False):\n",
    "    # Encode labels into integers or onehot\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data)\n",
    "    trans = le.transform(data)\n",
    "    if oneHot== True:\n",
    "        ohlen = (len(set(trans)))\n",
    "        eye=np.eye(ohlen)\n",
    "        return np.array([eye[i] for i in trans])\n",
    "    else:\n",
    "        return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=encode(checkedDataset.label.values, oneHot=True) # Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr,xtst,ytr,ytst = split(checkedDataset.time_series.values,y, 0.8) # Split data into test/train\n",
    "xval, xtst, yval, ytst = split(xtst, ytst, 0.5) # Split train into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr shape: (2968,), Xtr[0] shape: (455112,). Note here that each row of Xtr is a list containing a time series!\n",
      "3710\n",
      "(3710, 41)\n"
     ]
    }
   ],
   "source": [
    "print ('Xtr shape: {}, Xtr[0] shape: {}. Note here that each row of Xtr is a list containing a time series!'.format(\\\n",
    "                                                                                                    xtr.shape, xtr[0].shape))\n",
    "print (xtr.shape[0] + xval.shape[0] + xtst.shape[0])\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class DataGen(Sequence):\n",
    "    \"\"\"\n",
    "    See [4], [5] to understand how data generators work.\n",
    "    CURRENTLY: This generator does work, but need to fix all MFCC getting related functions\n",
    "    to properly deal with our data format (and finish some of them)\n",
    "    \"\"\"\n",
    "    def __init__(self, x, labels, batch_size=2):\n",
    "        self.x, self.y= x, labels\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "    def frame(self, audio, FFT_size=2048, hop_size=10, sample_rate=44100):\n",
    "        \"\"\"     \n",
    "        Convert batch of time series to batch of audio frame\n",
    "        Not currently working fully for batches, there is a cell below for\n",
    "        playing with this.\n",
    "        Taken from https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial\n",
    "        hop_size in ms\n",
    "        \"\"\"\n",
    "        audio = np.pad(audio, int(FFT_size / 2), mode='reflect')\n",
    "        frame_len = np.round(sample_rate * hop_size / 1000).astype(int)\n",
    "        frame_num = int((len(audio) - FFT_size) / frame_len) + 1\n",
    "        frames = np.zeros((frame_num,FFT_size))\n",
    "\n",
    "        for n in range(frame_num):\n",
    "            frames[n] = audio[n*frame_len:n*frame_len+FFT_size]\n",
    "\n",
    "        return frames\n",
    "    \n",
    "    def freq_domain(self):\n",
    "        # Convert audio frame into frequency domain\n",
    "        pass\n",
    "    \n",
    "    def mfcc(self):\n",
    "        # Given frequency domains, get the MFCCs\n",
    "        pass\n",
    "\n",
    "    def get_mfcc(self, batch):\n",
    "        \"\"\" \n",
    "        Given a batch of data X, we have n rows. Each row contains\n",
    "        a time series. Each of these time series needs to be converted to an audio frame and then\n",
    "        to a frequency domain. We can then use that to filter and extract useful MFCC features. \n",
    "        See [1], [2], [3].\n",
    "        \"\"\"\n",
    "        # Convert batch to MFCCs\n",
    "        mfccs=[]\n",
    "        for series in batch:\n",
    "            fr=self.frame(series[0])\n",
    "            print(fr.shape)\n",
    "            mfccs.append(fr)\n",
    "        return np.array(mfccs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        tmp_x=self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "#         batch_x=self.mfcc(tmp_x)\n",
    "        \n",
    "        return tmp_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=DataGen(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0.44391037, 0.44394571, 0.44387503, ..., 0.44504135, 0.44504135,\n",
       "       0.44504135]),\n",
       "       array([0.51426635, 0.5148826 , 0.51666975, ..., 0.51426635, 0.51426635,\n",
       "       0.51426635])], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to find out how to convert batch of time series to batch of frames\n",
    "\n",
    "def frame(audio, FFT_size=2048, hop_size=10, sample_rate=44100):\n",
    "    # Taken from https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial\n",
    "    # hop_size in ms\n",
    "    audio = np.pad(audio, int(FFT_size / 2), mode='reflect')\n",
    "    frame_len = np.round(sample_rate * hop_size / 1000).astype(int)\n",
    "    frame_num = int((len(audio) - FFT_size) / frame_len) + 1\n",
    "    frames = np.zeros((frame_num,FFT_size))\n",
    "\n",
    "    for n in range(frame_num):\n",
    "        frames[n] = audio[n*frame_len:n*frame_len+FFT_size]\n",
    "\n",
    "    return frames\n",
    "\n",
    "frt=frame(data[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 2048)\n"
     ]
    }
   ],
   "source": [
    "print (frt.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
