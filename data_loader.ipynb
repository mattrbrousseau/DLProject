{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Useful links for this notebook:<br><br>\n",
    "For converting the data:<br>\n",
    "[1] https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial <br>\n",
    "[2] https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html <br>\n",
    "[3] http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/ <br><br>\n",
    "\n",
    "Data generators:<br>\n",
    "[4] https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html <br>\n",
    "[5] https://keras.io/utils/#sequence <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import constants\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "np.random.seed(1001)\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import IPython\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy.io import wavfile\n",
    "from sklearn import preprocessing\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc=\"database/\"\n",
    "wav_path = data_loc+\"audio_train/\"\n",
    "sr=44100\n",
    "dataset = pd.read_csv(data_loc+\"train.csv\",header=0,names=['fname','label','verified'])\n",
    "checkedDataset = dataset.loc[dataset.verified == 1,[\"fname\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_file(name):\n",
    "    _, b = wavfile.read(wav_path + name)\n",
    "    assert _ == sr\n",
    "    return b\n",
    "\n",
    "checkedDataset['time_series'] = checkedDataset['fname'].apply(load_wav_file)\n",
    "checkedDataset['nframes'] = checkedDataset['time_series'].apply(len)\n",
    "checkedDataset=checkedDataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in short_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# First, lets normalize the time series\n",
    "# Perhaps we should address the warning given below?\n",
    "for i in range(checkedDataset.shape[0]):\n",
    "    c=checkedDataset.time_series[i]\n",
    "#     checkedDataset.time_series[i] = c/np.linalg.norm(c)\n",
    "    npmin=np.min(c)\n",
    "    npmax=np.max(c)\n",
    "    checkedDataset.time_series[i] = (c-npmin) / (npmax - npmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x,y,keep):\n",
    "    # test/train split\n",
    "    # trainsz - size of train set to retain; eg 0.7\n",
    "    trsize=int(x.shape[0] * keep)\n",
    "\n",
    "    x_train=x[:trsize]\n",
    "    x_val=x[trsize:] \n",
    "\n",
    "    y_train=y[:trsize] \n",
    "    y_val=y[trsize:] \n",
    "    \n",
    "    return x_train,x_val,y_train,y_val\n",
    "\n",
    "def encode(data, oneHot=False):\n",
    "    # Encode labels into integers or onehot\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data)\n",
    "    trans = le.transform(data)\n",
    "    if oneHot== True:\n",
    "        ohlen = (len(set(trans)))\n",
    "        eye=np.eye(ohlen)\n",
    "        return np.array([eye[i] for i in trans])\n",
    "    else:\n",
    "        return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=encode(checkedDataset.label.values, oneHot=True) # Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr,xtst,ytr,ytst = split(checkedDataset.time_series.values,y, 0.8) # Split data into test/train\n",
    "xval, xtst, yval, ytst = split(xtst, ytst, 0.5) # Split train into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr shape: (2968,), Xtr[0] shape: (455112,). Note here that each row of Xtr is a list containing a time series!\n",
      "3710\n",
      "(3710, 41)\n"
     ]
    }
   ],
   "source": [
    "print ('Xtr shape: {}, Xtr[0] shape: {}. Note here that each row of Xtr is a list containing a time series!'.format(\\\n",
    "                                                                                                    xtr.shape, xtr[0].shape))\n",
    "print (xtr.shape[0] + xval.shape[0] + xtst.shape[0])\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from scipy.signal import get_window\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "class DataGen(Sequence):\n",
    "    \"\"\"\n",
    "    See [4], [5] to understand how data generators work.\n",
    "    CURRENTLY: This generator does work, but need to fix all MFCC getting related functions\n",
    "    to properly deal with our data format (and finish some of them)\n",
    "    \"\"\"\n",
    "    def __init__(self, x, labels, batch_size=5, FFT_size=2048, sr=44100):\n",
    "        self.x, self.y= x, labels\n",
    "        self.batch_size=batch_size\n",
    "        self.FFT_size = FFT_size\n",
    "        self.sr = sr\n",
    "        \n",
    "    def frame(self, audio, hop_size=10):\n",
    "        \"\"\"     \n",
    "        Convert batch of time series to batch of audio frame\n",
    "        Not currently working fully for batches, there is a cell below for\n",
    "        playing with this.\n",
    "        Taken from https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial\n",
    "        hop_size in ms\n",
    "        \"\"\"\n",
    "        audio = np.pad(audio, int(self.FFT_size / 2), mode='reflect')\n",
    "        frame_len = np.round(self.sr * hop_size / 1000).astype(int)\n",
    "        frame_num = int((len(audio) - self.FFT_size) / frame_len) + 1\n",
    "        frames = np.zeros((frame_num, self.FFT_size))\n",
    "\n",
    "        for n in range(frame_num):\n",
    "            frames[n] = audio[n*frame_len:n*frame_len+self.FFT_size]\n",
    "\n",
    "        return frames\n",
    "    \n",
    "    def freq_domain(self, frames):\n",
    "        # Convert audio frame into frequency domain\n",
    "        window = get_window(\"hann\", self.FFT_size, fftbins=True)\n",
    "        wins=[]\n",
    "        for frame in frames:\n",
    "            wins.append(frame*window)\n",
    "        return np.array(wins)\n",
    "    \n",
    "    def mfcc(self, frames):\n",
    "        # Given frequency domains, get the MFCCs\n",
    "        # Code for this function heavily based on https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "        NFFT=512\n",
    "        nfilt=41\n",
    "            \n",
    "        num_ceps=41\n",
    "        cep_lifter = 22 # cep_lifter is a parameter typically set to 22 in most implementations. \n",
    "                        #However, it refers to the dimensionality of the MFCC vector in the original formulation\n",
    "            \n",
    "        # First, we need to do an N point FFT on each of our frames to get the frequency spectrum\n",
    "        mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
    "        pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
    "        \n",
    "        # The final step before getting our MFCCs is to compute our filter banks\n",
    "        low_freq_mel = 0\n",
    "        high_freq_mel = (2595 * np.log10(1 + (self.sr / 2) / 700))  # Convert Hz to Mel\n",
    "        mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
    "        hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "        bin = np.floor((NFFT + 1) * hz_points / self.sr)\n",
    "\n",
    "        fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
    "        for m in range(1, nfilt + 1):\n",
    "            f_m_minus = int(bin[m - 1])   # left\n",
    "            f_m = int(bin[m])             # center\n",
    "            f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "            for k in range(f_m_minus, f_m):\n",
    "                fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "            for k in range(f_m, f_m_plus):\n",
    "                fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "        filter_banks = np.dot(pow_frames, fbank.T)\n",
    "        filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "        filter_banks = 20 * np.log10(filter_banks)  # dB\n",
    "        \n",
    "        # Get MFCCs\n",
    "        mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13\n",
    "        (nframes, ncoeff) = mfcc.shape\n",
    "        n = np.arange(ncoeff)\n",
    "        lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)\n",
    "        mfcc *= lift  #*\n",
    "        \n",
    "        # Mean normalization\n",
    "        filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)\n",
    "        mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
    "        \n",
    "        # For now, lets just try padding to length of 200\n",
    "        print('mfcc shape before: ' + str(mfcc.shape))\n",
    "        if mfcc.shape[0] > 200:\n",
    "            mfcc = mfcc[:200,:]\n",
    "        elif mfcc.shape[0] < 200:\n",
    "            \"\"\"\n",
    "            ###################### NOTE - This is where the error is occuring. We need to pad\n",
    "                                   the x axis to be 200, and keep the y at 40.\n",
    "            \"\"\"\n",
    "            # Pad\n",
    "            ###### NOTE NEED TO FIX PAD FUNCTION HERE - INCORRECT RESULTS\n",
    "            num_zeros = 200 - mfcc.shape[0]\n",
    "#             mfcc[0] = np.pad(mfcc[0], num_zeros, mode=\"edge\")\n",
    "            mfcc[0] = np.append(mfcc[0], [0]*num_zeros, axis=0)\n",
    "            \n",
    "        print('mfcc shape after: ' + str(mfcc.shape) + '\\n')\n",
    "        \n",
    "        return mfcc\n",
    "\n",
    "    def get_mfcc(self, batch):\n",
    "        \"\"\" \n",
    "        Given a batch of data X, we have n rows. Each row contains\n",
    "        a time series. Each of these time series needs to be converted to an audio frame and then\n",
    "        to a frequency domain. We can then use that to filter and extract useful MFCC features. \n",
    "        See [1], [2], [3].\n",
    "        \"\"\"\n",
    "        # Convert batch to MFCCs\n",
    "        \n",
    "        # First, get the frames\n",
    "        frames=[]\n",
    "        for series in batch:\n",
    "            fr=self.frame(series) # Get the frame. Our X dimension will not be the same for all - take note.\n",
    "            frames.append(fr)\n",
    "        \n",
    "        frames = np.array(frames)\n",
    "        \n",
    "        # Given frames, convert these to frequency\n",
    "        freq = self.freq_domain(frames)\n",
    "        \n",
    "        # Given freq domain, we can finally extract the MFCCs\n",
    "        mfccs = []\n",
    "        for frame in freq:\n",
    "            mfccs.append(np.array(self.mfcc(frame)))\n",
    "        mfccs=np.array(mfccs)\n",
    "        \n",
    "        return mfccs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        tmp_x=self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Pass x batch to get transformed\n",
    "        mfcc=self.get_mfcc(tmp_x)\n",
    "        print (mfcc.shape)\n",
    "#         batch_x=np.empty(shape=(self.batch_size,200,40))\n",
    "        batch_x=[]\n",
    "#         for i, row in enumerate(mfcc):\n",
    "#             print (row.shape)\n",
    "#             batch_x.append(row)\n",
    "#         print (np.hstack(batch_x))\n",
    "        return mfcc, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=DataGen(xtr, ytr)\n",
    "val=DataGen(xval,yval)\n",
    "test=DataGen(xtst,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc shape before: (201, 40)\n",
      "mfcc shape after: (200, 40)\n",
      "\n",
      "mfcc shape before: (201, 40)\n",
      "mfcc shape after: (200, 40)\n",
      "\n",
      "mfcc shape before: (201, 40)\n",
      "mfcc shape after: (200, 40)\n",
      "\n",
      "mfcc shape before: (137, 40)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (103) into shape (40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-268d055c8ed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# data[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-4127431c29bc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Pass x batch to get transformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mmfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m#         batch_x=np.empty(shape=(self.batch_size,200,40))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-4127431c29bc>\u001b[0m in \u001b[0;36mget_mfcc\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mmfccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mmfccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mmfccs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-4127431c29bc>\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mnum_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m#             mfcc[0] = np.pad(mfcc[0], num_zeros, mode=\"edge\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mmfcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mfcc shape after: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (103) into shape (40)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Indicies: First 0: Batch 0\n",
    "          Second 0: Training data (1 is labels)\n",
    "          Third 0: Sample #\n",
    "          Fourth: Row of sample\n",
    "\"\"\"\n",
    "\n",
    "train[0][0][2].shape\n",
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f652fdd4668>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from librosa import display\n",
    "librosa.display.specshow(data[35][0][0], x_axis='time', y_axis='mel')\n",
    "# audio=data[30][0][0]\n",
    "# plt.plot(np.linspace(0, len(audio) / sr, num=len(audio)), audio)\n",
    "# plt.imshow(audio, aspect='auto', origin='lower');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Embedding, BatchNormalization\n",
    "from keras.layers import (Convolution1D, GlobalAveragePooling1D, Flatten,\n",
    "                          GlobalMaxPool1D, MaxPool1D, Flatten, concatenate, Activation)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import LeakyReLU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 200, 200)          32200     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 200, 200)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 200)          800       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 200, 192)          153792    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 200, 192)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 200, 192)          147648    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 200, 192)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 25, 192)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 25, 128)           98432     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 25, 128)           65664     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 128)            512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 41)                4141      \n",
      "=================================================================\n",
      "Total params: 637,549\n",
      "Trainable params: 636,893\n",
      "Non-trainable params: 656\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnet = Sequential([\n",
    "    Convolution1D(200,4, padding=\"same\", input_shape=(200, 40)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPool1D(1),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Convolution1D(192,4, padding=\"same\"),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    Convolution1D(192,4, padding=\"same\"),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    MaxPool1D(8),\n",
    "    \n",
    "    Convolution1D(128,4, padding=\"same\"),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    Convolution1D(128,4, padding=\"same\"),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    MaxPool1D(8),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "#     LSTM(256, activation='relu'),\n",
    "#     LSTM(256, activation='relu'),\n",
    "  \n",
    "#     Bidirectional(LSTM(256)),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(100),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(100),\n",
    "    LeakyReLU(alpha=0.3),\n",
    "    Dense(41, activation='softmax')\n",
    "])\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=0.0000001)\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20,\\\n",
    "                      verbose=0, mode='auto')\n",
    "\n",
    "cnet.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print (cnet.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_1_input to have 3 dimensions, but got array with shape (5, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-fdde23fc1919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     workers=6)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_1_input to have 3 dimensions, but got array with shape (5, 1)"
     ]
    }
   ],
   "source": [
    "cnet.fit_generator(generator=train,\n",
    "                    validation_data=val,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
