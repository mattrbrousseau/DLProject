{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Useful links for this notebook:<br><br>\n",
    "For converting the data:<br>\n",
    "[1] https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial <br>\n",
    "[2] https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html <br>\n",
    "[3] http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/ <br><br>\n",
    "\n",
    "Data generators:<br>\n",
    "[4] https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html <br>\n",
    "[5] https://keras.io/utils/#sequence <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import constants\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "np.random.seed(1001)\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import IPython\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy.io import wavfile\n",
    "from sklearn import preprocessing\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc=\"database/\"\n",
    "wav_path = data_loc+\"audio_train/\"\n",
    "sr=44100\n",
    "dataset = pd.read_csv(data_loc+\"train.csv\",header=0,names=['fname','label','verified'])\n",
    "checkedDataset = dataset.loc[dataset.verified == 1,[\"fname\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_file(name):\n",
    "    _, b = wavfile.read(wav_path + name)\n",
    "    assert _ == sr\n",
    "    return b\n",
    "\n",
    "checkedDataset['time_series'] = checkedDataset['fname'].apply(load_wav_file)\n",
    "checkedDataset['nframes'] = checkedDataset['time_series'].apply(len)\n",
    "checkedDataset=checkedDataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in short_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# First, lets normalize the time series\n",
    "# Perhaps we should address the warning given below?\n",
    "for i in range(checkedDataset.shape[0]):\n",
    "    c=checkedDataset.time_series[i]\n",
    "#     checkedDataset.time_series[i] = c/np.linalg.norm(c)\n",
    "    npmin=np.min(c)\n",
    "    npmax=np.max(c)\n",
    "    checkedDataset.time_series[i] = (c-npmin) / (npmax - npmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x,y,keep):\n",
    "    # test/train split\n",
    "    # trainsz - size of train set to retain; eg 0.7\n",
    "    trsize=int(x.shape[0] * keep)\n",
    "\n",
    "    x_train=x[:trsize]\n",
    "    x_val=x[trsize:] \n",
    "\n",
    "    y_train=y[:trsize] \n",
    "    y_val=y[trsize:] \n",
    "    \n",
    "    return x_train,x_val,y_train,y_val\n",
    "\n",
    "def encode(data, oneHot=False):\n",
    "    # Encode labels into integers or onehot\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data)\n",
    "    trans = le.transform(data)\n",
    "    if oneHot== True:\n",
    "        ohlen = (len(set(trans)))\n",
    "        eye=np.eye(ohlen)\n",
    "        return np.array([eye[i] for i in trans])\n",
    "    else:\n",
    "        return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=encode(checkedDataset.label.values, oneHot=True) # Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr,xtst,ytr,ytst = split(checkedDataset.time_series.values,y, 0.8) # Split data into test/train\n",
    "xval, xtst, yval, ytst = split(xtst, ytst, 0.5) # Split train into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr shape: (2968,), Xtr[0] shape: (455112,). Note here that each row of Xtr is a list containing a time series!\n",
      "3710\n",
      "(3710, 41)\n"
     ]
    }
   ],
   "source": [
    "print ('Xtr shape: {}, Xtr[0] shape: {}. Note here that each row of Xtr is a list containing a time series!'.format(\\\n",
    "                                                                                                    xtr.shape, xtr[0].shape))\n",
    "print (xtr.shape[0] + xval.shape[0] + xtst.shape[0])\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from scipy.signal import get_window\n",
    "\n",
    "class DataGen(Sequence):\n",
    "    \"\"\"\n",
    "    See [4], [5] to understand how data generators work.\n",
    "    CURRENTLY: This generator does work, but need to fix all MFCC getting related functions\n",
    "    to properly deal with our data format (and finish some of them)\n",
    "    \"\"\"\n",
    "    def __init__(self, x, labels, batch_size=2, FFT_size=2048, sr=44100):\n",
    "        self.x, self.y= x, labels\n",
    "        self.batch_size=batch_size\n",
    "        self.FFT_size = FFT_size\n",
    "        self.sr = sr\n",
    "        \n",
    "    def frame(self, audio, hop_size=10):\n",
    "        \"\"\"     \n",
    "        Convert batch of time series to batch of audio frame\n",
    "        Not currently working fully for batches, there is a cell below for\n",
    "        playing with this.\n",
    "        Taken from https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial\n",
    "        hop_size in ms\n",
    "        \"\"\"\n",
    "        audio = np.pad(audio, int(self.FFT_size / 2), mode='reflect')\n",
    "        frame_len = np.round(self.sr * hop_size / 1000).astype(int)\n",
    "        frame_num = int((len(audio) - self.FFT_size) / frame_len) + 1\n",
    "        frames = np.zeros((frame_num, self.FFT_size))\n",
    "\n",
    "        for n in range(frame_num):\n",
    "            frames[n] = audio[n*frame_len:n*frame_len+self.FFT_size]\n",
    "\n",
    "        return frames\n",
    "    \n",
    "    def freq_domain(self, frames):\n",
    "        # Convert audio frame into frequency domain\n",
    "        window = get_window(\"hann\", self.FFT_size, fftbins=True)\n",
    "        wins=[]\n",
    "        for frame in frames:\n",
    "            wins.append(frame*window)\n",
    "        return np.array(wins)\n",
    "    \n",
    "    def mfcc(self, batch):\n",
    "        # Given frequency domains, get the MFCCs\n",
    "        pass\n",
    "\n",
    "    def get_mfcc(self, batch):\n",
    "        \"\"\" \n",
    "        Given a batch of data X, we have n rows. Each row contains\n",
    "        a time series. Each of these time series needs to be converted to an audio frame and then\n",
    "        to a frequency domain. We can then use that to filter and extract useful MFCC features. \n",
    "        See [1], [2], [3].\n",
    "        \"\"\"\n",
    "        # Convert batch to MFCCs\n",
    "        # First, get the frames\n",
    "        frames=[]\n",
    "        for series in batch:\n",
    "            fr=self.frame(series) # Get the frame. Our X dimension will not be the same for all - take note.\n",
    "            frames.append(fr)\n",
    "        \n",
    "        frames = np.array(frames)\n",
    "        # Given frames, convert these to frequency\n",
    "        freq = self.freq_domain(frames)\n",
    "        \n",
    "        # Given freq domain, we can finally extract the MFCCs\n",
    "        mfccs=mfcc(freq)\n",
    "        \n",
    "        return frames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        tmp_x=self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Pass x batch to get transformed\n",
    "        batch_x=self.get_mfcc(tmp_x)\n",
    "        \n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=DataGen(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1033, 2048)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Indicies: First 0: Batch 0\n",
    "          Second 0: Training data (1 is labels)\n",
    "          Third 0: Sample #\n",
    "          Fourth: Row of sample\n",
    "\"\"\"\n",
    "data[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to find out how to convert batch of time series to batch of frames\n",
    "\n",
    "def frame(audio, FFT_size=2048, hop_size=10, sample_rate=44100):\n",
    "    # Taken from https://www.kaggle.com/ilyamich/mfcc-implementation-and-tutorial\n",
    "    # hop_size in ms\n",
    "    audio = np.pad(audio, int(FFT_size / 2), mode='reflect')\n",
    "    frame_len = np.round(sample_rate * hop_size / 1000).astype(int)\n",
    "    frame_num = int((len(audio) - FFT_size) / frame_len) + 1\n",
    "    frames = np.zeros((frame_num,FFT_size))\n",
    "\n",
    "    for n in range(frame_num):\n",
    "        frames[n] = audio[n*frame_len:n*frame_len+FFT_size]\n",
    "\n",
    "    return frames\n",
    "\n",
    "frt=frame(data[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 2048)\n"
     ]
    }
   ],
   "source": [
    "print (frt.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
