


# Miria
2018-08-13-14 - Working on the report
2018-08-12 - Adding plots and information to the presentation and finalizing it
2018-08-12 - Executted the codes on the server and formatted the results
2018-08-12 - Working on the report
2018-08-11 - creating bibliography on Latex and fixing the references to the bibliography and images in the report
2018-08-11 - Working on the report
2018-08-10 - Working on the report
2018-08-05 - Solving MOA server issues and installing packages to execute the codes
2018-08-04 - Start implementing a classifier using tensorflow and Keras
2018-07-27 - Plot mel-spectrograms, analyse its dimensions and filled up the report with the plots and dimensions' info. This dataset (size 128) is much smaller than the spectrograms (size 1025) so I will try the RF and MLP on them.
2018-07-26 - Finishing literature review
            -Calculate the mel-spectrogram that was used by Lee et all in the literature review
2018-07-25 - Writing the literature review and stablishing a good approach to implement as a start
2018-07-24 - Finding papers that deal with similar/same problem.
            - Plotting 2 samples of sounds (knock and oboe) in all the 5 description I have used so far to include in the report as a way to show how these two different sounds variates according to each description (tonneltz, spectral_centroid, spectral_bandwidth, mfcc and spectrograms)
2018-07-23 - Describe the data in function of the *spectrogram*. Dimensions are frequency in Hz, time and intensity in Db. Each sample is described in this huge space.
            - Try to classify using Random Forest but the samples were to big and the application crashes. Due to that, I did not try to classify with MLP.
            - Think how to apply convolution on the spectrograms focus on the pooling after the convolution to decrease dimensionality even more. Thought to treat the spectrogram as an image. The filters would be the ones to emphasize edges and the pooling would be the maximum function pooling. Then I decided to check the literature first to see what people already know that does not work =).
2018-07-20 - Classify the *tonneltz* using Random Forest and Multiple Layer Perceptron 
            - Study the dimensions of the *tonnelts* output and the number of samples with each dimension to evaluate how much is going to be lost if we stablish a maximun legth that is smaller than the biggest length found in the data. 6 dimensions with 20 to 2600 length each. The maximum length used was 1000 of length and the 6 dimensions were reshape into 1 dimension vector of total size of 6000 for sample.
            - Study the dimensions of the *spectral centroid* output and the number of samples with each dimension to evaluate how much is going to be lost if we stablish a maximun legth that is smaller than the biggest length found in the data. 1 dimension with lengths variating between 25 to 2600 of length. We cut it or padded it to a length of 1000 values.
            - Classify the *spectral centroid* data using Random Forest and Multiple Layer Perceptron
            - Study the dimensions of the *spectral bandwidth* output and the number of samples with each dimension to evaluate how much is going to be lost if we stablish a maximun legth that is smaller than the biggest length found in the data. 1 dimension with lengths variating between 25 to 2600 of length. We cut it or padded it to a length of 1000 values.
            - Classify the *spectral bandwidth* output using Random Forest and Multiple Layer Perceptron
            - Study the dimensions of the *mfcc* output and the number of samples with each dimension to evaluate how much is going to be lost if we stablish a maximun legth that is smaller than the biggest length found in the data. 25 dimension with lengths variating between 25 to 2600 of length. We cut it or padded it to a length of 1000 values and reshape the array into 1 dimension with 25000 values for sample
            - Try to classify the *mfcc* using Random Forest and Multiple Layer Perceptron. We got results for the RF but the MLP was taking too long to execute each epoch that I had to killed the application in order to test other strategies.
            - Start writing the report.
2018-07-18 - Describe the data in function of the *spectral centroid*
            - Describe the data in function of the *spectral bandwidth*
            - Describe the data in function of the *mfcc*      
2018-07-17 - Describe the data in function of *tonneltz*
            - Search for sounds properties trying to identify which property would be more helpful to differentiate different sources of sound.
            - Plotting the raw data and playing it in the jupyter notebook
            - Read and analyse parts of the baseline solution
2018-07-13 - Limit the maximum length of the raw data to use in a first classification attempt
2018-07-12 - Load data using pandas. Filter out the data that were not verified and the files names which the files are not in the train set folder 
2018-06-29 - Asked to the admin of MOA server to install Python 3 n the server 
2018-06-27 - Check what we have for data, what are the characteristics and what the data means
2018-06-27 - Read and analyse the problem descriptions. Check the rules' competition and input a summary with requirements and limitations
2018-06-27 - Download database


###### KENNY ######
2018-08-14 - Lots of writing part 2 :)
2018-08-13 - Lots of writing :)
2018-08-12 - Attempt to implement GoogLeNet (without success - would need more time for this :))
2018-08-11 - Update our report, added "methods" section including detailing the signal processing, explaining comparisons
             and mentions about noteable models that I had tried, and added future work
2018-08-10 - Implement an MFCC extraction notebook to have more flexible extractions than librosa
2018-08-03 - Created new notebook with some more data representations like CQT, STFT, trying new
             classifiers
2018-08-02 - Create latex template, move current writing to the latex file
2018-07-29 - Commit more models to git
2018-07-25 - Create functions for getting melspectrograms, and putting them in proper format
           - Start trying to create models that use melspectrogram
2018-07-22 - Start implementing models with Keras, commit models to git
2018-07-20 - View papers to get ideas for models
2018-07-19 - Commit notebook to allow others access to code
2018-07-10 - Visualize some of the data, pre processed data to get MFCCs, start working on models
2018-06-30 - Download database, set up jupyter notebook

#Matthew 
July 07 - Downloaded Kaggle data and loaded it into notebook
July 20 - Worked on loading .wav files into notebook and converting to MFCC
July 22 - Created basic CNN model, tried implementing tanh-estimator which did not work
July 23 - Started working with LSTM and applying it to the same model as CNN
July 24 - Made LSTM Bidirectional, got good results
July 25 - Tweaked model, added other layers, tested various hyperparameters
July 27 - Added more layers to model, started getting better accuracy 
August 6 - Worked on model more, tried different models and hyperparameters
August 7 - Tweaked and tested models more, tried using mel-spectrogram
August 8 - Tried implementing tanh-estimator again and run main model using it
August 9 - Tried to run large model with low learning rate to fix overshooting problem, writing paper
August 10 - Worked on models and writing paper, tried to help with MFCC implementation
August 11 - Worked on slides for presentation, writing and editing paper
August 12 - Tried to calculate accuracy if correct prediction was in the top 3, created a couple more models, wrote more of the paper, did more work on slides
August 13 - Presentation preparation, presentation, worked on slides, worked on report, tried to implement some suggestions from meeting
August 14 - Tried to implement some suggestions from meeting, wrote, edited and finalized the paper.
